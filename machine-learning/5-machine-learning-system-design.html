<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Other</h1>

<!-- Machine learning system design BEGIN -->
<div class="card mb-4" id="machine-learning-system-design">
  <div class="card-body">
    <h2 class="card-title">Machine learning system design</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#machine-learning-system-design-">Machine learning system design</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="machine-learning-system-design-">
  <div class="card-body">
    <h2 class="card-title">Machine learning system design</h2>
    <ul>
      <li>Clarify requirements</li>
      <ul>
        <li>Business objective. For example, increase number of bookings or revenue.</li>
        <li>Features that the system supports. For example, whether users can like/dislike videos.</li>
        <li>Data. What are data source? How large is dataset? Is data labeled?</li>
        <li>Contraints. For example, available computing power, mobile devise vs cloud.</li>
        <li>Scale. How many users? How many videos?</li>
        <li>Performance. How fast should prediction be? Batch vs realtime, accuracy vs latency.</li>
      </ul>
      <li>Framing problem as ML task</li>
      <ul>
        <li>Define ML objective</li>
        <ul>
          <li>Increase ticket sales -> Maximize number of event registration</li>
          <li>Increase user engagement -> Maximize time users spend watching videos</li>
          <li>Increase user clicks -> Maximize click-through rate</li>
          <li>Improve platform's safety -> Predict if content is harmful</li>
          <li>Increase user network growth -> Maximize number of formed connections</li>
        </ul>
        <li>Specify input and output</li>
        <li>Choose right ML category</li>
        <ul>
          <li>Supervised learning: classification (binary, multiclass), regression</li>
          <li>Unsupervised learning: clustering, association, dimension reduction</li>
          <li>Reinforcement learning</li>
        </ul>
      </ul>
      <li>Data preparation</li>
      <ul>
        <li>Data engineering</li>
        <ul>
          <li>Data source</li>
          <li>Data storage (DB)</li>
          <li>ETL</li>
          <li>Data types</li>
          <ul>
            <li>Structured: numerical (discrete, continuous), categorical (ordinal, nominal)</li>
            <li>Unstructured: audio, video, image, text</li>
          </ul>
        </ul>
        <li>Feature engineering</li>
        <ul>
          <li>Handle missing values</li>
          <ul>
            <li>Delete</li>
            <li>Imputation</li>
          </ul>
          <li>Feature scaling</li>
          <ul>
            <li>Normalization</li>
            <li>Standardization</li>
            <li>Log scaling</li>
          </ul>
          <li>Bucketing</li>
          <li>Encode categorical features</li>
          <ul>
            <li>Integer encoding</li>
            <li>One-hot encoding</li>
            <li>Embedding learning</li>
          </ul>
        </ul>
      </ul>
      <li>Model development</li>
      <ul>
        <li>Model selection</li>
        <ul>
          <li>Establish baseline</li>
          <li>Experiment with simple models</li>
          <li>Try complex models</li>
          <li>Emsemble if needed</li>
        </ul>
        <li>Model training</li>
        <ul>
          <li>Construct dataset</li>
          <ul>
            <li>Collect raw data</li>
            <li>Identify features and labels</li>
            <li>Select sampling strategy</li>
            <li>Split data</li>
            <li>Address imbalance</li>
          </ul>
          <li>Choose loss function</li>
          <li>Train from scratch vs fine-tuning</li>
          <li>Distributed training</li>
        </ul>
      </ul>
      <li>Evaluation</li>
      <li>Deployment and serving</li>
      <li>Monitoring and infrastructure</li>
    </ul>

    <h3 class="card-title">High level design</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-highlevel.png" alt="Card image cap">

    <h3 class="card-title">Component design</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-development-v1.png" alt="Card image cap">
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-training-v1.png" alt="Card image cap">
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-inference-batch-v1.png" alt="Card image cap">
    <ul>
      <li>Performce for out-of-sample and out-of-time.</li>
      <li>Features should be mostly unchanged when input data is slighly perturbed. (Could be challgenging when data contains similar/duplicate features)</li>
      <li>Interpretation should not be depending on training sample choices.</li>
    </ul>

    <h3 class="card-title">Problem definition</h3>
    <ul>
      <li>Construct ground truth.</li>
      <li>Metrics.</li>
    </ul>

    <h3 class="card-title">Data prep</h3>
    <ul>
      <li>Proportion of null/zero values across columns.</li>
      <li>Columns that should be rejected due to zero or null values.</li>
      <li>Categorical columns with high cardinality.</li>
      <li>Columns with high sparcity.</li>
      <li>Duplicate columns.</li>
      <li>Compute per-month count of rows and selected attribute to see if they make sense.</li>
      <li>Verify that join keys are consistent across tables.</li>
      <li>Verify that labels/values to apply exclusions are available in the tables.</li>
      <li>Verify that labels/values to apply ground truth are available in the tables.</li>
      <li>Rectify missing values in columns.</li>
      <ul>
      <li>Random missing value - value is missing for unexplained reason.</li>
      <li>Structural missing value - value is missing for a reason. (For example, the fact that it is missing means something)</li>
      <li>Engineered missing value - feature engineering introduced the missing values. (For example, divide by zero)</li>
      <li>Table join mismatch - IDs in one table were missing in another table, so missing values are created after join.</li>
    </ul>
    </ul>

    <h3 class="card-title">Data profiling</h3>
    <ul>
      <li>General statistics.</li>
      <li>Columns with large portion of missing values. (For example, > 10%)</li>
      <ul>
        <li>These columns should generally be retained for they may turn out to be quite predictive.</li>
        <li>XGBoost has build-in capability to handle missing values.</li>
      </ul>
      <li>Similar/duplicate columns. (For example, prefer one feature over another? Can use univariate analysis)</li>
      <li>Columns with consistant values should be removed because they provide no signal.</li>
      <li>Remove sensitive features from model inputs. (For example, age / gender)</li>
      <li>Data imputation (For example, NULL to 0) should rarely happens when feature is critical and will undergo feature engineering and treatment is known.</li>
    </ul>

    <h3 class="card-title">Exclusion</h3>
    <ul>
      <li>Exclude rows based on certain attributes. (This is driven by business reasons)</li>
    </ul>

    <h3 class="card-title">Ground truth construction</h3>

    <h3 class="card-title">Data split</h3>
    <ul>
      <li>Training: In-Time and In-Sample. Split into 5-folds for cross-validation.</li>
      <li>Testing: Out-of-Time test and In-Time & Out-of-Sample test.</li>
      <li>If a data about person is seen at many different dates, all data about that person must be assigned to the same split. (either Out-of-Sample or one of the folds) Otherwise, there is information leak bwetween training and validation.</li>
      <li>Final model is retrained with all 5 folds combined.</li>
    </ul>

    <h3 class="card-title">Data representativeness</h3>
    <ul>
      <li>Separate datasets by ground truth labels.</li>
      <li>Perform univariate analysis. For example, look at the distribution of samples of a key feature for both the entire dataset and the partitioned dataset. Repeat for all key features.</li>
      <li>All paritioned datasets must include sufficient volume of each ground truth labels across key features.</li>
      <li>Bin size may be increased or bins could be combined as a result of above analysis.</li>
    </ul>

    <h3 class="card-title">Model development</h3>
    <ul>
      <li>Define metric to evaluate the model.</li>
      <li>Score the model by the desired metric.</li>
      <li>Check model performace by month to check seasonality.</li>
      <li>Kubernetes based</li>
      <ul>
        <li>Make changes to code.</li>
        <li>Build, test, package the code.</li>
        <li>Build an image which includes the code package.</li>
        <li>Deploy the image to Kubenetes using tools like Skaffold / Helm.</li>
        <li>Run commands inside the image to execute the code.</li>
      </ul>
      <li>Databricks based</li>
      <ul>
        <li>Make changes to code.</li>
        <li>Build, test, package, publish the code.</li>
        <li>Import the code from the notebook.</li>
        <li>Write additional code on the notebook as needed.</li>
        <li>Run commands on the notebook execute the code.</li>
      </ul>
    </ul>

    <h3 class="card-title">Feature selection</h3>
    <ul>
      <li>Start with initial set of feature ~ 1500</li>
      <li>First gate</li>
      <ul>
        <li>Data preparation</li>
        <li>Feature engineering</li>
      </ul>
      <li>After exclusions ~ 1000</li>
      <li>First stage</li>
      <ul>
        <li>Assess each feature individually.</li>
        <li>Select a metric.</li>
        <li>Use 4-folds for training and 1 fold for validation.</li>
        <li>Train a shallow model with a single feature as input and compute performance in validation set.</li>
        <li>Rank individual features.</li>
        <li>Then, train a model wtih all features.</li>
        <li>Then again, rank the features.</li>
      </ul>
      <ul>
        <li>Perform recursive feature search.</li>
        <li>Use 4-folds for training and 1 fold for validation. (Validation fold must be different from previous step)</li>
        <li>For each feature in top N features, train a model and score performance on validation set.</li>
        <li>Add the best scoring features to the candidate features.</li>
      </ul>
      <li>Candidate features ~ 100</li>
      <li>Second gate</li>
      <ul>
        <li>Highly correlated features should be justified or redundant features should be removed.</li>
        <li>Future retraining starts from the candidate features.</li>
      </ul>
      <li>Second stage</li>
      <ul>
        <li>Perform 5-fold cross validation with each candidate feature.</li>
        <li>Compute shapley values on the validation set.</li>
        <li>Select stable features via union of top features across the folds.</li>
      </ul>
      <li>Stable features ~ 40</li>
    </ul>

    <h3 class="card-title">Hyperparameter tuning</h3>
    <ul>
      <li>Ex. grid search, random search, bayesian optimization.</li>
    </ul>

    <h3 class="card-title">Final model training</h3>
    <ul>
      <li>Train the model using stable features and tuned hyperparameters.</li>
      <li>Evaluate on OOS (seasonality) and OOT (final evaluation) test sets.</li>
    </ul>

    <h3 class="card-title">Monitoring</h3>
    <ul>
      <li>Partial dependency plot (PDP) assesses marginal effect of a feature to the model output.</li>
      <li>Indvidual conditional expectation (ICDE) is equivalent to PDP but for an individual data point.</li>
      <li>Feature contribution is assessed via shapley values.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>
<!-- Machine learning system design END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>