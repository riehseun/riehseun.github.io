<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Linear regression BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Linear regression</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#linear-regression-">Linear regression with pytorch</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="linear-regression-">
  <div class="card-body">
    <h2 class="card-title">Linear regression with pytorch</h2>

<pre><code class="python"># Load data
# Standardize data
# Intialize parameters
# Train
#   Compute Z, A (forward porp)
#   Compute cost
#   Compute gradient (backward prop)
#   Update weights
# Inference

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader

import torch
import torch.nn as nn
import torch.nn.functional as F

# Data

class CustomDataset(Dataset):

    def __init__(self, X_train, y_train):
        self.x = F.normalize(torch.from_numpy(X_train))  # (m, n)
        self.y = torch.from_numpy(y_train) # (m)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        return self.x[index].float(), self.y[index].float()

dataset = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)
train_data = CustomDataset(X_train, y_train)
test_data = CustomDataset(X_test, y_test)
train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=1, shuffle=True)

# Model
class LinearRegression(nn.Module):

    def __init__(self, num_features):
        super().__init__()
        # X (m,n) => Y (m, 1)
        self.linear = nn.Linear(num_features, 1)

    def forward(self, x):
        x = self.linear(x)
        x = torch.squeeze(x)
        return x

# Train
n = dataset.data.shape[1]
model = LinearRegression(n)
learning_rate = 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

epoch = 1000

for key, val in model.state_dict().items():
    print(f"{key}: {val}")

for e in range(epoch):
    for x_batch, y_batch in train_dataloader:

        optimizer.zero_grad()  # Reset grads

        y_hat = model(x_batch)  # (m, 1)

        # print(f"x_batch: {x_batch.shape}")
        # print(f"y_batch: {y_batch.shape}")
        # print(f"y_hat: {y_hat.shape}")
        # print(y_batch)
        # print(y_hat)

        loss = criterion(y_hat, y_batch)  # Compute loss

        loss.backward()  # Compute gradient

        optimizer.step()  # Adjust learning rate

        print(f'epoch: {e+1}, loss = {loss.item()}')

for key, val in model.state_dict().items():
    print(f"{key}: {val}")

# Inference
diff = 0
with torch.no_grad():
    for x_batch, y_batch in test_dataloader:
        y_pred = model(x_batch)  # no need to call model.forward()
        diff += abs(y_pred-y_batch)
    print(diff)</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>
<!-- Linear regression END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>