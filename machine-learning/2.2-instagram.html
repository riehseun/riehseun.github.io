<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Instagram BEGIN -->
<div class="card mb-4" id="instagram">
  <div class="card-body">
    <h2 class="card-title">Instagram</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#instagram-1">Requirement</a></li>
      <li><a href="#instagram-2">Problem</a></li>
      <li><a href="#instagram-3">Data preparation</a></li>
      <li><a href="#instagram-4">Model development</a></li>
      <li><a href="#instagram-5">Evaluation</a></li>
      <li><a href="#instagram-6">Serving</a></li>
      <li><a href="#instagram-7">Infrastructure</a></li>
      <li><a href="#instagram-8">Follow up</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="instagram-1">
  <div class="card-body">
    <h2 class="card-title">Requirement</h2>
    <ul>
      <li>Business</li>
      <ul>
        <li>What is the business objective? use ML for feed ranking</li>
        <li>What does a feed consist of? Posts and ADs</li>
        <li>What does a post consist of? Text, image, video</li>
        <ul>
          <li>Should the feed be personalized for each user? Yes</li>
          <li>Can users follow each other? Yes</li>
          <li>Can users report/block other users? Yes</li>
        </ul>
        <li>What does an AD consist of? Text, image, video</li>
        <ul>
          <li>Should ADs be personalized for each user? Yes</li>
          <li>Whare are the ADs placed? In the feeds</li>
          <li>Does each AD generate the same revenue? Yes</li>
          <li>Can an AD be shown to a user more than once? Yes</li>
        </ul>
      </ul>
      <li>Data</li>
      <ul>
        <li>Do we have training data available? No</li>
        <li>Does the system keep track of user interactions with posts and ADs? Yes</li>
        <li>Can user like/share/comment/hide/report the posts and ADs? Yes</li>
      </ul>
      <li>Constraints</li>
      <ul>
        <li>How much compute is available to do model training? Large cluster of GPUs are available</li>
        <li>Does the model need to be deployed to mobile devices? Yes</li>
        <li>Can the inference be batch or does it need to be online? Depends on the use case</li>
        <li>How fast should the inference be? Reasonably fast</li>
        <li>Is accuracy or latency more important? Both</li>
        <li>Should the model be trained continusouly? Yes</li>
      </ul>
      <li>Estimation</li>
      <ul>
        <li>How many users are using the system? 1M daily users, 1B total users</li>
        <li>How many posts are in the system? each user creates 1 post per day on average</li>
        <li>How many ADs are in the system? 1M per month</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-2">
  <div class="card-body">
    <h2 class="card-title">Problem</h2>

    <h3 class="card-title">ML problem</h3>
    <ul>
      <li>For each user, produce feeds where posts and ADs show up basd on probability of being clicked</li>
      <li>Input</li>
      <ul>
        <li>User</li>
      </ul>
      <li>Output</li>
      <ul>
        <li>List of posts and ADs basd on probability of being clicked</li>
      </ul>
    </ul>

    <h3 class="card-title">ML category</h3>
    <ul>
      <li>Supervised, ranking problem, learn to rank</li>
      <ul>
        <li>Collaborative filtering</li>
        <ul>
          <li>Assume similar users are interested in similar items</li>
          <li>Uses user-item interaction data only (No need to use item features)</li>
          <li>Needs to compute user-user or item-item similarities</li>
          <li>Pros</li>
          <ul>
            <li>No need for domain knowledge because item features are not used</li>
            <li>Can discover users new interest</li>
            <li>Less compute intensive than content-based filtering</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Cold-start problem when lack of user interaction data</li>
            <li>Hard to capture unique interest of users</li>
          </ul>
        </ul>
        <li>Content-based filtering</li>
        <ul>
          <li>Uses item features</li>
          <li>Recommend items that are similar to those that were relevant to user</li>
          <li>Pros</li>
          <ul>
            <li>No need to wait for user interaction data. Recommendation depends on item features only</li>
            <li>Captures unique interest of users</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Requires domain knowledge. Features are often engineered manually</li>
            <li>Hard to discover users new interest</li>
          </ul>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-3">
  <div class="card-body">
    <h2 class="card-title">Data preparation</h2>

    <h3 class="card-title">Data engineering</h3>
    <ul>
      <li>Training data</li>
      <ul>
        <li>Human label</li>
        <ul>
          <li>People manually labelling posts, ADs, reels, that they find relevant</li>
          <li>Accurate but expensive</li>
        </ul>
        <li>User interaction</li>
        <ul>
          <li>Utilize user-item interaction data</li>
          <li>Data is noisy and classes will be imbalanced, but inexpensive</li>
        </ul>
      </ul>
      <li>Database</li>
      <ul>
        <li>User</li>
        <ul>
          <li>user_id</li>
          <li>username</li>
          <li>email</li>
          <li>city</li>
          <li>country</li>
          <li>age</li>
          <li>gender</li>
        </ul>
        <li>Post</li>
        <ul>
          <li>post_id</li>
          <li>author_id</li>
          <li>text</li>
          <li>tags</li>
          <li>image</li>
          <li>video</li>
          <li>timestamp</li>
        </ul>
        <li>AD</li>
        <ul>
          <li>ad_id</li>
          <li>category</li>
          <li>text_description</li>
          <li>image_path</li>
          <li>video_path</li>
          <li>manual_tags</li>
        </ul>
        <li>User-AD interaction</li>
        <ul>
          <li>user_id</li>
          <li>ad_id</li>
          <li>interaction - impression, click</li>
          <li>timestamp</li>
          <li>position_of_AD_in_feed</li>
          <li>order_of_interaction_after_feed_is_shown</li>
        </ul>
        <li>User-post interation</li>
        <ul>
          <li>user_id</li>
          <li>post_id</li>
          <li>interaction_type - click, like, share, comment, report, hide, etc</li>
          <li>timestamp</li>
          <li>position_of_post_in_feed</li>
          <li>order_of_interaction_after_feed_is_shown</li>
        </ul>
        <li>Friendship</li>
        <ul>
          <li>user_id_1</li>
          <li>user_id_2</li>
          <li>timstamp</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Feature engineering</h3>
    <ul>
      <li>User</li>
      <ul>
        <li>User ID - embedding since the dimension is sparse</li>
        <li>Username - can't use due to dependecy with user ID</li>
        <li>Email -  can't use due to dependecy with user ID</li>
        <li>City - embedding</li>
        <li>Country - embedding</li>
        <li>Age - can't use due to bias and fairness concern</li>
        <li>Gender - can't use due to bias and fairness concern</li>
      </ul>
      <li>Post</li>
      <ul>
        <li>Post ID - embedding</li>
        <li>Description - BERT</li>
        <ul>
          <li>Preprocessing</li>
          <ul>
            <li>Text normalization (text cleanup)</li>
            <ul>
              <li>Lowercasing</li>
              <li>Punctuation removal</li>
              <li>Trim whitespaces</li>
              <li>Normalization Form KD (NFKD)</li>
              <li>Strip accents</li>
              <li>Lemmatization and stemming</li>
              <li>Ex. "A person  is walking in Montreal!" -> "a person walk in montreal"</li>
            </ul>
            <li>Tokenization</li>
            <ul>
              <li>Ex. "a person walk in montreal" -> "["a", "person", "walk", "in", "montreal"]"</li>
            </ul>
            <li>Tokens to IDs</li>
            <ul>
              <li>Option 1. lookup table</li>
              <ul>
                <li>Each token is mapped to unique ID</li>
                <li>Need to keep large table in memory</li>
                <li>New words cannot be handled</li>
              </ul>
              <li>Option 2. hashing</li>
              <ul>
                <li>Hash function is used to compute ID for each token</li>
                <li>Potential collision</li>
                <li>Cannot convert IDs to tokens</li>
              </ul>
              <li>Ex. "["a", "person", "walk", "in", "montreal"]" -> [33,28,4,16,99]</li>
            </ul>
          </ul>
          <li>Vectorization</li>
          <ul>
            <li>Statistical methods like BoW and TF-IDF cannot capture semantics</li>
            <li>Use SentenceBERT</li>
          </ul>
        </ul>
        <li>Image - CILP</li>
        <ul>
          <li>Preprocessing</li>
          <ul>
            <li>Resize - models require fixed-sized images</li>
            <li>Scale - pixel values should be between 0 and 1</li>
            <li>Standardization - pixel values should have mean 0 and variance 1</li>
            <li>Color mode - pick either RGB or CMYK</li>
          </ul>
          <li>Feature extraction</li>
          <ul>
            <li>CLIP's visual encoder, ViT, SimCLR</li>
          </ul>
        </ul>
        <li>Video - VideoMoco</li>
        <ul>
          <li>Preprocessing</li>
          <ul>
            <li>Decode frames</li>
            <li>Sample frames</li>
            <li>Resize</li>
            <li>Scale</li>
            <li>Normalize</li>
            <li>Pick color mode</li>
          </ul>
          <li>Feature extraction</li>
          <ul>
            <li>VideoMoCo</li>
          </ul>
        </ul>
        <li>Tag - CBOW</li>
        <ul>
          <li>Use Viterbi to tokenzie hashtags into different words</li>
          <li>Use feature hashing to convert words to Ids</li>
          <li>Use TF-IDF or word2vec to vectorize each tag</li>
          <li>Average embeddings of each tag</li>
        </ul>
        <li>Post's age - bucketize + one-hot</li>
      </ul>
      <li>AD</li>
      <ul>
        <li>Advertiser id - embedding</li>
        <li>Image - SimCLR</li>
        <li>Video - VideoMoCo</li>
        <li>Category - CBOW</li>
        <li>Total impressions or clicks on the Ad - normalize</li>
      </ul>
      <li>Author</li>
      <ul>
        <li>Author's violation history</li>
        <ul>
          <li>Number of violations - normalize</li>
          <li>Total user reports - normalize</li>
          <li>Profane word rate - normalize</li>
        </ul>
        <li>Author's demographics</li>
        <ul>
          <li>Age - can't use due to bias and fairness concern</li>
          <li>Gender - can't use due to bias and fairness concern</li>
          <li>City and country - embedding</li>
        </ul>
        <li>Account information</li>
        <ul>
          <li>Number of followers and followings - normalize</li>
          <li>Account's age - bucketize + one-hot</li>
        </ul>
      </ul>
      <li>User-post interaction</li>
      <ul>
        <li>View - normalize</li>
        <li>Like - normalize</li>
        <li>Comment - SentenceBERT</li>
        <li>Share - normalize</li>
        <li>Hide - normalize</li>
        <li>Report - normalize</li>
      </ul>
      <li>User-AD interaction</li>
      <ul>
        <li>Cliked Ads - average embeddings for each clicked AD</li>
        <li>User's historical engagement statistics - normalize</li>
      </ul>
      <li>User-author interaction</li>
      <ul>
        <li>Duration at which user followed the author - bucketize + one-hot</li>
        <li>Duration at which author followed the user - bucketize + one-hot</li>
        <li>like/click/comment/share rate - normalize</li>
        <li>length of friendship - bucketize + one-hot</li>
        <li>close friends and family - binary value 0 or 1</li>
      </ul>
      <li>Context</li>
      <ul>
        <li>month - one-hot</li>
        <li>day_of_week - one-hot</li>
        <li>time_of_day - bucketize + one-hot</li>
        <li>device - one-hot</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-4">
  <div class="card-body">
    <h2 class="card-title">Model development</h2>

    <h3 class="card-title">Model selection</h3>
    <ul>
      <li>Candidate generation</li>
      <ul>
        <li>Option 1. matrix factorization (collaborative filtering)</li>
        <ul>
          <li>Feedback matrix</li>
          <ul>
            <li>2D matrix (user and item) where 1 means user finds item relevant</li>
            <li>Relevancy can be defined using both explicit and implicit feedback</li>
            <li>Explicit feedback</li>
            <ul>
              <li>User likes/dislikes, shares, reports, etc</li>
              <li>Data is sparse</li>
            </ul>
            <li>Implicit feedback</li>
            <ul>
              <li>User clicks or dwell/watch time</li>
              <li>Data might be noisy</li>
            </ul>
          </ul>
          <li>Matrix factorization model</li>
          <ul>
            <li>Map user and item into embeddings such that their distance represents their relevance</li>
            <li>Decomposes feedback matric into two lower dimensional matrices, where one represents user embedding and the other represents item embedding</li>
          </ul>
          <li>Inference</li>
          <ul>
            <li>Take a dot product between user and item embeddings</li>
          </ul>
          <li>Pros</li>
          <ul>
            <li>Fast training because there are only two embedding matrices to learn</li>
            <li>Fast serving because learned embeddings are static</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Handling new users is difficult</li>
            <li>Model performance is lower</li>
          </ul>
        </ul>
        <li>Option 1. two-tower network (collaborative filtering - no item features)</li>
        <ul>
          <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-21.png" alt="Card image cap">
          <li>Narrow down items from billions to thousands</li>
          <li>Use model that does not rely on item feature for efficiency</li>
          <li>Inference</li>
          <ul>
            <li>Use ANN to find most relevant items for a given user from their embeddings</li>
          </ul>
          <li>Pros</li>
          <ul>
            <li>Utilizes user features</li>
            <li>Capable of handling new users</li>
            <li>Model performance is higher</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Slow serving having to compute user embeddings at query time</li>
            <li>Slow inference (if using content-based filtering) because model needs to transform item IDs to item embeddings</li>
            <li>More learning paramaters, thus traning is more expensive</li>
          </ul>
        </ul>
      </ul>
      <li>Ranking</li>
      <ul>
        <li>Option 1. point-wise</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>Simpler to implement</li>
            <li>Less computation</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Hard to capture relations between items</li>
            <li>Less accurate</li>
          </ul>
          <li>Option 1a. Logistic regression</li>
          <ul>
            <li>User-item interaction data is used as features</li>
            <li>Pros</li>
            <ul>
              <li>Fast inference</li>
              <li>Fast training</li>
              <li>Interpretable</li>
            </ul>
            <li>Cons</li>
            <ul>
              <li>Non-linear problems can't be solved</li>
              <li>Cannot handle dependency between features</li>
            </ul>
          </ul>
          <li>Option 1b. Decision tree (XGBoost)</li>
          <ul>
            <li>User-item interaction data is used as features to output score for items</li>
            <li>Pros</li>
            <ul>
              <li>Interpretable</li>
              <li>Little dataprep is needed</li>
            </ul>
            <li>Cons</li>
            <ul>
              <li>Feature changes require training the entire model from scratch</li>
              <li>Cannot handle embedding</li>
            </ul>
          </ul>
          <li>Option 1c. two-tower network (content based filtering - use item features)</li>
          <ul>
            <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-22.png" alt="Card image cap">
            <li>Accuracy is more important than efficiency</li>
          </ul>
        </ul>
        <li>Option 2. pair-wise</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>More accutate</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Complex to implement</li>
            <li>High computation</li>
          </ul>
          <li>Option 2a. RankNet</li>
          <li>Option 2b. LambdaRank</li>
        </ul>
        <li>Option 3. list-wise</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>More accutate</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Complex to implement</li>
            <li>High computation</li>
          </ul>
          <li>Option 3a. ListNet</li>
          <li>Option 3b. LambdaMart</li>
        </ul>
      </ul>
      <li>Re-ranking</li>
      <ul>
        <li>Freshness</li>
        <li>Diversity</li>
        <li>Fairness</li>
        <li>Personalization</li>
      </ul>
    </ul>

    <h3 class="card-title">Model training</h3>
    <ul>
      <li>Loss function</li>
      <ul>
        <li>Matrix factorization</li>
        <ul>
          <li>Randomly initializes two embedding matrices</li>
          <li>Mimimizes the loss between predicted scores matrix and feedback matrix</li>
          <ul>
            <li>Option 1. squared distance over observed user-item pairs</li>
            <ul>
              <li>\( \text{loss} = \displaystyle\sum_{(i,j) \in \text{obs}} (A_{ij}-U_{i}V_{j})^{2} \)</li>
              <li>Loss function does not penalize for bad prediction on unobserved pairs</li>
            </ul>
            <li>Option 2. squared distance over observed and unobserved user-item pairs</li>
            <ul>
              <li>\( \text{loss} = \displaystyle\sum_{(i,j)} (A_{ij}-U_{i}V_{j})^{2} \)</li>
              <li>Unobserved pairs dominate observed pairs during training because feedback matrix is sparce</li>
            </ul>
            <li>Option 3. weighted combination of squared distance over observed and unobserved user-item pairs</li>
            <ul>
              <li>\( \text{loss} = \displaystyle\sum_{(i,j) \in \text{obs}} (A_{ij}-U_{i}V_{j})^{2} + w\displaystyle\sum_{(i,j) \notin \text{obs}} (A_{ij}-U_{i}V_{j})^{2} \)</li>
              <li>\( w \) is a hyperparameter</li>
            </ul>
          </ul>
          <li>Weighted alternating least squares (WALS) - specific to matrix factorization</li>
          <ul>
            <li>Fix one embedding matrix \( U \) and optimize the other embedding matrix \( V \)</li>
            <li>Fix the other embedding matrix \( V \) and optimize the embedding matrix \( U \)</li>
            <li>Repeat</li>
          </ul>
        </ul>
        <li>Two-tower</li>
        <ul>
          <li>Feed ranking</li>
          <ul>
            <li>Multi-task DNN is appropriate to handle different types of user-post interaction</li>
            <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-23.png" alt="Card image cap">
            <li>Use MAE / MSE for regression task for dwell time prediction</li>
            <ul>
              <li>\( L = \dfrac{1}{N} \displaystyle\sum_{i} (y_{i}-\hat{y_{i}})^{2} \)</li>
            </ul>
            <li>Use cross-entropy for other binary classification predictions</li>
            <ul>
              <li>\( L = -\displaystyle\sum_{i} y_{i}log\hat{y_{i}} + (1-y_{i})log(1-\hat{y_{i}}) \)</li>
            </ul>
            <li>\( \text{Loss} = \lambda L_{\text{dwell}} + L_{\text{skip}} + L_{\text{like}} + \dots + L_{\text{share}} \)</li>
          </ul>
          <li>AD recommendation</li>
          <ul>
            <li>Binary classification, use cross-entropy</li>
          </ul>
          <li>Reel recommendation</li>
          <ul>
            <li>Binary classification, use cross-entropy</li>
          </ul>
        </ul>
      </ul>
      <li>Hyperparameters</li>
      <ul>
        <li>Matrix factorization</li>
        <ul>
          <li></li>
        </ul>
        <li>Two-tower</li>
        <ul>
          <li>Size of embedding vector</li>
          <li>Number of hidden layers</li>
          <li>Number of neurons in each layer</li>
          <li>Learning rate</li>
          <li>Choice of activation function</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>

    <h3 class="card-title">Offline</h3>
    <ul>
      <li>Candidate generation</li>
      <ul>
        <li>Option 1. precision@k</li>
        <ul>
          <li>\( \dfrac{\text{Number of relevant items in top k items}}{\text{k}} \)</li>
          <li>Does not consider ranking quality, but ranking is out of scope for candidate generation</li>
        </ul>
        <li>Option 2. recall@k</li>
        <ul>
          <li>\( \dfrac{\text{Number of relevant items in top k items}}{\text{total number of relevant items}} \)</li>
          <li>Does not consider ranking quality, but ranking is out of scope for candidate generation</li>
        </ul>
        <li>Option 3. ROC curve</li>
        <ul>
          <li>Trade-off between true positive and false positive</li>
          <li>ROC-AUC calculates area beneath POC curve</li>
          <li>High ROC-AUC indicates more accurate model</li>
        </ul>
        <li>Option 4. PR curve</li>
        <ul>
          <li>Trade-off between precision and recall</li>
          <li>PR-AUC calculates area beneath PR curve</li>
          <li>High PR-AUC indicates more accurate model</li>
        </ul>
        <li>Option 5. cross-entropy</li>
        <ul>
          <li>Multiply ground truth label (0 or 1) with the probability of item</li>
          <li>Then, sum it to assess the model performance</li>
          <li>\( \text{CE} = -\displaystyle\sum_{i} y_{i}log\hat{y_{i}} + (1-y_{i})log(1-\hat{y_{i}}) \)</li>
        </ul>
      </ul>
      <li>Ranking</li>
      <ul>
        <li>Option 1. mean reciprobal rank (MRR)</li>
        <ul>
          <li>\( MRR = \dfrac{1}{m} \displaystyle\sum_{i=1}^{m} \dfrac{1}{\text{rank}_{i}} \)</li>
          <ul>
            <li>\( {\text{rank}_{i}} \) is position on which the first relevant item appears in the output list</li>
          </ul>
          <li>Consider only the first relevant item in each output list, then average the reciprocal rank</li>
          <li>Ignores other relevant items in the list other than the first one, thus not suitable for feed ranking problem</li>
        </ul>
        <li>Option 2. mean average precision (mAP)</li>
        <ul>
          <li>AP</li>
          <ul>
            <li>\( AP = \dfrac{\displaystyle\sum_{i=1}^{k} \text{precision}@i}{n} \)</li>
            <ul>
              <li>\( n = \) total relevant items</li>
            </ul>
            <li>Averages precision@k at different values of k</li>
            <li>AP is high if more relevant items are located at the top of list</li>
          </ul>
          <li>mAP</li>
          <ul>
            <li>Compute AP for each output list, then average them</li>
          </ul>
          <li>Works well when each item is either relevant or irrelevant, but does not work well for scoring relevance</li>
          <li>We need relative score to rank posts, AD, videos not whether each item should be recommended or not</li>
        </ul>
        <li>Option 3. normalized discounted cumulative gain (nDCG)</li>
        <ul>
          <li>\( DCG_{p} = \displaystyle\sum_{i=1}^{p} \dfrac{\text{rel}_{i}}{log_{2}(i+1)} \)</li>
          <ul>
            <li>\( \text{rel}_{i} \) is ground truth relevance score of item ranked at \( i \)</li>
          </ul>
          <li>\( nDCG_{p} = \dfrac{DCG_{p}}{IDCG_{p}} \)</li>
          <ul>
            <li>where \( {IDCG_{p}} \) is \( {DCG_{p}} \) of ideal ranking</li>
          </ul>
        </ul>
      </ul>
      <li>Re-ranking</li>
      <ul>
        <li>Option 1. diversity</li>
        <ul>
          <li>How dissimilar recommended items are to each other</li>
          <li>Calculate average pairwise similarity (Ex. cosine similarity or dot product) between items outputed by the model</li>
        </ul>
        <li>Option 2. freshness</li>
        <ul>
          <li>How new is the item to the user</li>
        </ul>  
        <li>Option 3. Serendipity</li>
        <ul>
          <li>How unexpected is the item to the user</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Online</h3>
    <ul>
      <li>General</li>
      <ul>
        <li>Click-through rate (CTR)</li>
        <ul>
          <li>\( \dfrac{\text{number of clicks}}{\text{number of impressions}} \)</li>
          <li>Does not consider quality of recommended items</li>
          <li>Can be biasd towards popular or frequently recommended items</li>
        </ul>
        <li>Averge number of clicks per user</li>
        <ul>
          <li>\( \dfrac{\text{number of clicks}}{\text{number of users}} \)</li>
        </ul>
      </ul>
      <li>Feed ranking</li>
      <ul>
        <li>Reaction rate</li>
        <ul>
          <li>\( \dfrac{\text{number of liked/shared/commented/hidden/blocked/skipped posts}}{\text{total number of impressions}} \)</li>
        </ul>
      </ul>
      <li>AD recommendation</li>
      <ul>
        <li>Number of hides on ADs</li>
      </ul>
      <li>Reel recommendation</li>
      <ul>
        <li>Total watch time of videos</li>
        <li>User reaction to videos such as likes, share, etc</li>
      </ul>
<!--       <li>Search</li>
      <li>Harmful content detection</li>
      <ul>
        <li>Number of user reports on posts (per harmful class)</li>
        <li>Valid appeals</li>
        <ul>
          <li>\( \dfrac{\text{number of reversed appeals}}{\text{number of harmful posts detected by system}} \)</li>
        </ul>
        <li>Proactive rate</li>
        <ul>
          <li>\( \dfrac{\text{number of harmful posts detected by system}}{\text{number of harmful posts detected by system} + \text{reported by users}} \)</li>
        </ul>
      </ul> -->
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-6">
  <div class="card-body">
    <h2 class="card-title">Serving</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-1.png" alt="Card image cap">
    <ul>
      <li>Batch features (Ex. AD's text, image, video) don't change much, so they can be processed offline</li>
      <li>Dynamic features (Ex. number of clicks for an AD) should be computed in real-time</li>
    </ul>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-2.png" alt="Card image cap">
    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-3.png" alt="Card image cap">
    <ul>
      <li>Candidate generation</li>
      <ul>
        <li>Gather relevant feeds, ADs, reels from pool of items</li>
        <li>Matrix Factorization, two-tower NN (with no item features) can be used</li>
        <li>Filter can be used to exclude irrelevant items</li>
      </ul>
      <li>Ranking</li>
      <ul>
        <li>Two-tower NN (with item features) can be used</li>
      </ul>
      <li>Re-ranking</li>
      <ul>
        <li>Re-orders items to generate dynamic mixture of recommendations</li>
        <li>Apply additional criteria</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-7">
  <div class="card-body">
    <h2 class="card-title">Infrastructure</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-0/instagram-11.png" alt="Card image cap">
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>

<div class="card mb-4" id="instagram-8">
  <div class="card-body">
    <h2 class="card-title">Follow up</h2>
    <ul>
      <li>Explain how to calibrate the model</li>
      <ul>
        <li>Convert model score to actual probability</li>
        <li>Platt scaling</li>
        <ul>
          <li>Used for binary classification that uses sigmoid</li>
        </ul>
        <li>Isotonic regression</li>
        <ul>
          <li>Computationally expensive</li>
        </ul>
        <li>Bayesian calibration</li>
        <ul>
          <li>Requires prior knowledge</li>
        </ul>
      </ul>
      <li>Explain catastrophic forgetting and the solutions</li>
      <ul>
        <li>When weights from previous training gets updated to re-train with new data, old knowledge gets forgotton</li>
        <li>Regularization - prevent overfitting to new data</li>
        <li>Elastic weight consolidation - add regularization term to penalize changes to important weights</li>
        <li>Learning multiple tasks sequentially, there by learning different weights for different tasks</li>
      </ul>
      <li>Explain exploration-exploitation trade-off in recommendation system</li>
      <ul>
        <li>Balance between recommending popular items (exploitation) and recommending new potentially betwee items (exploration)</li>
      </ul>
      <li>Explain bias that may be present in recommendation system</li>
      <ul>
        <li>Popularity bias - tend to favor already popular items</li>
        <li>Exposure bias - tend to sfavor already observed/interacted ited</li>
        <li>Position bias - users are likely to interaction top of list, regardless of relevance</li>
      </ul>
      <li>Explain how to consider ethics in recommendation system</li>
      <ul>
        <li>Mitigate bias</li>
        <li>Protect user privacy</li>
        <li>Provide fair recommendation</li>
        <li>Consider social impact</li>
      </ul>
      <li>Explain the effect of seasonality (Ex. changes in user behavior during different seasons)</li>
      <ul>
        <li>Reduced accuracy and poor generalization</li>
        <li>Take seaonality into account during feature engineering - month, day of week, time of day</li>
      </ul>
      <li>Explain how to optimize the system for multiple objectives, instead of a single objective</li>
      <ul>
        <li>Design cost function as weights sum of losses where each loss represents a separate objective</li>
      </ul>
      <li>Explain how to benefit from negative feedback (Ex. dislikes)</li>
      <ul>
        <li>Model can learn to avoid irrelevant itms</li>
      </ul>
      <li>Explain how to handel posts that are going viral</li>
      <ul>
        <li>Examine features (Ex. likes, shares, comments)</li>
        <li>Diverfiy from other recommendations</li>
        <li>Check harmfulness</li>
      </ul>
      <li>Explain how to personalize newsfeed for new users</li>
      <ul>
        <li>Popular feeds</li>
        <li>Onboarding survey</li>
        <li>Implicit feedback</li>
      </ul>
      <li>Explain how to mitigate positional bias</li>
      <ul>
        <li>Randomly shuffle orders of shown items</li>
        <li>Use position of item as feature</li>
      </ul>
      <li>Explain how to determine re-training frequency</li>
      <ul>
        <li>Watch data distribution change</li>
        <li>Watch model performance</li>
        <li>Start with varying frequencies and iterate</li>
      </ul>
      <li>Explain how to leverage the sequence of item in user's search history</li>
      <ul>
        <li></li>
      </ul>
      <li>Explain how to recommend reel</li>
      <ul>
        <li>What does a reel consist of? Image and video</li>
        <li>Should reels be personalized for each user? Yes</li>  
      </ul>
      <li>Explain how to enable search function</li>
      <ul>
        <li>What should search return? Reel in the order of relevance</li>
        <li>Should search result be personalized for each user? No</li>
      </ul>
      <li>Explain how to remove harmful posts</li>
      <ul>
        <li>Should the system remove harmful contents? Yes</li>
        <li>What kinds of posts are considered harmful? Violence, nudity, etc</li>
        <li>Should the system support multiple languages? Yes</li>
        <li>Should the system tell the user why a post is removed? Yes</li>
        <li>Should harmful posts be removed immediately? Depends on the degree of harmfulness</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu | Aman Chadha
  </div>
</div>
<!-- Instagram END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>