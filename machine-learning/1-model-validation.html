<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Model validation BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Model validation</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#model-validation-1">Bias and variance</a></li>
      <li><a href="#model-validation-2">Orthogonalization</a></li>
      <li><a href="#model-validation-3">Cross valdidation</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="model-validation-1">
  <div class="card-body">
    <h2 class="card-title">Bias and variance</h2>
    <ul>
      <li>Need to find right balance without overfitting or underfitting the data.</li>
    </ul>

    <h3 class="card-title">Bias</h3>
    <ul>
      <li>Train set error.</li>
      <li>How far off model prediction is from correct value.</li>
      <li>Error from approximately true underlying function.</li>
      <li>Difference between predicted and actual value.</li>
    </ul>

    <h3 class="card-title">Variance</h3>
    <ul>
      <li>Dev set error.</li>
      <li>Variability of model prediction for given data point.</li>
      <li>Sensitivity to changes in training data.</li>
      <li>Overfitting: model works well on training data, but doesn't generalize well on unseen data.</li>
    </ul>

    <h3 class="card-title">Ex. election survey</h3>
    <ul>
      <li>Surveying from a phonebook is source of bias.</li>
      <li>Small sample size is source of variance.</li>
    </ul>

    <h3 class="card-title">Tackle bias</h3>
    <ul>
      <li>Bigger network.</li>
      <li>Train longer.</li>
    </ul>

    <h3 class="card-title">Tackle variance</h3>
    <ul>
      <li>Get more data.</li>
      <li>Regularization.</li>
    </ul>

    <!-- <h3 class="card-title">Why human-level performance</h3>
    <ul>
      <li>While ML is worse than human, you can</li>
      <ul>
        <li>Get labeled data from human.</li>
        <li>Gain insight from manual error analysis. (why did a person get this right?)</li>
        <li>Better analysis of bias/variance.</li>
      </ul>
    </ul> -->

    <!-- <h3 class="card-title">Avoidable bias</h3>
    <ul>
      <li>Human error as a proxy for bays error.</li>
      <li>Gap between human and training error: avoidable bias.</li>
      <li>Gap between training and dev error: variance.</li>
    </ul> -->

    <!-- <h3 class="card-title">Two fundamental assumptions of supervised learning</h3>
    <ul>
      <li>You can fit the training set pretty well ~ avoidable bias.</li>
      <li>Training set performance generalizes pretty well to dev/test set ~ variance.</li>
      <li>Increasing lambda decrease variance. Decreasing lambda decrease bias.</li>
      <li>More features decrease bias but increases variance. Less features decreases variance but increases bias.</li>
    </ul> -->

    <!-- <h3 class="card-title">Approaches</h3>
    <ul>
      <li>Linear model</li>
      <ul>
        <li>Regularization is used to decrease variance at the cost of increasing bias.</li>
      </ul>
      <li>Neural network</li>
      <ul>
        <li>Variance increases and bias decreases with number of hidden units. Regularization is used.</li>
      </ul>
      <li>K-nearest neighbor</li>
      <ul>
        <li>High K leads to high bias and low variance.</li>
      </ul>
      <li>Decision tree</li>
      <ul>
        <li>Depth of trees increases variance. Trees are pruned to control variance.</li>
      </ul>
    </ul> -->
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/deep-learning?">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="model-validation-2">
  <div class="card-body">
    <h2 class="card-title">Orthogonalization</h2>
    <ul>
      <li>Models are trained on train set.</li>
      <ul>
      	<li>Bigger network.</li>
      	<li>Better optimization algorithm.</li>
      </ul>
      <li>Hyperpameters are selected on validation set.</li>
      <ul>
      	<li>Regularization.</li>
      	<li>Bigger training set.</li>
      	<li>As we do this, we are leaking information from validation set to training set. We may end up overfitting to validation data.</li>
      </ul>
      <li>Final evaluation is done on test set.</li>
      <ul>
      	<li>Bigger dev set.</li>
      	<li>Dev and test set must come from the same distribution!</li>
        <li>Test set may not be needed.</li>
      </ul>
      <li>Perform in real world.</li>
      <ul>
      	<li>Change dev set.</li>
      	<li>Change cost function.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="model-validation-3">
  <div class="card-body">
    <h2 class="card-title">Cross valdidation</h2>

    <h3 class="card-title">K-fold cross validation</h3>
    <ul>
    	<li>Separate data into parts. Select one set as validation and all other sets as training. Repeat this process for all sets.</li>
    	<li>Must not be used in time-series data.</li>
    	<li>k in practice should be 4-5.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://github.com/alexeygrigorev/data-science-interviews/blob/master/theory.md">Theoretical interview questions</a>
  </div>
</div>
<!-- Model validation END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>