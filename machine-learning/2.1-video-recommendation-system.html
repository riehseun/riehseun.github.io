<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Video recommendation system BEGIN -->
<div class="card mb-4" id="video-recommendation-system">
  <div class="card-body">
    <h2 class="card-title">Video recommendataion system</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#video-recommendation-system-1">Requirement</a></li>
      <li><a href="#video-recommendation-system-2">Problem</a></li>
      <li><a href="#video-recommendation-system-3">Data preparation</a></li>
      <li><a href="#video-recommendation-system-4">Model development</a></li>
      <li><a href="#video-recommendation-system-5">Evaluation</a></li>
      <li><a href="#video-recommendation-system-6">Deployment and serving</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-1">
  <div class="card-body">
    <h2 class="card-title">Requirement</h2>
    <ul>
      <li>Business objective</li>
      <ul>
        <li>What is the the purpose of the system? Increase user engagement</li>
        <li>What should the system show to users? Personalized list of videos</li>
        <li>Should the system support multiple languages? Yes</li>
      </ul>
      <li>System features</li>
      <ul>
        <li>Should the model use user-video interaction data? Yes</li>
        <li>Should the model use Youtube playlist data? No, playlist is out of scope</li>
      </ul>
      <li>Data</li>
      <ul>
        <li>Do we have training data available? No</li>
      </ul>
      <li>Constraints</li>
      <li>Scale</li>
      <ul>
        <li>How many videos are there on platform? 10B</li>
      </ul>
      <li>Performance</li>
      <ul>
        <li>How fast the recommendation service should be? under 200ms</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-2">
  <div class="card-body">
    <h2 class="card-title">Problem</h2>

    <h3 class="card-title">ML problem</h3>
    <ul>
      <li>Option 1. maximize the number of user clicks? No, the system may recommend clickbaits</li>
      <li>Option 2. maximize the number of completed videos? No, the system may only recommend short vidoes</li>
      <li>Option 3. maximize total watch time? Yes</li>
      <li>Option 4. maximize the number of relevant videos? Yes, the relevant videos could be of user likes or user watching at least half of it</li>
      <li>Input</li>
      <ul>
        <li>A user</li>
      </ul>
      <li>Output</li>
      <ul>
        <li>A list of videos sorted by relevance score</li>
      </ul>
    </ul>

    <h3 class="card-title">ML category</h3>
    <ul>
      <li>Supervised, recommendation system, embedding based</li>
      <ul>
        <li>Option 1. content-based filtering</li>
        <ul>
          <li>Uses video features</li>
          <li>Recommend new videos similar to those that were relevant to user in the past</li>
          <li>Pros</li>
          <ul>
            <li>No need to wait for user interaction data. Recommendation depends on video features only</li>
            <li>Captures unique interest of users</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Requires domain knowledge. Video features are often engineered manually</li>
            <li>Hard to discover users' new interest</li>
          </ul>
        </ul>
        <li>Option 2. collaborative filtering</li>
        <ul>
          <li>Assume similar users are interested in similar videos</li>
          <li>Uses user-user or video-video similarities to recommend new videos</li>
          <li>Uses users historical engagement only (No need to use video features)</li>
          <li>Pros</li>
          <ul>
            <li>No need for domain knowledge because videos features are not used</li>
            <li>Can discover users new interest</li>
            <li>Less compute intensive than content-based filtering</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Cold-start problem when lack of user interaction data</li>
            <li>Hard to capture unique interest of users</li>
          </ul>
        </ul>
        <li>Option 3. hybrid filtering</li>
        <ul>
          <li>Use collaborative filtering first, followed by content-based filtering</li>
          <li>Best option</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-3">
  <div class="card-body">
    <h2 class="card-title">Data preparation</h2>

    <h3 class="card-title">Data engineering</h3>
    <ul>
      <li>Training data</li>
      <ul>
        <li>User-video interaction</li>
        <ul>
          <li>For each pair of (user-related features represented by embedding, video-related features represented by embedding)</li>
          <ul>
            <li>Positive - if user likes video or watches at least half of it</li>
            <li>Negative - if user dislikes video or just pick random videos</li>
          </ul>
        </ul>
      </ul>
      <li>Database</li>
      <ul>
        <li>Video</li>
        <ul>
          <li>video_id</li>
          <li>length</li>
          <li>manual_tags</li>
          <li>manual_title</li>
          <li>likes</li>
          <li>views</li>
          <li>language</li>
        </ul>
        <li>User</li>
        <ul>
          <li>user_id</li>
          <li>username</li>
          <li>age</li>
          <li>gender</li>
          <li>city</li>
          <li>country</li>
          <li>language</li>
        </ul>
        <li>User-video interation</li>
        <ul>
          <li>user_id</li>
          <li>video_id</li>
          <li>interaction_type - like, impression, watch, search, comment</li>
          <li>timestamp</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Feature engineering</h3>
    <ul>
      <li>Video feature</li>
      <ul>
        <li>video_id - categorical data, embedding</li>
        <li>length</li>
        <li>language - categorical data, embedding</li>
        <li>manual_tags - CBOW for each tag and aggregate</li>
        <li>title - BERT</li>
      </ul>
      <li>User feature</li>
      <ul>
        <li>User demographics</li>
        <ul>
          <li>user_id - embedding</li>
          <li>age - bucketize + one-hot encoding</li>
          <li>gender - one-hot encoding</li>
          <li>language - embedding</li>
          <li>city - embedding</li>
          <li>country - embedding</li>
        </ul>
        <li>Contextual information</li>
        <ul>
          <li>day_of_week - embedding</li>
          <li>time_of_day - bucketize + one-hot encoding</li>
          <li>device - one-hot encoding</li>
        </ul>
        <li>User-historical interactions</li>
        <ul>
          <li>search_history - BERT to map each search query to embedding vector. Average the query embeddings to get a fixed-sized feature vector</li>
          <li>liked_videos - embedding layer to map video_ids to embedding vector</li>
          <li>watched_videos - embedding layer (Similar to liked_videos)</li>
          <li>impressions - embedding layer (Similar to liked_videos)</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-4">
  <div class="card-body">
    <h2 class="card-title">Model development</h2>

    <h3 class="card-title">Model selection</h3>
    <ul>
      <li>Option 1. matrix factorization</li>
      <ul>
        <li>Collaborative filtering method because only the user interaction data with video is used</li>
      </ul>
      <li>Option 2. two tower neural network</li>
      <ul>
        <li>Can utilize all of user features, video features, interaction data</li>
        <li>Can be used as for both collaborative filtering and content-based filtering</li>
      </ul>
    </ul>

    <h3 class="card-title">Model training</h3>
    <ul>
      <li>Option 1. matrix factorization</li>
      <ul>
        <li>Feedback matrix</li>
        <ul>
          <li>2D matrix mapping user and video where value of 1 means the user find the video relevant</li>
          <li>Relevancy can be defined using both explicit and implicit feedback</li>
          <li>Explicit feedback</li>
          <ul>
            <li>User likes or shares</li>
            <li>Data is sparse</li>
          </ul>
          <li>Implicit feedback</li>
          <ul>
            <li>User clicks or watch time</li>
            <li>Data might be noisy</li>
          </ul>
        </ul>
        <li>Matrix factorization model</li>
        <ul>
          <li>An embedding model</li>
          <li>Learns to map each user into embedding vector and each video into embedding vector such that their distance represents their relevance</li>
          <li>Decomposes feedback matric into two lower dimensional matrices, where one represents the user embedding and the other represents video embedding</li>
        </ul>
        <li>Matrix factorization training</li>
        <ul>
          <li>Randomly initializes two embedding matrices</li>
          <li>Mimimizes the loss between predicted scores matrix and feedback matrix</li>
          <ul>
            <li>Option 1. squared distance over observed user-video pairs</li>
            <ul>
              <li>\( \text{loss} = \displaystyle\sum_{(i,j) \in \text{obs}} (A_{ij}-U_{i}V_{j})^{2} \)</li>
              <li>Loss function does not penalize for bad prediction on unobserved pairs</li>
            </ul>
            <li>Option 2. squared distance over observed and unobserved user-video pairs</li>
            <ul>
              <li>\( \text{loss} = \displaystyle\sum_{(i,j)} (A_{ij}-U_{i}V_{j})^{2} \)</li>
              <li>Unobserved pairs dominate observed pairs during training because feedback matrix is sparce</li>
            </ul>
            <li>Option 3. weighted combination of squared distance over observed and unobserved user-video pairs</li>
            <ul>
              <li>\( \text{loss} = \displaystyle\sum_{(i,j) \in \text{obs}} (A_{ij}-U_{i}V_{j})^{2} + w\displaystyle\sum_{(i,j) \notin \text{obs}} (A_{ij}-U_{i}V_{j})^{2} \)</li>
              <li>\( w \) is a hyperparameter</li>
            </ul>
          </ul>
        </ul>
        <li>Matrix factorization optimization</li>
        <ul>
          <li>Weighted alternating least squares (WALS) - specific to matrix factorization</li>
          <ul>
            <li>Fix one embedding matrix \( U \) and optimize the other embedding matrix \( V \)</li>
            <li>Fix the other embedding matrix \( V \) and optimize the embedding matrix \( U \)</li>
            <li>Repeat</li>
          </ul>
        </ul>
        <li>Matrix factorization inference</li>
        <ul>
          <li>Take a dot product between user and video embeddings</li>
        </ul>
        <li>Pros</li>
        <ul>
          <li>Fast training because there are only two embedding matrices to learn</li>
          <li>Fast serving because learned embeddings are static</li>
        </ul>
        <li>Cons</li>
        <ul>
          <li>Only relies on user-video interactions, not using other features such as user age, language, etc</li>
          <li>Handling new users is difficult</li>
          <li>Model performance is lower</li>
        </ul>
      </ul>
      <li>Option 2. two tower neural network</li>
      <ul>
        <li>Loss function</li>
        <ul>
          <li>This is binary classification, thus use cross-entropy</li>
        </ul>
        <li>Inference</li>
        <ul>
          <li>Use ANN to find most relevant videos for a given user from their embeddings</li>
        </ul>
        <li>Pros</li>
        <ul>
          <li>Utilizes user features</li>
          <li>Capable of handling new users</li>
          <li>Model performance is higher</li>
        </ul>
        <li>Cons</li>
        <ul>
          <li>Slow serving having to compute user embeddings at query time</li>
          <li>Slow inference if using content-based filtering because model needs to tranform video features to video embeddings</li>
          <li>More learning paramaters, thus traning is more expensive</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>

    <h3 class="card-title">Offline</h3>
    <ul>
      <li>Precision@k</li>
      <ul>
        <li>\( \dfrac{\text{Number of relevant video in top k recommended videos}}{\text{top k recommended videos}} \)</li>
      </ul>
      <li>Mean average precision (mAP)</li>
      <ul>
        <li>Average of average precision across all object classes</li>
      </ul>
      <li>Diversity</li>
      <ul>
        <li>How dissimilar recommended videos are to each other</li>
        <li>Calculate average pairwise similarity (Ex. cosine similarity or dot product) between videos outputed by the model</li>
      </ul>
    </ul>

    <h3 class="card-title">Online</h3>
    <ul>
      <li>Click-through rate</li>
      <li>The number of completed videos</li>
      <li>Total watch time</li>
      <li>Explicit user feedback - for example, user likes and dislikes</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-6">
  <div class="card-body">
    <h2 class="card-title">Serving</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-1/video-recommendation-system1.png" alt="Card image cap">

    <ul>
      <li>Candidate generation</li>
      <ul>
        <li>Narrow down videos from billions to thousands</li>
        <li>Use model that does not rely on video feature for efficiency</li>
        <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-1/video-recommendation-system2.png" alt="Card image cap">
        <li>Two-tower neural network without video features (collaborative filtering) can be used to capture relevant videos</li>
        <li>Use additional candidate generations to capture popular and trending videos</li>
        <li>Then use content-based filtering to further narrow down the videos</li>
      </ul>
      <li>Ranking</li>
      <ul>
        <li>Takes user and candidate videos as input, scores each video, and outputs a ranked list of videos</li>
        <li>Accuracy is more important than efficiency</li>
        <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-1/video-recommendation-system3.png" alt="Card image cap">
        <li>Two-tower neural network using both user and video features can be used</li>
      </ul>
      <li>Re-ranking</li>
      <ul>
        <li>Filter out certain videos like misinformation, clickbait, violence, nudity, hates</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="video-recommendation-system-7">
  <div class="card-body">
    <h2 class="card-title">Follow up</h2>
    <ul>
      <li>Explain exploration-exploitation trade-off in recommendation system</li>
      <li>Explain bias that may be present in recommendation system</li>
      <li>Explain how to consider ethics in recommendation system</li>
      <li>Explain the effect of seasonality (Ex. changes in user behavior during different seasons)</li>
      <li>Explain how to optimize the system for multiple objectives, instead of a single objective</li>
      <li>Explain how to benefit from negative feedback (Ex. dislikes)</li>
      <li>Explain how to leverage the sequence of videos in user's search history or watch history</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>
<!-- Video recommendation system END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>