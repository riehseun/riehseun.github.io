<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine learning</h1>

<!-- Harmful content detection BEGIN -->
<div class="card mb-4" id="harmful-content-detection">
  <div class="card-body">
    <h2 class="card-title">Harmful content detection</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#harmful-content-detection-1">Clarify requirements</a></li>
      <li><a href="#harmful-content-detection-2">Frame problem as ML task</a></li>
      <li><a href="#harmful-content-detection-3">Data preparation</a></li>
      <li><a href="#harmful-content-detection-4">Model development</a></li>
      <li><a href="#harmful-content-detection-5">Evaluation</a></li>
      <li><a href="#harmful-content-detection-6">Deployment and serving</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="harmful-content-detection-1">
  <div class="card-body">
    <h2 class="card-title">Clarify requirements</h2>
    <ul>
      <li>Business objective</li>
      <ul>
        <li>Should the system detect both harmful contents and bad users? Harmful content only</li>
        <li>Does the post content only texts? Post can contain texts, images, videos, and any combination of those</li>
        <li>How many languages are supported? All languages. Assume we have a pre-trained multilingual model to embed textual context</li>
        <li>What kind of posts are considered harmful? Violence, nudity, hate speeach</li>
        <li>Should the system explain to the users why the post is considered harmful? Yes</li>
        <li>Should the system remove harmful contents immediately or can it do batch inference offline? Violent posts should be removed in real time while others can be removed after some time</li>
      </ul>
      <li>Features that the system supports</li>
      <ul>
        <li>Can users report harmful posts? Yes</li>
      </ul>
      <li>Data</li>
      <ul>
        <li>Do we have annotated dataset? Humans annotate 10k posts per day</li>
      </ul>
      <li>Constraints</li>
      <li>Scale</li>
      <li>Performance</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="harmful-content-detection-2">
  <div class="card-body">
    <h2 class="card-title">Frame problem as ML task</h2>
    <ul>
      <li>Define ML objective</li>
      <ul>
        <li>Accurately predict harmful posts</li>
      </ul>
      <li>Specify input and output</li>
      <ul>
        <li>Input - a post</li>
        <li>Output - probability that the post is harmful</li>
        <li>Late fusion</li>
        <ul>
          <li>Train, evaluate, improve each model independently</li>
          <li>Separate training data is needed for each model</li>
          <li>Combination of modalities might be harmful even though each is benign</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection1.png" alt="Card image cap">
        <li>Early fusion</li>
        <ul>
          <li>Single model to train, so there is no need to separate training dataset</li>
          <li>Model considers all modalities together (If each modality is benign but the combination is harmful, model can capture this in unified feature vector)</li>
          <li>Model needs to learn complex relationship between modalities, requiring large set of data</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection2.png" alt="Card image cap">
      </ul>
      <li>Choose right ML category</li>
      <ul>
        <li>Single binary classifier</li>
        <ul>
          <li>Difficult to tell users why the post is considered harmful</li>
          <li>Difficult to determine what kind of harmful content the post contains</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection3.png" alt="Card image cap">
        <li>One binary classifier per harmful class</li>
        <ul>
          <li>Multiple models must be trained separately</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection4.png" alt="Card image cap">
        <li>A multi-label classifier</li>
        <ul>
          <li>Each input feature may need to be transformed differently</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection5.png" alt="Card image cap">
        <li>Multi-task classifier</li>
        <ul>
          <li>Shared layers - transform input features into new ones</li>
          <li>Task specific layers - each classification head transforms features in optiaml way to predict a specific harm probability</li>
          <li>Single model is used, thus training is less expensive</li>
          <li>Shared layers transform features so that they are beneficial for each task. This prevents redundant computations</li>
          <li>Training data for each task contributes to learning other tasks</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection6.png" alt="Card image cap">
        <li>Final design</li>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection7.png" alt="Card image cap">
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="harmful-content-detection-3">
  <div class="card-body">
    <h2 class="card-title">Data preparation</h2>
    <ul>
      <li>Data engineering</li>
      <ul>
        <li>Users</li>
        <ul>
          <li>id</li>
          <li>username</li>
          <li>email</li>
        </ul>
        <li>Posts</li>
        <ul>
          <li>post_id</li>
          <li>author_id</li>
          <li>textual_content</li>
          <li>image_path,</li>
          <li>video_path</li>
        </ul>
        <li>User-post interations</li>
        <ul>
          <li>user_id</li>
          <li>post_id</li>
          <li>interaction_type (impression / like / comment / share / report)</li>
        </ul>
      </ul>
      <li>Feature engineering</li>
      <ul>
        <li>Textual content</li>
        <ul>
          <li>Text preprocessing</li>
          <li>Vectorization</li>
          <ul>
            <li>Statistical methods like BoW and TF-IDF cannot capture semantics</li>
            <li>BERT takes long time to produce text embeddings and is for english only</li>
            <li>DistlimBERT can be used here</li>
          </ul>
        </ul>
        <li>Image or video</li>
        <ul>
          <li>Preprocessing - decode, resize, normalize</li>
          <li>Feature extraction - convert unstructured data into feature vector</li>
          <ul>
            <li>Image - CLIP's visual encoder, SimCLR</li>
            <li>Video - VideoMoCo</li>
          </ul>
        </ul>
        <li>User interation to the post</li>
        <ul>
          <li>Number of likes, shares, comments, reports - scale these values to speed up convergence during training</li>
          <li>Comments</li>
        </ul>
        <li>Author features</li>
        <ul>
          <li>Author's violation history</li>
          <ul>
            <li>Number of violations</li>
            <li>Total user reports</li>
            <li>Profane word rate</li>
          </ul>
          <li>Author's demographics</li>
          <ul>
            <li>Age</li>
            <li>Gender - use one-hot encoding</li>
            <li>City and country - use embedding layer to represent these as feature vectors</li>
          </ul>
          <li>Account information</li>
          <ul>
            <li>Number of followers and followings</li>
            <li>Account age</li>
          </ul>
        </ul>
        <li>Contexual information</li>
        <ul>
          <li>Time of day - use one-hot encoding</li>
          <li>Device - use one-hot encoding</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection8.png" alt="Card image cap">
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="harmful-content-detection-4">
  <div class="card-body">
    <h2 class="card-title">Model development</h2>
    <ul>
      <li>Model selection</li>
      <ul>
        <li>Neural network</li>
        <li>Hyperparameter tuning with grid search</li>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Constructing dataset</li>
        <ul>
          <li>Human annotators - accurate but expensive. Used for evaluation dataset</li>
          <li>User reports - noisy but produced more quickly. Used for training dataset</li>
        </ul>
        <li>Choosing loss function</li>
        <ul>
          <li>In multi-task training, each task is assigned a loss function based on its ML category</li>
          <li>Since each task is binary classification, cross-entropy is used for each task</li>
        </ul>
        <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection9.png" alt="Card image cap">
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="harmful-content-detection-5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>
    <ul>
      <li>Offline</li>
      <ul>
        <li>PR curve</li>
        <ul>
          <li>Trade-off between precision and recall</li>
          <li>PR-AUC calculates area beneath PR curve</li>
          <li>High PR-AUC indicates more accurate model</li>
        </ul>
        <li>ROC curve</li>
        <ul>
          <li>Trade-off between true positive (recall) and false positive</li>
          <li>ROC-AUC calculates area beneath POC curve</li>
          <li>High ROC-AUC indicates more accurate model</li>
        </ul>
      </ul>
      <li>Online</li>
      <ul>
        <li>Prevalence</li>
        <ul>
          <li>Number of harmful posts / Total number of posts</li>
          <li>Treats all harmful posts equally</li>
          <li>Does not capture number of people affected by harmful posts</li>
        </ul>
        <li>Harmful impressions</li>
        <ul>
          <li>Better metric than prevalence</li>
        </ul>
        <li>Valid appeals</li>
        <ul>
          <li>Number of reversed appeals / Number of harmful posts detected by system</li>
        </ul>
        <li>Proactive rate</li>
        <ul>
          <li>Number of harmful posts detected by system / Number of harmful posts detected by system + reported by users</li>
        </ul>
        <li>User reports per harmful class</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="harmful-content-detection-6">
  <div class="card-body">
    <h2 class="card-title">Deployment and serving</h2>

    <img class="img-fluid" class="card-img-top" src="/img/machine-learning-system-design/harmful-content-detection10.png" alt="Card image cap">

    <h3 class="card-title">Harmful content detection service</h3>
    <ul>
      <li>Computes probability of posts being harmful</li>
    </ul>

    <h3 class="card-title">Violation enforcement service</h3>
    <ul>
      <li>Immediately takes down posts</li>
      <li>Notifies users why the post is taken down</li>
    </ul>

    <h3 class="card-title">Demotion service</h3>
    <ul>
      <li>Temporarily demotes posts to be reviewd by human</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>
<!-- Harmful content detection END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>