<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- ChatGPT BEGIN -->
<div class="card mb-4" id="chatgpt">
  <div class="card-body">
    <h2 class="card-title">ChatGPT</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#chatgpt-1">Requirement</a></li>
      <li><a href="#chatgpt-2">Problem</a></li>
      <li><a href="#chatgpt-3">Data preparation</a></li>
      <li><a href="#chatgpt-4">Model development</a></li>
      <li><a href="#chatgpt-5">Evaluation</a></li>
      <li><a href="#chatgpt-6">Serving</a></li>
      <li><a href="#chatgpt-7">Follow up</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="chatgpt-1">
  <div class="card-body">
    <h2 class="card-title">Requirement</h2>
    <ul>
      <li>Business objective</li>
      <ul>
        <li>Which languages should the system support? English only</li>
        <li>Should the system moderate contents? Yes</li>
        <li>Should the system support images and videos as input and output? No, text only</li>
        <li>Should the system support follow up questions? Yes, context window should be at least 4096</li>
        <li>Should the system browser website, call APIs? No</li>
        <li>Should the system be personalized to each user? No</li>
      </ul>
      <li>System features</li>
      <li>Data</li>
      <ul>
        <li>Do we have training data available? Yes, 80k examples of questions and answers</li>
      </ul>
      <li>Constraints</li>
      <li>Scale</li>
      <li>Performance</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="chatgpt-2">
  <div class="card-body">
    <h2 class="card-title">Problem</h2>

    <h3 class="card-title">ML problem</h3>
    <ul>
      <li>Generate texts based on prompt</li>
      <li>Input</li>
      <ul>
        <li>User prompt</li>
      </ul>
      <li>Output</li>
      <ul>
        <li>Response</li>
      </ul>
    </ul>

    <h3 class="card-title">ML category</h3>
    <ul>
      <li>Generative</li>
      <ul>
        <li>Transformer</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="chatgpt-3">
  <div class="card-body">
    <h2 class="card-title">Data preparation</h2>

    <h3 class="card-title">Data engineering</h3>
    <ul>
      <li>Training data</li>
      <ul>
        <li>General data from web</li>
        <ul>
          <li>Content extraction and parsing</li>
          <li>URL and domain filtering</li>
          <li>Language identification</li>
          <li>Content quality filtering</li>
        </ul>
        <li>General data from web, books, articles, social media</li>
        <ul>
          <li>Remove inappropriate content</li>
          <li>Mask sensitive information</li>
          <ul>
            <li>Ex. PII</li>
          </ul>
          <li>Remove low-quality data</li>
          <li>Remove duplicate data</li>
          <li>Remove irrelevant data</li>
          <ul>
            <li>Ex. non-standard characters</li>
          </ul>
          <li>Tokenized text</li>
        </ul>
      </ul>
      <li>Database</li>
    </ul>

    <h3 class="card-title">Feature engineering</h3>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="chatgpt-4">
  <div class="card-body">
    <h2 class="card-title">Model development</h2>

    <h3 class="card-title">Model selection</h3>
    <ul>
      <li>Decoder</li>
    </ul>

    <h3 class="card-title">Model training</h3>
    <ul>
      <li>Architecture</li>
      <ul>
        <li>Positional encoding</li>
        <ul>
          <li>Option 1. absolute</li>
          <ul>
            <li>Ex. sinusoidal, learnable</li>
            <li>Hard to generalize for sequences with different length</li>
          </ul>
          <li>Option 2. relative</li>
          <ul>
            <li>Encodes difference in the positions of two tokens</li>
          </ul>
          <li>Option 3. rotary (RoPE)</li>
          <ul>
            <li>Apply rotation matrix to token embedding</li>
          </ul>
        </ul>
      </ul>
      <li>Loss function</li>
      <ul>
        <li>Pre-training</li>
        <ul>
          <li>Train on general data that has English</li>
          <ul>
            <li>Example datasets - Common Crawl, C4, Github, Books, Wikipedia, ArXiv, Stack Exchange</li>
          </ul>
          <li>Objective is to predict next token</li>
          <li>Cross-entropy loss</li>
        </ul>
        <li>Fine-tuning</li>  
        <ul>
          <li>Train on pairs of prompt-response</li>
          <ul>
            <li>Example datasets - InstructGPT, Alpaca, Dolly-15K, FLAN 2022</li>
          </ul>
          <li>Objective is to predict next token</li>
          <li>Cross-entropy loss</li>
        </ul>
        <li>Reinforcement learning from human feedback (RLHF)</li>  
        <ul>
          <li>Make model generate responses preferred by human</li>
          <li>Train reward model</li>
          <ul>
            <li>Input - pair of prompt and response</li>
            <li>Output - score representing helpfulness of response for the prompt</li>
            <li>Copy model from fine-tuning and add a prediction head</li>
            <li>Training data</li>
            <ul>
              <li>Manually create a list of prompts</li>
              <li>Generate multiple responses for each prompt</li>
              <li>Rank responses</li>
              <li>Create preference pairs - (prompt, winning response, losing response)</li>
            </ul>
          </ul>
          <li>Optimize</li>
          <ul>
            <li>Proximal policy optimization (PPO)</li>
            <ul>
              <li>Update model weights to maximize score from reward model</li>
            </ul>
          </ul>
        </ul>
      </ul>
      <li>Hyperparameters</li>
      <li>Sampling</li>
      <ul>
        <li>Stochastic</li>
        <ul>
          <li>Multinomial</li>
          <ul>
            <li>Token is chosen based on probabilities of each token</li>
            <li>Randomness is too big, especially when probabilty distribution is flat</li>
          </ul>
          <li>Top k</li>
          <ul>
            <li>Sample from k most likely tokens rathen than from entire distribution</li>
            <li>If sharp distribution, model might miss the best choice resulting in non-sensical outputs</li>
            <li>If flat distribution, model may not consider enough word options</li>
          </ul>
          <li>Top p</li>
          <ul>
            <li>Adjust number of tokens to be considered based on their combined probabilities</li>
            <li>Consider smallest possible number of tokens whose cumulative probabily exceeds p</li>
          </ul>
        </ul>
        <li>Temperature</li>
        <ul>
          <li>Adjusted softmax with temperature - \( p_{i} = \dfrac{\text{exp}(\dfrac{x_{i}}{T})}{\displaystyle\sum_{j}^{n}\text{exp}(\dfrac{x_{i}}{T})} \)</li>
          <li>When T > 1, model generates more uniform probability distribution, making predictions more random</li>
          <li>When T < 1, predictions become more determinstic</li>
          <li>When T = 0, sampling becomes deterministic (always same output)</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="chatgpt-5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>

    <h3 class="card-title">Offline</h3>
    <ul>
      <li>Task specific</li>
      <ul>
        <li>Common-sense reasoning</li>
        <ul>
          <li>Ex. PIQA (Physical Interation QA), SIQA, HellaSwag, WinoGrande, OpenBookQA, CommonsenseQA</li>
        </ul>
        <li>World knowledge</li>
        <ul>
          <li>Ex. TriviaQA, NQ (Natural Questions), SQuAD (Stanford Question Answering Dataset)</li>
        </ul>
        <li>Reading comprehension</li>
        <ul>
          <li>Ex. SQuAD, QuAC, BoolQ</li>
        </ul>
        <li>Mathematical reasoning</li>
        <ul>
          <li>Ex. MATH, GSM8K (Grade School Math 8K)</li>
        </ul>
        <li>Code generation</li>
        <ul>
          <li>Ex. HumanEval, MBPP (MultiPL-E Benchmarks for Programming Problems)</li>
        </ul>
        <li>Composite benchmark</li>
        <ul>
          <li>Ex. MMLU (Massive Multitask Language Understanding), MMMU (Massive Multilingual Multitask Understanding), AGIEval, Meta Llama 3 human evaluation</li>
        </ul>
      </ul>
      <li>Safety</li>
      <ul>
        <li>Toxicity and Harmful content</li>
        <ul>
          <li>Ex. RealToxicityPrompts, ToxiGen, HateCheck</li>
        </ul>
        <li>Bias and fairness</li>
        <ul>
          <li>Ex. CrowS-Pairs, BBQ, BOLD</li>
        </ul>
        <li>Truthfulness</li>
        <ul>
          <li>Ex. TruthfulQA</li>
        </ul>
        <li>User privacy and data leakage</li>
        <ul>
          <li>Ex. PrivacyQA</li>
        </ul>
        <li>Adversarial robustness</li>
        <ul>
          <li>Ex. AdvGLUE, TextFooler, AdvBench</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Online</h3>
    <ul>
      <li>User engagement</li>
      <li>Conversion rate</li>
      <li>Online leaderboards</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="chatgpt-6">
  <div class="card-body">
    <h2 class="card-title">Serving</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-2/chatgpt-1.png" alt="Card image cap">

    <ul>
      <li>Safety filtering</li>
      <ul>
        <li>Detect harmful, inappropriate, unsafe quries</li>
      </ul>
      <li>Prompt enhancer</li>
      <ul>
        <li>Expand acrynyms, correct spelling mistakes, add additional context</li>
      </ul>
      <li>Response generator</li>
      <ul>
        <li>Uses top-p sampling to generate response</li>
      </ul>
      <li>Response safety evaluator</li>
      <li>Rejection response generator</li>
      <li>Session management</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="chatgpt-7">
  <div class="card-body">
    <h2 class="card-title">Follow up</h2>
    <ul>
      <li>Explain how to manage dialogue and transfer contexts</li>
      <li>Explain how to do multi-token prediction</li>
      <li>Explain how to handle very long sequence length</li>
      <li>Explain how to develop multimodal LLM</li>
      <li>Explain how to use distillation for faster text generation</li>
      <li>Explain how to fine-tune LLM for specific task without forgetting previous knowledge</li>
      <li>Explain how to address privacy and security concerns in LLM</li>
      <li>Explain PPO, DPO, rejection sampling</li>
      <li>Explain how to reduce harmfulness in LLM</li>
      <li>Explain in-context learning</li>
      <li>Explain grouped query attention</li>
      <li>Explain how to implement KV cache</li>
      <li>Explain how to produce clear and verifiable justification for model ouputs</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>
<!-- ChatGPT END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>