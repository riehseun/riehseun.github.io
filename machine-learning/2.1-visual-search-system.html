<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Visual search system BEGIN -->
<div class="card mb-4" id="visual-search-system">
  <div class="card-body">
    <h2 class="card-title">Visual search system</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#visual-search-system-1">Requirement</a></li>
      <li><a href="#visual-search-system-2">Problem</a></li>
      <li><a href="#visual-search-system-3">Data preparation</a></li>
      <li><a href="#visual-search-system-4">Model development</a></li>
      <li><a href="#visual-search-system-5">Evaluation</a></li>
      <li><a href="#visual-search-system-6">Serving</a></li>
      <li><a href="#visual-search-system-7">Follow up</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="visual-search-system-1">
  <div class="card-body">
    <h2 class="card-title">Requirement</h2>
    <ul>
      <li>Business objective</li>
      <ul>
        <li>What is the the purpose of the system? Given an image, return similar images</li>
        <li>Should the images be ranked from most similar to least similar? Yes</li>
        <li>Should the system support videos? No</li>
        <li>Should the images be personalized to each user? No</li>
        <li>Should the images be moderated? No</li>
      </ul>
      <li>System features</li>
      <ul>
        <li>Should the model use image metadata? No, only the pixels are used</li>
        <li>Can users like, share, save images? No, only supported action is image clicks</li>
      </ul>
      <li>Data</li>
      <ul>
        <li>Do we have training data available? No</li>
        <li>Should we label the data based on user interaction? Yes</li>
      </ul>
      <li>Constraints</li>
      <ul>
        <li></li>
      </ul>
      <li>Scale</li>
      <ul>
        <li>How many images are there? 100-200B</li>
      </ul>
      <li>Performance</li>
      <ul>
        <li>How fast should the search be? Reasonably fast</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="visual-search-system-2">
  <div class="card-body">
    <h2 class="card-title">Problem</h2>

    <h3 class="card-title">ML problem</h3>
    <ul>
      <li>Retrieve images that are similar to the image that user provided</li>
      <li>Input</li>
      <ul>
        <li>Image provided by user</li>
      </ul>
      <li>Output</li>
      <ul>
        <li>Images that are similar to input image</li>
        <li>Output images are ranked by similarity score</li>
      </ul>
    </ul>

    <h3 class="card-title">ML category</h3>
    <ul>
      <li>Supervised, ranking problem, representation learning</li>
      <ul>
        <li>Learn embeddings of images such that</li>
        <ul>
          <li>Similar images are close</li>
          <li>Dissimilar images are far</li>
        </ul>
        <li>Input images are transformed into embedding vector</li>
        <li>Distance between input image and other images are computed to output similarity score</li>
        <li>Images are then ranked by similarity score</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="visual-search-system-3">
  <div class="card-body">
    <h2 class="card-title">Data preparation</h2>

    <h3 class="card-title">Data engineering</h3>
    <ul>
      <li>Training data</li>
      <ul>
        <li>Option 1. human label</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>Less noisy</li>
            <li>Reflects real data</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Expensive</li>
            <li>Time consuming</li>
          </ul>
        </ul>
        <li>Option 2. user interaction</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>No extra cost</li>
            <li>Data is auto generated</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Data can be noisy due to user misclicks</li>
            <li>Data can be sparce since lots of images may not have click data</li>
          </ul>
        </ul>
        <li>Option 3. self-supervision</li>
        <ul>
          <li>Ex. SimCLR, MoCo</li>
          <li>Pros</li>
          <ul>
            <li>Not expensive</li>
            <li>Data is not noisy</li>
            <li>Lots of data can be generated</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Constructed images differ from real data</li>
          </ul>
        </ul>
        <li>We choose option 3 as main source of data since this is least expensive and fast</li>
      </ul>
      <li>Database</li>
      <ul>
        <li>We use the following tables to keep user interaction data</li>
        <li>Image</li>
        <ul>
          <li>image_id</li>
          <li>owner_id</li>
          <li>upload_time</li>
          <li>manual_tags</li>
        </ul>
        <li>User</li>
        <ul>
          <li>user_id</li>
          <li>username</li>
          <li>email</li>
          <li>age</li>
          <li>gender</li>
          <li>city</li>
          <li>country</li>
        </ul>
        <li>Image-user interaction</li>
        <ul>
          <li>user_id</li>
          <li>input_image_id</li>
          <li>displayed_image_id</li>
          <li>rank_of_displayed_image</li>
          <li>interaction - impression, click</li>
          <li>timestamp</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Feature engineering</h3>
    <ul>
      <li>Image</li>
      <ul>
        <li>Resize - models require fixed-sized images</li>
        <li>Scale - pixel values should be between 0 and 1</li>
        <li>Standardization - pixel values should have mean 0 and variance 1</li>
        <li>Color mode - pick either RGB or CMYK</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="visual-search-system-4">
  <div class="card-body">
    <h2 class="card-title">Model development</h2>

    <h3 class="card-title">Model selection</h3>
    <ul>
      <li>Neural network</li>
      <ul>
        <li>Good at handling unstructured data like images</li>
        <li>Can produce embeddings of images</li>
        <li>Option 1. ResNet</li>
        <ul>
          <li>Able to construct very deep neural network</li>
          <li>Skip connections make model very robust against issues like vanishing gradient</li>
          <li>Training cost is cheaper than transformer based models</li>
        </ul>
        <li>Option 2. ViT</li>
        <ul>
          <li>Generalize well with a wide range of image data</li>
          <li>Excels in transfer learning</li>
          <li>Can make accurate predictions with very limited training examples</li>
          <li>Better accuracy than convolutional neural network</li>
        </ul>
        <li>Use contrastive learning</li>
        <ul>
          <li>An input image</li>
          <li>One similar image to the input image (Positive or ground truth)</li>
          <ul>
            <li>Image must be constructed</li>
          </ul>
          <li>Few dissimilar images from the input image (Negative)</li>
          <ul>
            <li>Images can be randomly selected</li>
          </ul>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Model training</h3>
    <ul>
      <li>Loss function</li>
      <ul>
        <li>Constrastive loss function</li>
        <ul>
          <li>Dot product or cosine similarity is used to compute distances in embedding space</li>
          <ul>
            <li>Euclidean distance is not used due to curse of dimensionality</li>
          </ul>
          <li>Softmax is applied to distances to make them sum to 1</li>
          <li>Cross-entropy is used to measure how close the probabilities are to the ground truth</li>
        </ul>
      </ul>
      <li>Hyperparameters</li>
      <ul>
        <li>Number of convolutional layers</li>
        <li>Number of neurons in fully connected layers</li>
        <li>Size of embedding vector</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="visual-search-system-5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>

    <h3 class="card-title">Offline</h3>
    <ul>
      <li>Option 1. precision@k</li>
      <ul>
        <li>\( \dfrac{\text{Number of relevant items in the output list (contaning top k items)}}{\text{k}} \)</li>
        <li>Cons</li>
        <ul>
          <li>Does not consider ranking quality</li>
        </ul>
      </ul>
      <li>Option 2. recall@k</li>
      <ul>
        <li>\( \dfrac{\text{Number of relevant items in the output list (contaning top k items)}}{\text{total relevant items in the dataset}} \)</li>
        <li>Cons</li>
        <ul>
          <li>Does not consider ranking quality</li>
          <li>Denominator can be very big, which negatively impacts recall value</li>
        </ul>
      </ul>
      <li>Option 3. mean reciprobal rank (MRR)</li>
      <ul>
        <li>\( MRR = \dfrac{1}{m} \displaystyle\sum_{i=1}^{m} \dfrac{1}{\text{rank}_{i}} \)</li>
        <ul>
          <li>\( {\text{rank}_{i}} \) is position on which the first relevant item appears in the output list</li>
        </ul>
        <li>Consider only the first relevant item in each output list, then average the reciprocal rank</li>
        <li>Cons</li>
        <ul>
          <li>Ignores other relevant items in the list other than the first one</li>
        </ul>
      </ul>
      <li>Option 4. mean average precision (mAP)</li>
      <ul>
        <li>AP</li>
        <ul>
          <li>\( AP = \dfrac{\displaystyle\sum_{i=1}^{k} \text{precision}@i}{n} \)</li>
          <ul>
            <li>\( n = \) total relevant items</li>
          </ul>
          <li>Averages precision@k at different values of k</li>
          <li>AP is high if more relevant items are located at the top of list</li>
        </ul>
        <li>mAP</li>
        <ul>
          <li>Compute AP for each output list, then average them</li>
        </ul>
        <li>Cons</li>
        <ul>
          <li>Works well when each item is either relevant or irrelevant, but does not work well for relevance scores</li>
        </ul>
      </ul>
      <li>Option 5. normalized discounted cumulative gain (nDCG)</li>
      <ul>
        <li>\( DCG_{p} = \displaystyle\sum_{i=1}^{p} \dfrac{\text{rel}_{i}}{log_{2}(i+1)} \)</li>
        <ul>
          <li>\( \text{rel}_{i} \) is ground truth relevance score of image ranked at \( i \)</li>
        </ul>
        <li>\( nDCG_{p} = \dfrac{DCG_{p}}{IDCG_{p}} \)</li>
        <ul>
          <li>where \( {IDCG_{p}} \) is \( {DCG_{p}} \) of ideal ranking</li>
        </ul>
        <li>Example</li>
        <ul>
          <li>Assume visual search system return images \( I1, I2, I3, I4 \) in the order of relevance</li>
          <li>Assume human rates the images on scale of \( 0 \) to \( 3 \) such that \( I1=3, I2=2, I3=3, I4=0 \) (\( 3 \) is highly relevant, \( 0 \) is merely relevant)</li>
          <li>\( DCG_{p} = \frac{3}{log(1+1)} + \frac{2}{log(2+1)} + \frac{3}{log(3+1)} + \frac{0}{log(4+1)} = 3 + 1.262 + 1.5 + 0 = 5.762 \)</li>
        </ul>
        <li>Cons</li>
        <ul>
          <li>nDCG does not penalize irrelevant search result</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Online</h3>
    <ul>
      <li>Click-through rate (CTR)</li>
      <ul>
        <li>\( \dfrac{\text{number of clicked images}}{\text{total number of suggested images}} \)</li>
      </ul>
      <li>Average daily/weekly/monthly time spent on suggested images</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="visual-search-system-6">
  <div class="card-body">
    <h2 class="card-title">Serving</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-1/visual-search-system1.png" alt="Card image cap">

    <ul>
      <li>Indexing pipeline</li>
      <ul>
        <li>Object storage</li>
        <ul>
          <li>Stores new images</li>
        </ul>
        <li>Indexing service</li>
        <ul>
          <li>Indexes the embeddings of new images so that NN search can easily find it</li>
        </ul>
        <li>Index table</li>
        <ul>
          <li>Stores images embeddings in sorted order</li>
        </ul>
      </ul>
      <li>Prediction pipeline</li>
      <ul>
        <li>Embedding generation service</li>
        <ul>
          <li>Preprocess the input images and use trained model to determine its embedding</li>
        </ul>
        <li>Nearest neighbor service</li>
        <ul>
          <li>Retrieve similar images from embedding space</li>
          <li>Option 1. exact NN</li>
          <ul>
            <li>Time \( \text{O}(ND) \) where \( N \) is total number of points and \( D \) is dimension</li>
            <li>\( N \) could be billions</li>
          </ul>
          <li>Option 2. approximate NN</li>
          <ul>
            <li>Time \( \text{O}(\text{log}(N)D) \)</li>
            <li>Option 1. tree-based</li>
            <ul>
              <li>Similar to gradient boosted tree</li>
              <li>Ex. R-trees, Kd-trees, Annoy (Approximate Nearest Neighbor Oh Yeah)</li>
            </ul>
            <li>Option 2. locality sensitive hashing (LSH)</li>
            <ul>
              <li>Use hash function to reduce the dimensions of points and group them into buckets</li>
              <li>Maps points in close proximity to same bucket</li>
              <li>LSH searches only those points in the same bucket</li>
            </ul>
            <li>Option 3. clustering-based</li>
            <ul>
              <li>Group points based on simiarities</li>
              <li>Algorithm only searches the subset of points in the cluster</li>
            </ul>
          </ul>
          <li>Due to algorithm runtime, we choose ANN</li>
        </ul>
        <li>Re-ranking service</li>
        <ul>
          <li>Filters inappropriate results, removes duplicates, etc</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="visual-search-system-7">
  <div class="card-body">
    <h2 class="card-title">Follow up</h2>
    <ul>
      <li>Explain how to moderate images</li>
      <li>Explain how to handle bias? (Ex. positional bias)</li>
      <li>Explain how to use metadata (Ex. tags) to improve search result</li>
      <li>Explain smart crop using object detection</li>
      <li>Explain how to use GNN to learn better representation</li>
      <li>Explain how to search images using text</li>
      <li>Explain how to use active learning or human-in-the-loop ML to annotate data more efficiently</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>
<!-- Visual search system END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>