<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Optimization BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Optimization</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#optimization-">Vanishing/exploding gradients</a></li>
      <li><a href="#optimization-">Gradient checking</a></li>
      <li><a href="#optimization-">Gradient descent</a></li>
      <li><a href="#optimization-">Gradient optimization</a></li>
      <li><a href="#optimization-">Learning rate decay</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="optimization-">
  <div class="card-body">
    <h2 class="card-title">Vanishing/exploding gradients</h2>
    <ul>
      <li>Happens in deep neural network</li>
      <li>If \( \textbf{W}^{[l]} \) is slighly bigger than identity matrix \( \textbf{I} \), gradients will blow up as the number of layers increases</li>
      <ul>
        <li>For example, \( 1.1^{L} \)</li>
      </ul>
      <li>If \( \textbf{W}^{[l]} \) is slighly smaller than identity matrix \( \textbf{I} \), gradients will diminish as the number of layers increases</li>
      <ul>
        <li>For example, \( 0.9^{L} \)</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="optimization-">
  <div class="card-body">
    <h2 class="card-title">Gradient checking</h2>
    <ul>
      <li>Take \( \textbf{W}^{[1]}, \textbf{b}^{[1]} \dots \textbf{W}^{[L]}, \textbf{b}^{[L]} \) and reshape into a big vector \( \theta \)</li>
      <li>Take \( \textbf{dW}^{[1]}, \textbf{db}^{[1]} \dots \textbf{dW}^{[L]}, \textbf{db}^{[L]} \) and reshape into a big vector \( d\theta \)</li>
      <li>For each \( i \)</li>
      <ul>
        <li>\( d\theta_{approx} = \dfrac{J(\theta_{1} \dots \theta_{i} + \epsilon) - J(\theta_{1} \dots \theta_{i} - \epsilon)}{2\theta} \approx \dfrac{\partial J}{\partial \theta_{i}} \) where \( \epsilon = 10^{-7} \) and compare it against \( d\theta_{i} \)</li>
        <li>\( \dfrac{||d\theta_{approx}-d\theta||_{2}}{||d\theta_{approx}||_{2} + ||d\theta||_{2}} \approx 10^{-7} \) is good</li>
        <li>Bigger than \( 10^{-3} \) means something wrong</li>
      </ul>
      <li>Do not use gradient checking during training, only use it when debugging</li>
      <li>Include regularization term in \( d\theta \) calculation</li>
      <li>Gradient checking does not work with dropout</li>
      <ul>
        <li>Can do gradient checking with <code>keep_prop=1.0</code>, then later turn on dropout</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="optimization-">
  <div class="card-body">
    <h2 class="card-title">Gradient descent</h2>
    <ul>
      <li>Find values of parameters of function that minimize a cost function</li>
      <li>Used when parameters cannot be calculated analytically</li>
      <li>Take negative of gradients of a function at a point</li>
      <li>Repeatedly update that point until reaching an optimal point</li>
      <li>Error - difference between actual and predicted</li>
      <li>Loss - some aggregation of errors</li>
      <li>Learning rate-  size of steps you want to take in particular direction</li>
      <ul>
        <li>Updated location = previous location + step size * number of steps</li>
        <li>Updated value = previous value - learning rate * gradient</li>
      </ul>
    </ul>

    <h3 class="card-title">Batch</h3>
    <ul>
      <li>Run through all samples to do single update of parameters</li>
      <li>Used when training set is small (Less than 2,000)</li>
    </ul>

<pre><code class="python">for t in range(steps):
    dw = gradient(loss, data, w)
    w = w - learning_rate * dw</code></pre>

    <h3 class="card-title">Min-batch</h3>
    <ul>
      <li>Run through subset of samples to do single update of parameters</li>
      <li>Subsets of both inputs and labelled outputs</li>
      <li>Typically, min-batch size is 64, 128, 256, 512</li>
      <li>Make sure each mini-batch \( \textbf{X}^{[t]}, \textbf{y}^{[t]} \) fits in CPU/GPU memory</li>
    </ul>

    <h4 class="card-title">How to get min-batches</h4>
    <ul>
      <li>Shuffle the training set \( \textbf{X} \) and \( \textbf{y} \)</li>
      <li>Partition the shuffled set into min-batches</li>
    </ul>

<pre><code class="python">def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):

    np.random.seed(seed)
    m = X.shape[1]  # Number of training examples
    mini_batches = []

    # Shuffle
    permutation = list(np.random.permutation(m))
    shuffled_X = X[:, permutation]
    shuffled_Y = Y[:, permutation].reshape((1,m))

    # Partition (Minus the end case)
    num_complete_minibatches = math.floor(m/mini_batch_size)
    for k in range(0, num_complete_minibatches):
        mini_batch_X = shuffled_X[:, k*mini_batch_size:(k+1)*mini_batch_size]
        mini_batch_Y = shuffled_Y[:, k*mini_batch_size:(k+1)*mini_batch_size]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)

    # Handling the end case
    if m % mini_batch_size != 0:
        mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size:m]
        mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size:m]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)

    return mini_batches</code></pre>

    <h4 class="card-title">Implementation</h4>
    <ul>
      <li>In one epoc, min-batch gradient descent take \( nb \) gradient descents rather than 1 </li>
      <li>Let <code>num_epocs</code> \( = ne \)</li>
      <li>Let <code>batch_size</code> \( = bs \)</li>
      <li>Let <code>num_batches</code> \( = nb \)</li>
      <li>for \( t = 1 \dots ne \)</li>
      <ul>
        <li>for \( t = 1 \dots nb \)</li>
        <ul>
          <li>Forward prop on \( \textbf{X}^{\{t\}} \)</li>
          <ul>
            <li>\( \textbf{Z}^{[1]} = \textbf{W}^{[1]}\textbf{X}^{\{t\}} + \textbf{b}^{[1]} \)</li>
            <li>\( \textbf{A}^{[1]} = g^{[1]}(\textbf{Z}^{[1]}) \)</li>
            <li>\( \vdots \)</li>
            <li>\( \textbf{A}^{[L]} = g^{[L]}(\textbf{Z}^{[L]}) \)</li>
          </ul>
          <li>Compute cost</li>
          <ul>
            <li>\( J^{\{t\}} = \dfrac{1}{bs}\displaystyle\sum_{i=1}^{l}L(\hat{y}^{(i)}, y^{(i)}) + \dfrac{\lambda}{2bs}\displaystyle\sum_{l}||\textbf{W}^{[l]}||_{F}^{2} \)</li>
          </ul>
          <li>Backward prop</li>
          <ul>
            <li>Use \( J^{\{t\}}, \textbf{X}^{\{t\}}, \textbf{y}^{\{t\}} \)</li>
          </ul>
          <li>Update parameter</li>
          <ul>
            <li>\( \textbf{W}^{[l]} = \textbf{W}^{[l]} - \alpha \textbf{dW}^{[l]} \)</li>
            <li>\( \textbf{b}^{[l]} = \textbf{b}^{[l]} - \alpha \textbf{db}^{[l]} \)</li>
          </ul>
        </ul>
      </ul>
    </ul>

<pre><code class="python">for t in range(steps):
    for mini_batch in get_batches(data, batch_size):
        dw = gradient(loss, mini_batch, w)
        w = w - learning_rate * dw</code></pre>

    <h3 class="card-title">Stochastic</h3>
    <ul>
      <li>Run through one sample to do single update of parameters</li>
    </ul>

<pre><code class="python">for t in range(steps):
    for example in data:
        dw = gradient(loss, example, w)
        w = w - learning_rate * dw</code></pre>

    <h3 class="card-title">Local optima</h3>
    <ul>
      <li>In high dimensions, when gradient is 0, it is almost always saddle points rather than local optima (So it is unlikely for the optimization algorithm to stuck at bad local optima)</li>
      <li>Plateaus (where derivatives are close to 0) can slow down the learning</li>
    </ul>

<pre><code class="python">import torch
import torch.nn as nn

def train():

    model = nn.Linear(4,2)

    criterion = torch.nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)

    for epoch in range(10):
        # Convert inputs and labels to variable.
        inputs = torch.Tensor([0.8,0.4,0.4,0.2])
        labels = torch.Tensor([1,0])

        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward.
        optimizer.zero_grad()

        # Get output from the model from the inputs.
        outputs = model(inputs)

        # Get loss for the predicted output.
        loss = criterion(outputs, labels)
        print(loss)

        # Get gradients w.r.t to parameters.
        loss.backward()

        # Update parameters.
        optimizer.step()

        print('epoch {}, loss {}'.format(epoch, loss.item()))

if __name__ == "__main__":
    train()</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> | <a href="https://www.educative.io/path/become-a-deep-learning-professional">Become a Deep Learning Professional</a>
  </div>
</div>

<div class="card mb-4" id="optimization-">
  <div class="card-body">
    <h2 class="card-title">Gradient optimization</h2>

    <h3 class="card-title">Exponentially weighted averages (Moving average)</h3>
    <ul>
      <li>\( v_{t} = \beta v_{t-1} + (1-\beta) \theta_{t-1} \)</li>
      <li>\( v_{t} \) is approximately averaging over \( \frac{1}{\beta-1} \) data points.</li>
      <li>To improve initial phase of estimates, use \( \frac{v_{t}}{1-\beta} \). However, in ML, we don't usually bother with bias in the initial phase</li>
    </ul>

    <h3 class="card-title">Momentum</h3>
    <ul>
      <li>On vertical axis, we want slower learning & reduce oscilation ( \( \textbf{b} \) direction )</li>
      <li>But on horizontal axis, we want faster learning ( \( \textbf{W} \) direction )</li>
      <li>Initialize \( \textbf{V}_{dW} = \textbf{V}_{db} = 0 \)</li>
      <li>On each iteration \( t \)</li>
      <ul>
        <li>Compute \( \textbf{dW} \) and \( \textbf{db} \)</li>
        <li>\( \textbf{V}_{dW} = \beta \textbf{V}_{dW} + (1-\beta) \textbf{dW} \)</li>
        <li>\( \textbf{V}_{db} = \beta \textbf{V}_{db} + (1-\beta) \textbf{db} \)</li>
        <li>\( \textbf{W} = \textbf{W} - \alpha \textbf{V}_{dW} \)</li>
        <li>\( \textbf{b} = \textbf{b} - \alpha \textbf{V}_{db} \)</li>
        <li>\( \beta \) is commonly chosen to be \( 0.9 \)</li>
      </ul>
      <li>On vertical direction, the derivates will average out to zero</li>
      <li>Velocity is the running mean of gradients including the direction</li>
      <li>At every step, update velocity, then update weights with the velocity</li>
    </ul>

<pre><code class="python">def initialize_velocity(parameters):

    L = len(parameters) // 2  # Number of layers in the neural networks
    v = {}

    # Initialize velocity
    for l in range(L):
        v["dW" + str(l+1)] = np.zeros((parameters["W" + str(l+1)].shape[0], parameters["W" + str(l+1)].shape[1]))
        v["db" + str(l+1)] = np.zeros((parameters["b" + str(l+1)].shape[0], parameters["b" + str(l+1)].shape[1]))

    return v</code></pre>

<pre><code class="python">def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):

    L = len(parameters) // 2  # Number of layers in the neural networks

    for l in range(L):
        v["dW" + str(l+1)] = beta * v["dW" + str(l+1)] + (1- beta) * grads["dW" + str(l+1)]
        v["db" + str(l+1)] = beta * v["db" + str(l+1)] + (1- beta) * grads["db" + str(l+1)]
        parameters["W" + str(l+1)] = parameters["W" + str(l+1)] - learning_rate * v["dW" + str(l+1)]
        parameters["b" + str(l+1)] = parameters["b" + str(l+1)] - learning_rate * v["db" + str(l+1)]

    return parameters, v</code></pre>

<pre><code class="python">for t in range(steps):
    dw = gradient(loss, w)
    v = beta * v + (1-beta) * dw
    w = w - learning_rate * v</code></pre>

    <h3 class="card-title">RMSprop</h3>
    <ul>
      <li>RMSprop has the same motivation as momentum</li>
      <li>Initialize \( \textbf{S}_{dW} = \textbf{S}_{db} = 0 \)</li>
      <li>On each iteration \( t \)</li>
      <ul>
        <li>Compute \( \textbf{dW} \) and \( \textbf{db} \)</li>
        <li>\( \textbf{S}_{dW} = \beta \textbf{S}_{dW} + (1-\beta) \textbf{dW}^{2} \) (Square is applied to element-wise)</li>
        <li>\( \textbf{S}_{db} = \beta \textbf{S}_{db} + (1-\beta) \textbf{db}^{2} \) (Square is applied to element-wise)</li>
        <li>\( \textbf{W} = \textbf{W} - \alpha \frac{\textbf{dW}}{\sqrt{\textbf{S}_{dW}}+\epsilon} \)</li>
        <li>\( \textbf{b} = \textbf{b} - \alpha \frac{\textbf{db}}{\sqrt{\textbf{S}_{db}}+\epsilon} \)</li>
        <li>\( \epsilon \) is in order not to divide by zero</li>
      </ul>
      <li>We want small \( \textbf{S}_{dW} \) and large \( \textbf{S}_{db} \)</li>
    </ul>

<pre><code class="python">for t in range(steps):
    dw = gradient(loss, w)
    squared_gradients = beta * squared_gradients + (1-beta) * dw * dw
    w = w - learning_rate * (dw/(squared_gradients.sqrt()+e)</code></pre>

    <h3 class="card-title">Adam (Adaptive moment estimation)</h3>
    <ul>
      <li>Initialize \( V_{dW} = V_{db} = S_{dW} = S_{db} = 0 \)</li>
      <li>On each iteration \( t \)</li>
      <ul>
        <li>Compute \( dW \) and \( db \)</li>
        <li>\( V_{dW} = \beta_{1} V_{dW} + (1-\beta_{1}) dW \)</li>
        <li>\( V_{db} = \beta_{1} V_{db} + (1-\beta_{1}) db \)</li>
        <li>\( S_{dW} = \beta_{2} S_{dW} + (1-\beta_{2}) dW^{2} \)</li>
        <li>\( S_{db} = \beta_{2} S_{db} + (1-\beta_{2}) db^{2} \)</li>
        <li>\( V_{dW, corrected} = \dfrac{V_{dW}}{1-\beta_{1}^{t}} \)</li>
        <li>\( V_{db, corrected} = \dfrac{V_{db}}{1-\beta_{1}^{t}} \)</li>
        <li>\( S_{dW, corrected} = \dfrac{S_{dW}}{1-\beta_{2}^{t}} \)</li>
        <li>\( S_{db, corrected} = \dfrac{S_{db}}{1-\beta_{2}^{t}} \)</li>
        <li>\( W = W - \alpha \dfrac{V_{dW, corrected}}{\sqrt{S_{dW, corrected}}+\epsilon} \)</li>
        <li>\( b = b - \alpha \dfrac{V_{db, corrected}}{\sqrt{S_{db, corrected}}+\epsilon} \)</li>
        <li>\( \beta_{1} \) is commonly chosen to be \( 0.9 \)</li>
        <li>\( \beta_{2} \) is commonly chosen to be \( 0.999 \)</li>
      </ul>
    </ul>

<pre><code class="python">def initialize_adam(parameters):

    L = len(parameters) // 2  # Number of layers in the neural networks
    v = {}
    s = {}

    for l in range(L):
        v["dW" + str(l+1)] = np.zeros((parameters["W" + str(l+1)].shape[0], parameters["W" + str(l+1)].shape[1]))
        v["db" + str(l+1)] = np.zeros((parameters["b" + str(l+1)].shape[0], parameters["b" + str(l+1)].shape[1]))
        s["dW" + str(l+1)] = np.zeros((parameters["W" + str(l+1)].shape[0], parameters["W" + str(l+1)].shape[1]))
        s["db" + str(l+1)] = np.zeros((parameters["b" + str(l+1)].shape[0], parameters["b" + str(l+1)].shape[1]))

    return v, s</code></pre>

<pre><code class="python">def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):

    L = len(parameters) // 2  # Number of layers in the neural networks
    v_corrected = {}
    s_corrected = {}

    for l in range(L):
        v["dW" + str(l+1)] = beta1 * v["dW" + str(l+1)] + (1-beta1) * grads["dW" + str(l+1)]
        v["db" + str(l+1)] = beta1 * v["db" + str(l+1)] + (1-beta1) * grads["db" + str(l+1)]
        v_corrected["dW" + str(l+1)] = v["dW" + str(l+1)] / (1 - np.square(beta1))
        v_corrected["db" + str(l+1)] = v["db" + str(l+1)] / (1 - np.square(beta1))
        s["dW" + str(l+1)] = beta2 * s["dW" + str(l+1)] + (1-beta2) * np.square(grads["dW" + str(l+1)])
        s["db" + str(l+1)] = beta2 * s["db" + str(l+1)] + (1-beta2) * np.square(grads["db" + str(l+1)])
        s_corrected["dW" + str(l+1)] = s["dW" + str(l+1)] / (1 - np.square(beta2))
        s_corrected["db" + str(l+1)] = s["db" + str(l+1)] / (1 - np.square(beta2))
        parameters["W" + str(l+1)] = parameters["W" + str(l+1)] - learning_rate * v_corrected["dW" + str(l+1)] / ( np.sqrt(s_corrected["dW" + str(l+1)]) + epsilon)
        parameters["b" + str(l+1)] = parameters["b" + str(l+1)] - learning_rate * v_corrected["db" + str(l+1)] / ( np.sqrt(s_corrected["db" + str(l+1)]) + epsilon)

    return parameters, v, s</code></pre>

<pre><code class="python">for t in range(steps):
    dw = gradient(loss, w)
    moment1 = beta1 * moment1 + (1-beta1) * dw
    moment2 = beta2 * moment2 + (1-beta2) * dw * dw
    moment1_unbiased = moment1 / (1-beta1**t)
    moment2_unbiased = moment2 / (1-beta2**t)
    w = w - learning_rate * moment1_unbiased / (moment2_unbiased.sqrt()+e)</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> | <a href="https://www.educative.io/path/become-a-deep-learning-professional">Become a Deep Learning Professional</a>
  </div>
</div>

<div class="card mb-4" id="optimization-">
  <div class="card-body">
    <h2 class="card-title">Learning rate decay</h2>
    <ul>
      <li>Helps gradient descent converge by taking smaller steps as it approaches the minimum</li>
      <li>We want bigger \( \alpha \) in the beginning but smaller \( \alpha \) near the optimum.</li>
      <li>Let <code>decay_rate</code> \( = dr \)</li>
      <li>Let <code>num_epocs</code> \( = ne \)</li>
      <li>\( \alpha = \dfrac{1}{dr * ne}\alpha_{0} \)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a>
  </div>
</div>
<!-- Optimization END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>