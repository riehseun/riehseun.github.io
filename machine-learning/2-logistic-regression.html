<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- logistic regression BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Logistic regression</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#logistic-regression-1">Logistic regression</a></li>
      <li><a href="#logistic-regression-2">Set up</a></li>
      <li><a href="#logistic-regression-3">Gradient descent</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="logistic-regression-1">
  <div class="card-body">
    <h2 class="card-title">Logistic regression</h2>
    <ul>
      <li>Used for binary classification.</li>
      <li>Fits curve to data.</li>
      <ul>
        <li>Still is linear model because there is linear relationship between input and output.</li>
      </ul>
      <li>There is no layer. (Or hidden units)</li>
    </ul>

    <h3 class="card-title">Steps</h3>
    <ul>
      <li>Load data.</li>
      <li>If necessary</li>
      <ul>
        <li>Flatten matrix inputs into vectors.</li>
        <li>Normalize the data.</li>
      </ul>
      <li>Initialize parameters.</li>
      <li>Iterate</li>
      <ul>
        <li>Forward prop</li>
        <li>Compute cost</li>
        <li>Backward prop</li>
        <li>Retrive gradient</li>
        <li>Update weights</li>
      </ul>
      <li>Use the final weights and training data to do compute prediction.</li>
      <li>Apply sigmoid to the prediction, which gives value either 0 or 1.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://github.com/iamtodor/data-science-interview-questions-and-answers">Data science interview questions with answers</a>
  </div>
</div>

<div class="card mb-4" id="logistic-regression-2">
  <div class="card-body">
    <h2 class="card-title">Set up</h2>
    <ul>
      <li>\( x \in R, y \in \{0,1\} \)</li>
      <li>\( m \) training examples such that \( \{ (x^{(1)},y^{(1)}) \dots (x^{(m)},y^{(m)}) \} \)</li>
      <li>X.shape = \( (n_{x},m) \), Y.shape = \( (1,m) \)</li>
      <li>\( \hat{y} = \sigma (w^{T}w+b) \)</li>
      <ul>
        <li>Without \( \sigma \), it is just linear regression.</li>
      </ul>
      <li>Loss function: \( L(\hat{y},y) = -(ylog\hat{y} + (1-y)log(1-\hat{y})) \)</li>
      <ul>
        <li>This loss function is convex, thus gradient descent can find the global optimum.</li>
        <li>\( L(\hat{y},y) = \frac{1}{2}(\hat{y}-y)^{2} \) something like this is not convex.</li>
      </ul>
      <li>Cost function: \( J(w,b) = \dfrac{1}{m}\displaystyle\sum_{1}^{m} L(\hat{y}^{(i)},y^{(i)}) \)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/deep-learning?">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="logistic-regression-3">
  <div class="card-body">
    <h2 class="card-title">Gradient descent</h2>

    <h3 class="card-title">One training example with \( n = 2 \) features</h3>
    <ul>
      <li>Let \( \hat{y} = a \), \( z = w_{1}x_{1} + w_{2}x_{2} + b \) </li>
      <li>\( da = \frac{dL}{da} = -\frac{y}{a} + \frac{1-y}{1-a} \)</li>
      <li>\( dz = \frac{dL}{dz} = \frac{dL}{da}\frac{da}{dz} =  (-\frac{y}{a} + \frac{1-y}{1-a}) a(1-a) = a-y \)</li>
      <li>Then, \( dw_{1} = x_{1}dz \), \( dw_{2} = x_{2}dz \), \( db = dz \)</li>
      <li>Then, \( w_{1} = w_{1} - \alpha dw_{1} \), \( w_{2} = w_{2} - \alpha dw_{2} \), \( b = b - \alpha db \)</li>
    </ul>

    <h3 class="card-title">\( m \) training examples</h3>
    <ul>
      <li>Let \( \textbf{a} = \sigma({\textbf{z}}) \) , \( \textbf{z} = \textbf{w}^{T}\textbf{x} + \textbf{b} \)</li>
      <li>\( \textbf{dz} = \textbf{a} - \textbf{y} \)</li>
      <li>Then, \( \textbf{dw} = \frac{1}{m}\textbf{x}\textbf{dz}^{T} \), \( \textbf{db} = \dfrac{1}{m}\displaystyle\sum_{1}^{m}dz^{(i)} \)</li>
      <li>Then, \( \textbf{w} = \textbf{w} - \alpha \textbf{dw} \), \( \textbf{b} = \textbf{b} - \alpha \textbf{db} \)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/deep-learning?">Deep Learning Specialization</a>
  </div>
</div>
<!-- Logistic regression END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>