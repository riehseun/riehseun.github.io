<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Machine learning BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Machine learning</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#machine-learning-">Machine learning</a></li>
      <li><a href="#machine-learning-">Bias and variance</a></li>
      <li><a href="#machine-learning-">Orthogonalization</a></li>
      <li><a href="#machine-learning-">Cross valdidation</a></li>
      <li><a href="#machine-learning-">Classification</a></li>
      <!-- <li><a href="#machine-learning-">Project workflow</a></li> -->
      <!-- <li><a href="#machine-learning-">Decision tree</a></li> -->
      <li><a href="#machine-learning-">Feature selection</a></li>
      <li><a href="#machine-learning-">Recommender system</a></li>
      <li><a href="#machine-learning-">Dimensionality</a></li>
      <li><a href="#machine-learning-">Statistics</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Machine learning</h2>
    <ul>
      <li>There are patterns to learn, which are complex</li>
      <li>Data is available or it is possible to collect data</li>
      <li>Learn pattern from data and use this knowledge to perform tasks</li>
    </ul>

    <h3 class="card-title">Supervised learning</h3>
    <ul>
      <li>Train with labeled data</li>
      <li>Ex. linear regression, logistic regression, naive Bayes, KNN, SVM, decision tree, random forest, boosting tree, MLP, CNN, RNN, LSTM</li>
    </ul>

    <h4 class="card-title">Regression</h4>
    <ul>
      <li>Predict variables based on other (dependent) variables</li>
    </ul>

    <h3 class="card-title">Unsupervised learning</h3>
    <ul>
      <li>Detect patterns in data without labels</li>
      <li>Ex. clustering (k-means), PCA, autoencoder, GAN</li>
    </ul>

    <h4 class="card-title">Clustering</h4>
    <ul>
      <li>Grouping objects such that objects in same group are similar and objects in different group are dissimilar</li>
    </ul>

    <h3 class="card-title">Reinforcement learning</h3>
    <ul>
      <li>Trains algorithm to make decisions to achieve the most optimal results</li>
    </ul>

    <!-- <h3 class="card-title">K-means</h3>
    <ul>
      <li>Partition points into K subsets.</li>
      <li>Compute centroid of current partitioning.</li>
      <li>Assign each point to cluster.</li>
    </ul>

    <h3 class="card-title">Gaussian mixture model Vs K-means</h3>
    <ul>
      <li>K-mean</li>
      <ul>
        <li>Data point must belong to one cluster.</li>
        <li>Computes distance.</li>
      </ul>
      <li>GM</li>
      <ul>
        <li>Probability of point belonging to each cluster.</li>
        <li>Computes weighted distance.</li>
      </ul>
    </ul> -->
  </div>
  <div class="card-footer text-muted">
    Reference: Designing Machine Learning Systems, Chip Huyen
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Bias and variance</h2>
    <ul>
      <li>Need to find right balance without overfitting or underfitting the data</li>
    </ul>

    <h3 class="card-title">Bias</h3>
    <ul>
      <li>Train set error</li>
      <li>How far off model prediction is from correct value</li>
      <li>Error from approximately true underlying function</li>
      <li>Difference between predicted and actual value</li>
    </ul>

    <h3 class="card-title">Variance</h3>
    <ul>
      <li>Dev set error</li>
      <li>Variability of model prediction for given data point</li>
      <li>Sensitivity to changes in training data</li>
      <li>Overfitting - model works well on training data, but doesn't generalize well on unseen data</li>
    </ul>

    <h3 class="card-title">Ex. election survey</h3>
    <ul>
      <li>Surveying from a phonebook is source of bias</li>
      <li>Small sample size is source of variance</li>
    </ul>

    <table>
      <tr>
        <td></td>
        <td>variance</td>
        <td>bias</td>
        <td>both bias and variance</td>
        <td>neither</td>
      </tr>
      <tr>
        <td>train set error</td>
        <td>1%</td>
        <td>15%</td>
        <td>15%</td>
        <td>0.5%</td>
      </tr>
      <tr>
        <td>test set error</td>
        <td>11%</td>
        <td>16%</td>
        <td>30%</td>
        <td>1%</td>
      </tr>
    </table>

    <!-- <h3 class="card-title">Why human-level performance</h3>
    <ul>
      <li>While ML is worse than human, you can</li>
      <ul>
        <li>Get labeled data from human.</li>
        <li>Gain insight from manual error analysis. (why did a person get this right?)</li>
        <li>Better analysis of bias/variance.</li>
      </ul>
    </ul> -->

    <!-- <h3 class="card-title">Avoidable bias</h3>
    <ul>
      <li>Human error as a proxy for bays error.</li>
      <li>Gap between human and training error: avoidable bias.</li>
      <li>Gap between training and dev error: variance.</li>
    </ul> -->

    <!-- <h3 class="card-title">Two fundamental assumptions of supervised learning</h3>
    <ul>
      <li>You can fit the training set pretty well ~ avoidable bias.</li>
      <li>Training set performance generalizes pretty well to dev/test set ~ variance.</li>
      <li>Increasing lambda decrease variance. Decreasing lambda decrease bias.</li>
      <li>More features decrease bias but increases variance. Less features decreases variance but increases bias.</li>
    </ul> -->

    <!-- <h3 class="card-title">Approaches</h3>
    <ul>
      <li>Linear model</li>
      <ul>
        <li>Regularization is used to decrease variance at the cost of increasing bias.</li>
      </ul>
      <li>Neural network</li>
      <ul>
        <li>Variance increases and bias decreases with number of hidden units. Regularization is used.</li>
      </ul>
      <li>K-nearest neighbor</li>
      <ul>
        <li>High K leads to high bias and low variance.</li>
      </ul>
      <li>Decision tree</li>
      <ul>
        <li>Depth of trees increases variance. Trees are pruned to control variance.</li>
      </ul>
    </ul> -->
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/deep-learning?">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Orthogonalization</h2>
    <ul>
      <li>Models are trained on train set (Tackle underfitting)</li>
      <ul>
        <li>Better neural network architecture</li>
        <li>Hyperparameter search</li>
        <li>Bigger network/model</li>
        <li>Better optimization algorithm</li>
        <li>Train longer</li>
      </ul>
      <li>Hyperpameters are selected on validation set (Tackle overfitting)</li>
      <ul>
        <li>Better neural network architecture</li>
        <li>Hyperparameter search</li>
        <li>Regularization</li>
        <li>Bigger training set</li>
      </ul>
      <li>Final evaluation is done on test set</li>
      <ul>
        <li>Bigger dev set</li>
        <li>Dev and test set must come from the same distribution!</li>
        <li>Test set may not be needed</li>
      </ul>
      <li>Perform in real world</li>
      <ul>
        <li>Change dev set</li>
        <li>Change cost function</li>
      </ul>
    </ul>

    <h3 class="card-title">Training and dev/test on different distribution</h3>

    <h4 class="card-title">Example</h4>
    <ul>
      <li>Assume 200,000 is from web image and 10,000 is from mobile image</li>
      <li>Goal is to do image recognition on mobile device</li>
      <li>Then, use 2,500 mobile images for dev set and another 2,500 mobile images for test set</li>
      <li>Use 200,000 + 5,000 for the training set</li>
    </ul>

    <h4 class="card-title">Error analysis</h4>
    <ul>
      <li>If dev error >> training error, it could be because both variance and distribution mismatch</li>
      <li>Training-dev set - same distribution as training set, but not used in training</li>
      <li>If training-dev error >> training error, it is variance problem</li>
      <li>If dev error >> training-dev error, it is not a variance problem. It is data mismatch problem</li>
    </ul>

    <h4 class="card-title">Handle data mismatch</h4>
    <ul>
      <li>Make training data similar to dev/test set via synthesizing data</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Cross valdidation</h2>

    <h3 class="card-title">K-fold cross validation</h3>
    <ul>
      <li>Randomly shuffle dataset</li>
      <li>Divide dataset into k bins</li>
      <li>Iterate on k bins</li>
      <ul>
        <li>Use one bin as test set and all other bins as training set</li>
        <li>Fit model on training set and evaluate on test set</li>
        <li>Remember the score from each iteration</li>
      </ul>
      <li>Average accuracies from iterations to compute the accuracy score</li>
      <li>k in practice should be 4-5</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.shiksha.com/online-courses/articles/k-fold-cross-validation/#:~:text=In%20K%2Dfold%20cross%2Dvalidation%2C%20the%20data%20set%20is,5%2Dfold%20cross%2Dvalidation">K-fold Cross-validation</a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Classification</h2>
    <ul>
      <li>Finite number of outputs</li>
      <li>Ex. logistic regression, decision tree, random forests</li>
    </ul>

    <h3 class="card-title">Imbalanced data in classification</h3>
    <ul>
      <li>Collect more data</li>
      <li>Undersample from over-represented class</li>
      <li>Change performance metric</li>
      <ul>
        <li>Accuracy is not the right metric to use when data is imbalanced</li>
        <li>Look at precision, recall, F1 score</li>
      </ul>
      <li>Data augmentation</li>
      <ul>
        <li>For example, crop/rotate images</li>
      </ul>
    </ul>

    <h3 class="card-title">Evaluate classification model</h3>
    <ul>
      <li>True Negative - ground truth was negative and prediction was negative</li>
      <li>True Positive - ground truth was positive and prediction was positive</li>
      <li>False Negative - ground truth was positive but prediction was negative</li>
      <li>False Positive - ground truth was negative but prediction was positive</li>
      <li>Confusion table shows TP, FP, TN, FN</li>
      <li>In perfectly separable data, both precision and recall can be 1</li>
      <li>But in real world, shifting decision boundary increase one but decrease the other</li>
      <li>Precision</li>
      <ul>
        <li>Correctness on predicted positive</li>
        <li>What percentage of positive predictions were correct?</li>
        <ul>
          <li>Ex. of examples recognized as cat, what % actually are cats?</li>
        </ul>
        <li>\( \dfrac{\text{True Positive}}{\text{True Positive} + \text{False Positive}} \)</li>
      </ul>
      <li>Recall</li>
      <ul>
        <li>Correctness of actual positive</li>
        <li>What percentage of positive cases did you catch?</li>
        <ul>
          <li>Ex. what % of actual cats are correctly recognized</li>
        </ul>
        <li>\( \dfrac{\text{True Positive}}{\text{True Positive} + \text{False Negative}} \)</li>
      </ul>
      <li>F1 score</li>
      <ul>
        <li>Average of precision and recall</li>
        <li>\( \dfrac{2}{\frac{1}{P} + \frac{1}{R}} \)</li>
      </ul>
      <li>Accuracy</li>
      <ul>
        <li>What percentage of predictions were correct?</li>
        <li>\( \dfrac{\text{True Positive} + \text{True Negative}}{\text{True Negative} + \text{True Positive} + \text{False Negative} + \text{False Positive}} \)</li>
      </ul>
      <li>False Positive Vs. False Negative</li>
      <ul>
        <li>In medical exam, False Negative is threatening to patients. Thus, False Positive is preferred</li>
        <li>In spam filtering, False Positive is annoying to users. Thus, False Negative is preferred</li>
      </ul>
      <li>ROC-AUC</li>
      <ul>
        <li>Trade-off between TP and FP</li>
      </ul>
      <li>PR-AUC</li>
      <ul>
        <li>Trade-off between precision and recall</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<!-- <div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Project workflow</h2>
    <ul>
      <li>What is business objective?</li>
      <ul>
        <li>Increase revenue, win more customers?</li>
      </ul>
      <li>Define problem</li>
      <ul>
        <li>Outline the gap we are trying to solve.</li>
      </ul>
      <li>Can the problem be solved without data science?</li>
      <ul>
        <li>For example, just recommend top N items based on very simple logic.</li>
      </ul>
      <li>Review existing ML</li>
      <ul>
        <li>No need to re-invent the wheel.</li>
      </ul>
      <li>Setup metrics.</li>
      <ul>
        <li>What does it mean to be sucessful and not successful?</li>
      </ul>
      <li>Exploratory data analysis</li>
      <ul>
        <li>See what data is like via lots of plotting.</li>
      </ul>
      <li>Partition data into 3 sets.</li>
      <ul>
        <li>Train/dev/test.</li>
      </ul>
      <li>Preprocess</li>
      <ul>
        <li>Data cleaning, transformation, etc.</li>
      </ul>
      <li>Feature engineering</li>
      <ul>
        <li>Requires domain knowledge. Can be minimum if using deep learning.</li>
      </ul>
      <li>Develop model</li>
      <ul>
        <li>Choose algorithms, hypterparameters, etc.</li>
      </ul>
      <li>Ensemble</li>
      <ul>
        <li>Beware. Some ensembles are too complex to put into prodiction.</li>
      </ul>
      <li>Deploy/Monitor model</li>
      <ul>
        <li>Continue iterating afterwards.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div> -->

<!-- <div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Decision tree</h2>
    <ul>
      <li>Used for classification.</li>
      <li>Internal node: test on attribute.</li>
      <li>Branch: test outcome.</li>
      <li>Leaf: class label.</li>
      <li>Main parameters: maximum tree depth, minimum samples per tree node, impurity criterion.</li>
    </ul>

    <h3 class="card-title">Random forest</h3>
    <ul>
      <li>Used for regression and classification.</li>
      <li>Consist of many decision trees.</li>
    </ul>

    <h3 class="card-title">Gradient boosting</h3>
    <ul>
      <li>Relies on regression trees, which minimizes MSE.</li>
      <li>Greedy algorithm: tree is built starting from root. For each leaf, split selected to minimize MSE for this step.</li>
      <li>Build collection of trees one by one. Then, predictions of individual trees are summed.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div> -->

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Feature selection</h2>
    <ul>
      <li>Remove unneeded, irrelevant, redundant attribute from data.</li>
      <li>Redundant features can mislead the model.</li>
      <ul>
        <li>Especially, k-nearest neighbors.</li>
      </ul>
      <li>Irrelevant features can overfit the model.</li>
      <li>Ex. PCA</li>
    </ul>

    <h3 class="card-title">Filter method</h3>
    <ul>
      <li>Assign score to each feature.</li>
      <li>Often considers features independent.</li>
      <li>Ex. chi squared test, information gain, correlation coefficient scores</li>
    </ul>

    <h3 class="card-title">Embedded method</h3>
    <ul>
      <li>Learn which features are contributing to the accuracy of model.</li>
      <li>Ex. regularization (LASSO, elastic net, ridge regression)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Recommender system</h2>
    <ul>
      <li>Relevant and personalized information.</li>
      <li>Should not be something users know well.</li>
      <li>Diverse suggestions.</li>
      <li>Users should explore new items.</li>
    </ul>

    <h3 class="card-title">Collaborative filtering</h3>
    <ul>
      <li>Recommendation is calculated as average of other experiences.</li>
      <li>Does not work well on sparse data, also has cold start problem.</li>
      <li>Item-based: rate an item based on ratings by users similar to current user.</li>
      <li>User-based: rate an item based on similar items that current user rated.</li>
    </ul>

    <h3 class="card-title">Cold start problem</h3>
    <ul>
      <li>Cannot make recommendation for new item.</li>
      <li>Cannot find similarity with other users for new user.</li>
    </ul>

    <h3 class="card-title">Content-based filtering</h3>
    <ul>
      <li>An approach to solve cold start problem.</li>
      <li>Recommend items that are similar to items that user liked already.</li>
      <li>Do not take other users into consideration.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Dimensionality</h2>

    <h3 class="card-title">Curse of dimensionalty</h3>
    <ul>
      <li>High dimensional data is extremely sparse.</li>
      <li>It's hard to do machine learning on sparse data.</li>
    </ul>

    <h3 class="card-title">Sigular value decomposition</h3>
    <ul>
      <li>Refactor a matrix into three pieces: left matrix, diagonal matrix, right matrix.</li>
    </ul>

    <h3 class="card-title">Priciple component analysis</h3>
    <ul>
      <li>Special type of SVD.</li>
      <li>Left matrix and right matrix are eigenvectors.</li>
      <li>Diagonal matrix is eigenvalues.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-">
  <div class="card-body">
    <h2 class="card-title">Statistics</h2>
    <ul>
      <li>Type 1 error - rejecting the null hypothesis when it is actually true</li>
      <li>Type 2 error - failing to reject the null hypothesis when it is actually false</li>
    </ul>

    <h3 class="card-title">Sparse data</h3>
    <ul>
      <li>L1 regularization.</li>
      <li>Linear regression if linear relationship.</li>
      <li>One-hot encoding.</li>
    </ul>

    <h3 class="card-title">Statistical power</h3>
    <ul>
      <li>Likelyhood that study will find effect when in fact there is effect.</li>
      <li>Higher statistical power, less likely to make false negative.</li>
    </ul>

    <h3 class="card-title">Outlier</h3>
    <ul>
      <li>Can be removed during data preparation using standard deviation.</li>
    </ul>

    <h3 class="card-title">Anomaly</h3>
    <ul>
      <li>68% of data is one std away.</li>
      <li>95% of data is two std away.</li>
      <li>9% of data is three std away.</li>
      <li>Statistical method</li>
      <ul>
        <li>Consider data point with 3 std away as outlier and likely anomaly.</li>
      </ul>
      <li>Metric method</li>
      <ul>
        <li>A point is considered anomaly if removing it significantly improves the model.</li>
        <li>Outlier score is a degree that a point doesn't belong to a cluster.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>
<!-- Machine learning END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>