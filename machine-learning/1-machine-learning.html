<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Machine learning BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Machine learning</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#machine-learning-1">Project workflow</a></li>
      <li><a href="#machine-learning-10">Supervised learning</a></li>
      <li><a href="#machine-learning-11">Classification</a></li>
      <li><a href="#machine-learning-12">Decision tree</a></li>
      <li><a href="#machine-learning-14">Normalization</a></li>
      <li><a href="#machine-learning-15">Bias and variance</a></li>
      <li><a href="#machine-learning-16">Hyperparameters</a></li>
      <li><a href="#machine-learning-17">Feature selection</a></li>
      <li><a href="#machine-learning-18">Recommender system</a></li>
      <li><a href="#machine-learning-19">Dimensionality</a></li>
      <li><a href="#machine-learning-20">Statistics</a></li>
      <li><a href="#machine-learning-100">Unsupervised learning</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="machine-learning-1">
  <div class="card-body">
    <h2 class="card-title">Project workflow</h2>
    <ul>
      <li>What is business objective?</li>
      <ul>
        <li>Increase revenue, win more customers?</li>
      </ul>
      <li>Define problem</li>
      <ul>
        <li>Outline the gap we are trying to solve.</li>
      </ul>
      <li>Can the problem be solved without data science?</li>
      <ul>
        <li>For example, just recommend top N items based on very simple logic.</li>
      </ul>
      <li>Review existing ML</li>
      <ul>
        <li>No need to re-invent the wheel.</li>
      </ul>
      <li>Setup metrics.</li>
      <ul>
        <li>What does it mean to be sucessful and not successful?</li>
      </ul>
      <li>Exploratory data analysis</li>
      <ul>
        <li>See what data is like via lots of plotting.</li>
      </ul>
      <li>Partition data into 3 sets.</li>
      <ul>
        <li>Train/dev/test.</li>
      </ul>
      <li>Preprocess</li>
      <ul>
        <li>Data cleaning, transformation, etc.</li>
      </ul>
      <li>Feature engineering</li>
      <ul>
        <li>Requires domain knowledge. Can be minimum if using deep learning.</li>
      </ul>
      <li>Develop model</li>
      <ul>
        <li>Choose algorithms, hypterparameters, etc.</li>
      </ul>
      <li>Ensemble</li>
      <ul>
        <li>Beware. Some ensembles are too complex to put into prodiction.</li>
      </ul>
      <li>Deploy/Monitor model</li>
      <ul>
        <li>Continue iterating afterwards.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-10">
  <div class="card-body">
    <h2 class="card-title">Supervised learning</h2>
    <ul>
      <li>Training with labeled data.</li>
      <li>Ex. linear regression, logistic regression, naive Bayes, KNN, SVM, decision tree, random forest, boosting tree, MLP, CNN, RNN, LSTM.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-11">
  <div class="card-body">
    <h2 class="card-title">Classification</h2>
    <ul>
      <li>Finite number of outputs.</li>
      <li>Ex. logistic regression, decision tree, random forests.</li>
    </ul>

    <h3 class="card-title">Imbalanced data in classification</h3>
    <ul>
      <li>Collect more data.</li>
      <li>Undersample from over-represented class.</li>
      <li>Change performance metric</li>
      <ul>
        <li>Accuracy is not the right metric to use when data is imbalanced.</li>
        <li>Look at precision / recall / F1 score.</li>
      </ul>
      <li>Data augmentation</li>
      <ul>
        <li>For example, crop/rotate images.</li>
      </ul>
    </ul>

    <h3 class="card-title">Evaluate classification model</h3>
    <ul>
      <li>True Negative: ground truth was negative and prediction was negative.</li>
      <li>True Positive: ground truth was positive and prediction was positive.</li>
      <li>False Negative: ground truth was positive but prediction was negative.</li>
      <li>False Positive: ground truth was negative but prediction was positive.</li>
      <li>Confusion table shows TP, FP, TN, FN.</li>
      <li>In perfectly separable data, both precision and recall can be 1.</li>
      <li>But in real world, shifting decision boundary increase one but decrease the other.</li>
      <li>Precision</li>
      <ul>
        <li>Correctness on predicted positive.</li>
        <li>What percentage of positive predictions were correct?</li>
        <ul>
          <li>Ex. of examples recognized as cat, what % actually are cats?</li>
        </ul>
        <li>True Positive / (True Positive + False Positive)</li>
      </ul>
      <li>Recall</li>
      <ul>
        <li>Correctness of actual positive.</li>
        <li>What percentage of positive cases did you catch?</li>
        <ul>
          <li>Ex. what % of actual cats are correctly recognized.</li>
        </ul>
        <li>True Positive / (True Positive + False Negative)</li>
      </ul>
      <li>F1 score</li>
      <ul>
        <li>Average of precision and recall.</li>
        <li>2 / ( (1/P) + (1/R) )</li>
      </ul>
      <li>Accuracy</li>
      <ul>
        <li>What percentage of predictions were correct?</li>
        <li>(True Positive + True Negative) / (True Negative + True Positive + False Negative + False Positive)</li>
      </ul>
      <li>False Positive Vs. False Negative</li>
      <ul>
        <li>In medical exam, False Negative is threatening to patients. Thus, False Positive is preferred.</li>
        <li>In spam filtering, False Positive is annoying to users. Thus, False Negative is preferred.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-12">
  <div class="card-body">
    <h2 class="card-title">Decision tree</h2>
    <ul>
      <li>Used for classification.</li>
      <li>Internal node: test on attribute.</li>
      <li>Branch: test outcome.</li>
      <li>Leaf: class label.</li>
      <li>Main parameters: maximum tree depth, minimum samples per tree node, impurity criterion.</li>
    </ul>

    <h3 class="card-title">Random forest</h3>
    <ul>
      <li>Used for regression and classification.</li>
      <li>Consist of many decision trees.</li>
    </ul>

    <h3 class="card-title">Gradient boosting</h3>
    <ul>
      <li>Relies on regression trees, which minimizes MSE.</li>
      <li>Greedy algorithm: tree is built starting from root. For each leaf, split selected to minimize MSE for this step.</li>
      <li>Build collection of trees one by one. Then, predictions of individual trees are summed.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-14">
  <div class="card-body">
    <h2 class="card-title">Normalization</h2>
    <ul>
      <li>Assures better convergence during backpropagation.</li>
    </ul>

    <h3 class="card-title">Batch nomralization</h3>
    <ul>
      <li>Normalize activations.</li>
    </ul>

    <h3 class="card-title">Batch normalization as regularization</h3>
    <ul>
      <li>Each mini-batch is scaled by mean/variance computed on just that mini-batch.</li>
      <li>This has slight regularization effect.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-15">
  <div class="card-body">
    <h2 class="card-title">Bias and variance</h2>
    <ul>
      <li>Need to find right balance without overfitting or underfitting the data.</li>
    </ul>

    <h3 class="card-title">Bias</h3>
    <ul>
      <li>How far off model prediction is from correct value.</li>
      <li>Error from approximately true underlying function.</li>
      <li>Difference between predicted and actual value.</li>
    </ul>

    <h3 class="card-title">Variance</h3>
    <ul>
      <li>Variability of model prediction for given data point.</li>
      <li>Sensitivity to changes in training data.</li>
      <li>Overfitting: model works well on training data, but doesn't generalize well on unseen data.</li>
    </ul>

    <h3 class="card-title">Ex. election survey</h3>
    <ul>
      <li>Surveying from a phonebook is source of bias.</li>
      <li>Small sample size is source of variance.</li>
    </ul>

    <h3 class="card-title">Why human-level performance</h3>
    <ul>
      <li>While ML is worse than human, you can</li>
      <ul>
        <li>Get labeled data from human.</li>
        <li>Gain insight from manual error analysis. (why did a person get this right?)</li>
        <li>Better analysis of bias/variance.</li>
      </ul>
    </ul>

    <h3 class="card-title">Avoidable bias</h3>
    <ul>
      <li>Human error as a proxy for bays error.</li>
      <li>Gap between human and training error: avoidable bias.</li>
      <li>Gap between training and dev error: variance.</li>
    </ul>

    <h3 class="card-title">Two fundamental assumptions of supervised learning</h3>
    <ul>
      <li>You can fit the training set pretty well ~ avoidable bias.</li>
      <li>Training set performance generalizes pretty well to dev/test set ~ variance.</li>
      <li>Avoidable bias</li>
      <ul>
        <li>Traing bigger model.</li>
        <li>Train longer / use better optimization algorithms.</li>
        <li>NN architecture / hyperparameters search.</li>
      </ul>
      <li>Dev error</li>
      <ul>
        <li>More data.</li>
        <li>Regularization.</li>
        <li>NN architecture / hyperparameters search.</li>
      </ul>
      <li>Increasing lambda decrease variance. Decreasing lambda decrease bias.</li>
      <li>More features decrease bias but increases variance. Less features decreases variance but increases bias.</li>
    </ul>

    <h3 class="card-title">Approaches</h3>
    <ul>
      <li>Linear model</li>
      <ul>
        <li>Regularization is used to decrease variance at the cost of increasing bias.</li>
      </ul>
      <li>Neural network</li>
      <ul>
        <li>Variance increases and bias decreases with number of hidden units. Regularization is used.</li>
      </ul>
      <li>K-nearest neighbor</li>
      <ul>
        <li>High K leads to high bias and low variance.</li>
      </ul>
      <li>Decision tree</li>
      <ul>
        <li>Depth of trees increases variance. Trees are pruned to control variance.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-16">
  <div class="card-body">
    <h2 class="card-title">Hyperparameters</h2>
    <ul>
      <li>Should use random sampling to choose the number of layers, number of features, etc.</li>
      <li>Scale parameters accordingly such as log scale.</li>
      <li>Panda: babysit one model.</li>
      <li>Caviar: train many models in parallel.</li>
    </ul>

    <h3 class="card-title">Hyperparameter tuning</h3>
    <ul>
      <li>Grid search</li>
      <li>Random search</li>
      <li>Bayesian Optimization (heaviliy outperforms above two)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-17">
  <div class="card-body">
    <h2 class="card-title">Feature selection</h2>
    <ul>
      <li>Remove unneeded, irrelevant, redundant attribute from data.</li>
      <li>Redundant features can mislead the model.</li>
      <ul>
        <li>Especially, k-nearest neighbors.</li>
      </ul>
      <li>Irrelevant features can overfit the model.</li>
      <li>Ex. PCA</li>
    </ul>

    <h3 class="card-title">Filter method</h3>
    <ul>
      <li>Assign score to each feature.</li>
      <li>Often considers features independent.</li>
      <li>Ex. chi squared test, information gain, correlation coefficient scores</li>
    </ul>

    <h3 class="card-title">Embedded method</h3>
    <ul>
      <li>Learn which features are contributing to the accuracy of model.</li>
      <li>Ex. regularization (LASSO, elastic net, ridge regression)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-18">
  <div class="card-body">
    <h2 class="card-title">Recommender system</h2>
    <ul>
      <li>Relevant and personalized information.</li>
      <li>Should not be something users know well.</li>
      <li>Diverse suggestions.</li>
      <li>Users should explore new items.</li>
    </ul>

    <h3 class="card-title">Collaborative filtering</h3>
    <ul>
      <li>Recommendation is calculated as average of other experiences.</li>
      <li>Does not work well on sparse data, also has cold start problem.</li>
      <li>Item-based: rate an item based on ratings by users similar to current user.</li>
      <li>User-based: rate an item based on similar items that current user rated.</li>
    </ul>

    <h3 class="card-title">Cold start problem</h3>
    <ul>
      <li>Cannot make recommendation for new item.</li>
      <li>Cannot find similarity with other users for new user.</li>
    </ul>

    <h3 class="card-title">Content-based filtering</h3>
    <ul>
      <li>An approach to solve cold start problem.</li>
      <li>Recommend items that are similar to items that user liked already.</li>
      <li>Do not take other users into consideration.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-19">
  <div class="card-body">
    <h2 class="card-title">Dimensionality</h2>

    <h3 class="card-title">Curse of dimensionalty</h3>
    <ul>
      <li>High dimensional data is extremely sparse.</li>
      <li>It's hard to do machine learning on sparse data.</li>
    </ul>

    <h3 class="card-title">Sigular value decomposition</h3>
    <ul>
      <li>Refactor a matrix into three pieces: left matrix, diagonal matrix, right matrix.</li>
    </ul>

    <h3 class="card-title">Priciple component analysis</h3>
    <ul>
      <li>Special type of SVD.</li>
      <li>Left matrix and right matrix are eigenvectors.</li>
      <li>Diagonal matrix is eigenvalues.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-20">
  <div class="card-body">
    <h2 class="card-title">Statistics</h2>

    <h3 class="card-title">Sparse data</h3>
    <ul>
      <li>L1 regularization.</li>
      <li>Linear regression if linear relationship.</li>
      <li>One-hot encoding.</li>
    </ul>

    <h3 class="card-title">Statistical power</h3>
    <ul>
      <li>Likelyhood that study will find effect when in fact there is effect.</li>
      <li>Higher statistical power, less likely to make false negative.</li>
    </ul>

    <h3 class="card-title">Outlier</h3>
    <ul>
      <li>Can be removed during data preparation using standard deviation.</li>
    </ul>

    <h3 class="card-title">Anomaly</h3>
    <ul>
      <li>68% of data is one std away.</li>
      <li>95% of data is two std away.</li>
      <li>9% of data is three std away.</li>
      <li>Statistical method</li>
      <ul>
        <li>Consider data point with 3 std away as outlier and likely anomaly.</li>
      </ul>
      <li>Metric method</li>
      <ul>
        <li>A point is considered anomaly if removing it significantly improves the model.</li>
        <li>Outlier score is a degree that a point doesn't belong to a cluster.</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="machine-learning-100">
  <div class="card-body">
    <h2 class="card-title">Unsupervised learning</h2>
    <ul>
      <li>Detect patterns in data without labels.</li>
      <li>Ex. clustering (k-means), PCA, autoencoder, GAN.</li>
    </ul>

    <h3 class="card-title">K-means</h3>
    <ul>
      <li>Partition points into K subsets.</li>
      <li>Compute centroid of current partitioning.</li>
      <li>Assign each point to cluster.</li>
    </ul>

    <h3 class="card-title">Gaussian mixture model Vs K-means</h3>
    <ul>
      <li>K-mean</li>
      <ul>
        <li>Data point must belong to one cluster.</li>
        <li>Computes distance.</li>
      </ul>
      <li>GM</li>
      <ul>
        <li>Probability of point belonging to each cluster.</li>
        <li>Computes weighted distance.</li>
      </ul>
    </ul>

  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>
<!-- Machine learning END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>