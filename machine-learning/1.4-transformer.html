<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Transformer BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Transformer</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#transformer-1">Transformer</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="transformer-1">
  <div class="card-body">
    <h2 class="card-title">Transformer</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/machine-learning/transformer1.png" style="width: 500px; height: 700px" alt="Card image cap">

    <ul>
      <li>Output of layer \( l \) is becomes the input of layer \( l+1 \) until prediction is reached</li>
      <li>There is no RNN or LSTM</li>
      <li>There are 6 sets of encoder and decoder layers</li>
      <li></li>
    </ul>

    <h3 class="card-title">Encoder stack</h3>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/machine-learning/transformer2.png" style="width: 300px; height: 500px" alt="Card image cap">

    <ul>
      <li>Input embedding</li>
      <ul>
        <li>Converts input tokens to vector of \( d_{\text{model}} = 512 \) dimension using learned embeddings</li>
        <ul>
          <li>Tokenizer transforms a sentence into tokens</li>
          <li>An embedding method is used to convert each word to a vector of \( 512 \) numbers</li>
        </ul>
      </ul>
      <li>Positional encoding</li>
      <li>Add positional encoding to input embedding to produce final encoding</li>
        <ul>
<pre><code class="python">def encoding(pos, pe)
    for i in range(0, 512,2):
        # Positional encoding
        val =  pos / (10000**((2*i)/d_model))
        pe[0][i] = math.sin(val)
        pe[0][i+1] = math.cos(val)

        # Final encoding
        fe[0][i] = (y[0][i]*math.sqrt(d_model)) + pe[0][i]
        fe[0][i+1] = (y[0][i+1]*math.sqrt(d_model)) + pe[0][i+1]</code></pre>
        </ul>
      <li>Multi-head attention</li>
      <li>Feedforward network</li>
    </ul>

    <h3 class="card-title">Decoder stack</h3>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/machine-learning/transformer3.png" style="width: 300px; height: 700px" alt="Card image cap">

    <ul>
      <li></li>
      <li></li>
      <li></li>
      <li></li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Transformers for Natural Language Processing, Denis Rothman
  </div>
</div>
<!-- Transformer END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>