<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Neural Network BEGIN -->
<div class="card mb-4" id="subject">
  <div class="card-body">
    <h2 class="card-title">Neural Network</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#neural-network-">Binary Classification</a></li>
      <li><a href="#neural-network-">Multi-class Classification</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="neural-network-">
  <div class="card-body">
    <h2 class="card-title">Binary Classification</h2>
    
<pre><code class="python"># Load data
# Standardize data
# Intialize parameters
# Train
#   Compute Z, A (forward porp)
#   Compute cost
#   Compute gradient (backward prop)
#   Update weights
# Inference

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader

import torch
import torch.nn as nn
import torch.nn.functional as F

# Data

class CustomDataset(Dataset):

    def __init__(self, X_train, y_train):
        self.x = F.normalize(torch.from_numpy(X_train))  # (m, n)
        self.y = torch.from_numpy(y_train) # (m)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        return self.x[index].float(), self.y[index].float()

dataset = load_breast_cancer()
n = dataset.data.shape[1]
print(f"num_features: {n}")
m = len(dataset.data)
print(f"num_data: {m}")
X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)
train_data = CustomDataset(X_train, y_train)
test_data = CustomDataset(X_test, y_test)
train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=1, shuffle=True)

# Model
class NeuralNetwork(nn.Module):

    def __init__(self, num_features, num_neurons_h1):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(num_features, num_neurons_h1),
            nn.ReLU(),
            nn.Linear(num_neurons_h1, 1)
        )

        # self.model = nn.Sequential(
        #     nn.Linear(num_features, 4),
        #     nn.ReLU(),
        #     nn.Linear(4, 6),
        #     nn.ReLU(),
        #     nn.Linear(6, 5),
        #     nn.ReLU(),
        #     nn.Linear(5, 1)
        # )

    def forward(self, x):
        x = self.model(x)
        x = torch.sigmoid(x)
        x = torch.squeeze(x)
        return x

# Train
n = dataset.data.shape[1]
model = NeuralNetwork(n, 4)
learning_rate = 0.01
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

epoch = 1000

for key, val in model.state_dict().items():
    print(f"{key}: {val}")

for e in range(epoch):
    for x_batch, y_batch in train_dataloader:

        optimizer.zero_grad()  # Reset grads

        y_hat = model(x_batch)  # (m, 1)

        # print(f"x_batch: {x_batch.shape}")
        # print(f"y_batch: {y_batch.shape}")
        # print(f"y_hat: {y_hat.shape}")
        # print(y_batch)
        # print(y_hat)

        loss = criterion(y_hat, y_batch)  # Compute loss

        loss.backward()  # Compute gradient

        optimizer.step()  # Adjust learning rate

        print(f"epoch: {e+1}, loss = {loss.item()}")

for key, val in model.state_dict().items():
    print(f"{key}: {val}")

# Inference
correct = 0
incorrect = 0
with torch.no_grad():
    for x_batch, y_batch in test_dataloader:
        y_pred = model(x_batch)  # no need to call model.forward()
        if y_pred > 0.5:
            y_pred = 1
        else:
            y_pred = 0
        if y_pred == y_batch[0]:
            correct += 1
        else:
            incorrect += 1
    accuracy = correct/(correct+incorrect)
    print(f"accurach: {accuracy}")</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>

<div class="card mb-4" id="neural-network-">
  <div class="card-body">
    <h2 class="card-title">Multi-class Classification</h2>
    
<pre><code class="python"># Load data
# Standardize data
# Intialize parameters
# Train
#   Compute Z1, A1, Z2, A2, so on (forward porp)
#   Compute cost
#   Compute gradient (backward prop)
#   Update weights
# Inference

from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader

import torch
import torch.nn as nn
import torch.nn.functional as F

# Data

class CustomDataset(Dataset):

    def __init__(self, X_train, y_train):
        self.x = F.normalize(torch.from_numpy(X_train))  # (m, n)
        self.y = torch.from_numpy(y_train) # (m)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        return self.x[index].float(), self.y[index]

dataset = load_wine()
X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)
train_data = CustomDataset(X_train, y_train)
test_data = CustomDataset(X_test, y_test)
train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=1, shuffle=True)

# Model
class NeuralNetwork(nn.Module):

    def __init__(self, num_features, num_neurons_h1, num_classes):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(num_features, num_neurons_h1),
            nn.ReLU(),
            nn.Linear(num_neurons_h1, num_classes)
        )

        # self.model = nn.Sequential(
        #     nn.Linear(num_features, 4),
        #     nn.ReLU(),
        #     nn.Linear(4, 6),
        #     nn.ReLU(),
        #     nn.Linear(6, 5),
        #     nn.ReLU(),
        #     nn.Linear(5, num_classes)
        # )

    def forward(self, x):
        x = self.model(x)
        # x = torch.softmax(x, dim=1)
        return x

# Train
n = dataset.data.shape[1]
model = NeuralNetwork(n, 4, 3)
learning_rate = 0.01
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

epoch = 1000

for key, val in model.state_dict().items():
    print(f"{key}: {val}")

for e in range(epoch):
    for x_batch, y_batch in train_dataloader:

        optimizer.zero_grad()  # Reset grads

        y_hat = model(x_batch)  # (m, 3)

        # print(f"x_batch: {x_batch.shape}")
        # print(f"y_batch: {y_batch.shape}")
        # print(f"y_hat: {y_hat.shape}")
        # print(y_batch)
        # print(y_hat)

        loss = criterion(y_hat, y_batch)  # Compute loss

        loss.backward()  # Compute gradient

        optimizer.step()  # Adjust learning rate

        print(f'epoch: {e+1}, loss = {loss.item():.4f}')

for key, val in model.state_dict().items():
    print(f"{key}: {val}")

# Inference
correct = 0
incorrect = 0
with torch.no_grad():
    for x_batch, y_batch in test_dataloader:
        y_pred = model(x_batch)  # no need to call model.forward()
        if torch.argmax(y_pred) == y_batch[0]:
            correct += 1
        else:
            incorrect += 1
    print(correct/(correct+incorrect))</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href=""></a>
  </div>
</div>
<!-- Neural Network END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>