<!DOCTYPE html>

<html lang="en">

<head>


<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Seungmoon's DevOps Engineering Blog">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="Python, Groovy, Kubernetes, Docker, Jenkins, Terraform, Bash">

<title>Seungmoon Rieh</title>

<!-- Third Party CSS -->
<link href="other/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="other/highlight/styles/monokai-sublime.css" rel="stylesheet">

<!-- CSS -->
<link href="img/seungmoonrieh.jpg" rel="icon">
<link href="css/site.css" rel="stylesheet">

<!-- Third Party JavaScript -->
<script src="other/jquery/jquery.min.js"></script>
<script src="other/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="other/highlight/highlight.pack.js"></script>

<!-- JavaScript -->
<script src="js/site.js"></script>


</head>


<body>


<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
<div class="container">
<a class="navbar-brand" href="index.html">Seungmoon Rieh</a>
<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
  <span class="navbar-toggler-icon"></span>
</button>
<div class="collapse navbar-collapse" id="navbarResponsive">
  <ul class="navbar-nav ml-auto">
    <li class="nav-item">
      <div class="btn-group">
        <button type="button" class="btn btn-rose dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">DevOps</button>
        <div class="dropdown-menu">
          <a class="dropdown-item" href="#devops">DevOps</a>
          <div class="dropdown-divider"></div>
          <a class="dropdown-item" href="#aboutme">About Me</a>
        </div>
      </div>
    </li>
    <li class="nav-item">
      <div class="btn-group">
        <button type="button" class="btn btn-info dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Develop</button>
        <div class="dropdown-menu">
          <a class="dropdown-item" href="#virtualbox">Virtual Box</a>
          <a class="dropdown-item" href="#git">GIT</a>
          <a class="dropdown-item" href="#python">Python</a>
          <a class="dropdown-item" href="#anaconda">Anaconda</a>
          <a class="dropdown-item" href="#groovy">Groovy</a>
          <a class="dropdown-item" href="#java">Java</a>
        </div>
      </div>
    </li>
    <li class="nav-item">
      <div class="btn-group">
        <button type="button" class="btn btn-primary dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Provision</button>
        <div class="dropdown-menu">
          <a class="dropdown-item" href="#terraform">Terraform</a>
          <a class="dropdown-item" href="#salt">Salt</a>
        </div>
      </div>
    </li>
    <li class="nav-item">
      <div class="btn-group">
        <button type="button" class="btn btn-success dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Deploy</button>
        <div class="dropdown-menu">
          <a class="dropdown-item" href="#jenkins">Jenkins</a>
          <a class="dropdown-item" href="#docker">Docker</a>
          <a class="dropdown-item" href="#kubernetes">Kubernetes</a>
          <a class="dropdown-item" href="#nexus">Nexus</a>
        </div>
      </div>
    </li>
    <li class="nav-item">
      <div class="btn-group">
        <button type="button" class="btn btn-teal dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">OS</button>
        <div class="dropdown-menu">
          <a class="dropdown-item" href="#linux">Linux</a>
          <a class="dropdown-item" href="#ubuntu">Ubuntu</a>
          <a class="dropdown-item" href="#f5">F5</a>
        </div>
      </div>
    </li>
  </ul>
</div> <!-- /.collapse navbar-collapse -->
</div> <!-- /.container -->
</nav> <!-- /.navbar navbar-expand-lg navbar-dark bg-dark fixed-top -->


<div class="container">
<div class="row">
<div class="col-md-12">
  <h1 class="my-4">Software Engineering</h1>


  <!-- DevOps BEGIN -->
  <div class="card mb-4" id="devops">
    <div class="card-body">
      <h2 class="card-title">DevOps</h2>
      <p class="card-text">DevOps culture aims to achieve efficiency in Software Development Life Cycle. Areas to improve in SDLC will differ by organizations but will generally include</p>
      <ul>
        <li>Deliever busniess requirement in agile fashion</li>
        <li>Reduce time to deploy</li>
        <li>Fast reponse to errors</li>
        <li>Robust security control</li>
        <li>Achieve target reliability</li>
      </ul>

      <h3 class="card-title">DevOps qualifications</h3>
      <ul>
        <li>Branching strategy (Git flow, Github flow)</li>
        <li>Deployment and release strategy (Blue/Green, Canary, Dark Launch)</li>
        <li>Configuration (Salt, Ansible)</li>
        <li>Provisioning (Terraform)</li>
        <li>Containerization (Docker)</li>
        <li>Cloud computing (GCP, Azure, AWS)</li>
        <li>Container orchestration (Kubernetes)</li>
        <li>CI/CD, SDLC (Jenkins)</li>
        <li>Scripting (Bash, Python, Groovy)</li>
        <li>Code build (Maven, npm, gradle)</li>
        <li>Security (SonarQube, Veracode, TLS/SSL, AD/LDAP)</li>
      </ul>

      <ul class="list-unstyled mb-0">
        <li><a href="#devops-1">1. Cloud</a></li>
        <li><a href="#devops-2">2. Continuous Integration</a></li>
        <li><a href="#devops-3">3. Continuous Delivery</a></li>
        <li><a href="#devops-4">4. Microservice-centric architecture</a></li>
        <li><a href="#devops-5">5. Test Automation</a></li>
        <li><a href="#devops-6">6. Infrastructure/Configuration as Code</a></li>
        <li><a href="#devops-7">7. Continuous Monitoring</a></li>
        <li><a href="#devops-8">8. Release strategy</a></li>
        <li><a href="#devops-9">9. Security</a></li>
        <li><a href="#devops-10">10. Scaliability and Reliablity</a></li>
        <li><a href="#devops-11">11. Network</a></li>
        <li><a href="#devops-12">12. Agile</a></li>
        <li><a href="#devops-13">13. DevOps Culture and Metrics</a></li>
        <li><a href="#devops-14">14. DB Basic</a></li>
        <li><a href="#devops-15">15. Pipelining</a></li>
        <li><a href="#devops-16">16. Message vs. Event</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="devops-1">
    <div class="card-body">
      <h2 class="card-title">1. Cloud</h2>
      <p class="card-text">Compute Power (three approaches)</p>
      <ul>
        <li>VM : Physical Hardware -> Operating System -> Hypervisor controller -> VM (App, OS, Virtual Hardware)</li>
        <li>Container : Physical Hardware -> Operating System -> Container Engine -> Container (App, dependencies)</li>
        <li>Serverless : Physical Hardware -> Operating System -> Serverless Runtime -> Function</li>
      </ul>
      <p class="card-text">4 types of computing resource management reponsibility by the users</p>
      <ul>
        <li>On-premises : Networking / Storage / Servers / Virtualization / OS / Middleware / Runtime / Data / Application</li>
        <li>Infrastructure as a Service : OS / Middleware / Runtime / Data / Application</li>
        <li>Platform as a Service : Data / Application</li>
        <li>Software as a Service : Everything is managed by Cloud Provider</li>
      </ul>
      <p class="card-text">Characteristics of cloud native</p>
      <ul>
        <li>Lightweight APIs</li>
        <li>Containers as standard deployment format</li>
        <li>Microservices</li>
        <li>Security at scale (Ex. Security tools provided by the Vendor)</li>
        <li>Reliability (Ex. Fully managed DB with high availability)</li>
        <li>Fast innovation (Ex. Serverless scales without managing infrastructure)</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-2">
    <div class="card-body">
      <h2 class="card-title">2. Continuous Integration</h2>
      <p class="card-text">Continuous Integration means <strong>fast</strong> and <strong>automated</strong> feedback whenever there is code change</p>
      <img class="img-fluid" class="card-img-top" src="img/devops/devops-1-a.png" alt="Card image cap">
      <h3>Continuous Integration may include</h3>
      <ul>
        <li>builds</li>
        <li>unit test</li>
        <li>static analysis</li>
        <li>dynamic analysis</li>
        <li>package</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-3">
    <div class="card-body">
      <h2 class="card-title">3. Continuous Delivery</h2>
      <p class="card-text">Continuous Delivery means fast deployment of new features to production</p>
      <img class="img-fluid" class="card-img-top" src="img/devops/devops-2-a.png" alt="Card image cap">
      <h3>Continuous Delivery requires</h3>
      <ul>
        <li>Externalized Configuration</li>
        <li>Automated tests</li>
        <li>Short build time (Failing slow tests!)</li>
        <li>Isolated and small pipeline steps</li>
        <li>Modularized code-base and parallel builds</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-4">
    <div class="card-body">
      <h2 class="card-title">4. Microservice-centric architecture</h2>
      <p class="card-text">Example migration pattern from legacy system to modern architecture</p>
      <img class="img-fluid" class="card-img-top" src="img/devops/devops-3-a.png" alt="Card image cap">
      <h3>Monolithic</h3>
      <ul>
        <li>All components of application are colocated within a single unit</li>
        <li>Tied to a single technology stack
        <li>Data schema updates can be difficult since entire business logic shared a single DB</li>
        <li>Difficult to scale services independently</li>
      </ul>
      <h3>Microservice</h3>
      <ul>
        <li>Small, independent, and loosely coupled, thus can be deployed and scaled independently</li>
        <li>Impact of bugs from each component can be limited</li>
        <li>Each service is typically responsible for its own data</li>
        <li>Managing dependencies between components can be challenging (Ex. features of component A depends on features of component B)</li>
      </ul>
      <h3>Serverless</h3>
      <ul>
        <li>PaaS where business logic runs as functions</li>
        <li>Executions are event driven (http request, schedule, messages added to a queue, DB events, etc)</li>
        <li>Pros: only charged for what is used, automatic scaling</li>
        <li>Cons: there are execution timeouts of functions for each cloud provider, high frequency exeuctions can be cheaper in VM than in serverless</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-5">
    <div class="card-body">
      <h2 class="card-title">5. Test Automation</h2>
      <ul>
        <li>Unit test - test each method/function</li>
        <li>Integration test  - test all components/modules of application togerther</li>
        <li>Behavior/Functional test  - test business logic</li>
        <li>Non-Functional test - test roll-back, roll-forward, performance/load/stress, penetration, compliance, etc</li>
        <li>User Acceptance test - test user interface</li>
      </ul>
      <p class="card-text">Volumn of each test should be the following</p>
      <img class="img-fluid" class="card-img-top" src="img/devops/devops-4-a.png" alt="Card image cap">
      <ul>
        <li>Because unit tests are for each method/function, there is no limit on how many tests you should have</li>
        <li>Integration/Functional tests should have enough size to catch potential errors at earlier stage</li>
        <li>UI tests will however frequently be modified based on changes on application layout, so this test should be small</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-6">
    <div class="card-body">
      <h2 class="card-title">6. Infrastructure/Configuration as Code</h2>
      <p class="card-text">Infrastructure as Code</p>
      <ul>
        <li>No changes via GUI</li>
        <li>No live modification of instance (Immutable Server) - automating provisioning and recovery</li>
        <li>Versioning every infrastructure changes - making infrastructure reproducible</li>
      </ul>
      <p class="card-text">Configuration as Code</p>
      <ul>
        <li>Idempotency - operation results in the same outcome each time we apply</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-7">
    <div class="card-body">
      <h2 class="card-title">7. Monitoring</h2>
      <ul>
        <li>Hook the test: Not only monitor availablity of services and resource comsumption, also periodically run tests to catch potential errors early</li>
        <li>Auto-correction upon finding problems: bring up the services that are down, clean up disk space by removing tmp files, safe or hard restart the server to clear memory, etc</li>
      </ul>
      <h3>Dickerson hierarchy of reliability</h3>
      <ul>
        <li><strong>monitoring</strong>: understand what is running in production. relibility is measured from customer perspective (there is no difference between system failing due to code bug or scaling issue from customers' point of view)</li>
        <li><strong>incident response</strong>: respond with urgency, rather than react. focus on clear communication and make information accessible</li>
        <li><strong>post-incident review</strong>: this is for pure learning purpose. it must be blameless. it is not document or report. understand that human errors do happen but they are not the cause of failures but symtom of larger problems</li>
        <li><strong>test and release procedures</strong>: </li>
        <li><strong>capacity planning</strong>: </li>
        <li><strong>development</strong>: </li>
        <li><strong>product</strong>: </li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-8">
    <div class="card-body">
      <h2 class="card-title">8. Release strategy</h2>
      <p class="card-text">Blue-Green</p>
      <ul>
        <li>Deployment strategy to avoid downtown during deployment</li>
        <li>Using IaC, deploy new instance "Green" (existing instance will be called "Blue")</li>
        <li>Run tests on Green instance</li>
        <li>Make "Green" the production instance - switch traffic from Blue to Green by re-mapping DNS to Green's IP address, remove Blue from load-balancer and add Green, etc</li>
      </ul>
      <p class="card-text">Carnary</p>
      <ul>
        <li>Similar to Blue-Green but redirect only subset of users instead of all users (choose users who are more active, etc)</li>
        <li>Both Blue and Green would be up during this time</li>
        <li>Great way to do capacity testing on new instance (can always roll-back by redirecting users to old instance)</li>
        <li>Management of multiple versions of Software is required</li>
      </ul>
      <p class="card-text">Dark-launching</p>
      <ul>
        <li>releasing production-ready features to subset of users prior to full release</li>
        <li>Feature toggle - run specific part of code based on configuration stored online</li>
        <li>Turn on features only for subset of users before releasing features to everybody</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-9">
    <div class="card-body">
      <h2 class="card-title">9. Security</h2>
      <h3>SSL (Secure Sockets Layer)</h3>
      <ul>
        <li>Ensure that all data passed between Web server and Browsers remain private</li>
        <li>Web server creates private and public Key</li>
        <li>User submits Certificate Signing Request (CSR), which includes public key, to Certification Authority. CA then will issue SSL Certificate</li>
        <li>Web server will match user's SSL Certificate to its private Key</li>
        <li>When Broswer connects to secure site, it will check whether SSL Certificate is not expired, and it is isseud by Certification Authority that Browser trusts, and it is being used by the website for which it has been issued</li>
      </ul>

      <h3>SSL handshake</h3>
      <ul>
        <li>Client hello - client to server with TLS version</li>
        <li>Server hello - server to client with configuration it picked</li>
        <li>Server key exchange message - server to client with required information to generate pre-master secret</li>
        <li>Certificate request - server to client with certificate type, algorithm, and authorities</li>
        <li>Client certificate - client to server with certificate chain</li>
        <li>Client key exchange message - client to server so that a common key can be generated. Both sides then generate a master secret using pre-master secret, which is then used to generate symmetric key to encrypt session data</li>
      </ul>

      <h3>A layered approach to security</h3>
      <ul>
        <li>Data : attackers are always after this</li>
        <li>Application : free of vulnerabilities, application secrets in a secure storage medium</li>
        <li>Compute : secure access to VMs, implement endpoint protection, keep systems patched and current</li>
        <li>Networking : deny by default, implement secure connectivity to on-premises networks, restrict inbound internet access</li>
        <li>Perimeter : use distributed denial of service (DDoS) protection, use perimeter firewalls to identify malicious attacks</li>
        <li>Identity and access : use SSO and multi-factor authentication</li>
        <li>Physical security : access to physical data centre with compute machines</li>
      </ul>
      <h3>Examples of security breaches and attacks</h3>
      <ul>
        <li>Data : Exposing an encryption key or using weak encryption</li>
        <li>Application : Malicious code injection and execution. For example, SQL injection and cross-site scripting (XSS)</li>
        <li>Compute : Malware executing malicious code to compromise system</li>
        <li>Networking : Unnecessary open ports to the Internet. For example, leaving SSH or RDP open to virtual machines to leading brute-force attacks against your systems</li>
        <li>Perimeter : Denial-of-service (DoS) attacks</li>
        <li>Identity and access : Exposed credentials and toxic combinations of permissions and authorization</li>
        <li>Physical security : Unauthorized access to facilities</li>
      </ul>
      <p class="card-text">Authentication vs Authorization</p>
      <ul>
        <li>Authentication : process of establishing identity of a person</li>
        <li>Authorization : process of establishing what level of access an authenticated person has</li>
      </ul>
      <p class="card-text">Authentication strategy</p>
      <ul>
        <li>Single sign-on : access across applications is granted to a single identity/user, simplifying security model</li>
        <li>Multi-factor authentication : requires two or more elements for full authentication</li>
      </ul>
      <p class="card-text">Encryption</p>
      <ul>
        <li>Encryption : process of making data unreadable and unusable to unauthorized viewers</li>
        <li>Symmetric encryption : uses the same key to encrypt and decrypt the data</li>
        <li>Asymmetric encryption : uses public key and private key pair. Can use one key to encrypt but need both keys to decrypt. Ex. Transport Layer Security (TLS) used in HTTPS</li>
      </ul>
      <p class="card-text">Security concerns</p>
      <ul>
        <li>Input and outputs : Always validate input. Always use parameterized queries. Always encode your output</li>
        <li>Key Vault : Store connection strings, secrets, passwords, certificates, access policies, file locks, and automation scripts</li>
        <li>Framework : For example, Java/Javascript. Keep them updated</li>
        <li>Dependencies : Track vulnerabilities on your 3rd party dependencies</li>
      </ul>

      <p class="card-text">Active Directory - directory service implementation that provide authentication, group and user management, policy administration, etc. It supports both Kerberos and LDAP. It also provides SSO</p>
      <p class="card-text">LDAP (LightWeight Directory Acess Protocol) - open protocol used for directory service authentication</p>
      <p class="card-text">Relationship between AD and LDAP is similar to Apache and HTTP</p>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://medium.com/@kasunpdh/ssl-handshake-explained-4dabb87cdce">SSL Handshake explained</a> | <a href="https://www.varonis.com/blog/the-difference-between-active-directory-and-ldap/">The Difference Between Active Directory and LDAP</a>
    </div>
  </div>

  <div class="card mb-4" id="devops-10">
    <div class="card-body">
      <h2 class="card-title">10. Scaliability and Reliablity</h2>
      <h3>Scaling</h3>
      <ul>
        <li>Compute load patterns - consistent growth, constantly fluctuating loads, cyclical loads, unpredictable bursts</li>
        <li>Scale sets - load balancer distributes requests across VMs. Uses health probe to determine availability of each VM by pinging it</li>
        <li>Scaling up - adding more resources to a single instance (vertical scaling)</li>
        <li>Scaling out - addition of instances (horizontal scaling)</li>
      </ul>
      <h3>Strategies to achieve scalability and performance</h3>
      <ul>
        <li>Data partitioning - data partitions can be managed and accessed separately</li>
        <li>Caching - store frequently used data for fast retrieval. could be placed at database or application layer</li>
        <li>Autoscaling - dynamically allocate resources to match performance requirements</li>
        <li>Background jobs - tasks such as batch jobs, intensive processing tasks, and long-running processes should run as background jobs, decoupled from applicatio UI to minimize load</li>
        <li>Messaging - requests can continue to flow-in without error if application can’t keep up</li>
        <li>Scale units - define units for scaling</li>
      </ul>
      <h3>Architecting for availability</h3>
      <ul>
        <li>Recovery point objective - Maximum duration of acceptable data loss. For example, 30 minutes of data or four hours of data</li>
        <li>Recovery time objective - Maximum duration of acceptable downtime</li>
        <li>Design backup, restore, replication, and recovery capabilities based on above</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-11">
    <div class="card-body">
      <h2 class="card-title">11. Network</h2>
      <h3>Load balancing</h3>
      <ul>
        <li>Use of a dedicated instance (or a pair of instances) to dispatch incoming requests to back-end servers</li>
      </ul>
      <p class="card-text">Benefites</p>
      <ul>
        <li>Throughput is improved by parallel processing</li>
        <li>Yield higher availability</li>
        <li>SSL offload - client connects to load balancer via SSL, but redirect requests to servers are made via unencrypted HTTP to reduce load on the servers</li>
        <li>Caching - load balancer can cache popular requests</li>
      </ul>
      <p class="card-text">Serving response back</p>
      <ul>
        <li>Proxing - load balancer receives response from backend and relays it back to the client</li>
        <li>TCP Handoff - server sends response directly to the client</li>
      </ul>
      <p class="card-text">Types</p>
      <ul>
        <li>Equitable dispatching - uses simple round-robin algorithm to distribute traffic evenly between all nodes. For example, Elastic Load Balancer (ELB) of AWS</li>
        <li>Hash-based distribution - requests from the same client for the duration of session are directed to the same server every time by hashing metadata. Pros - store session data in memory than shared data storage like database or Redis cache. Cons - caching work causes small latency. For example, Azure Load Balancer</li>
      </ul>
      <h3>FQDN (Fully Qualified Domain Name)</h3>
      <ul>
        <li>Complete domain name of computer, host, or internet</li>
        <li>Ex. www.github.com - [hostname].[domain].[tld (top-level-domain)]</li>
        <li>When connecting to a host, FQDN must be specified. Then, DNS server finds IP address from the hostname looking at DNS table</li>
      </ul>
      <h3>Reverse proxy</h3>
      <ul>
        <li>Proxy sits on top of clients - used for blocking certain contents (servers are freely accessible through internet)</li>
        <li>Reverse proxy sit on top of servers - used for protection from attacks and SSL encrypting (clients can freely connect to internet)</li>
        <li>Can act as load-balancing but is also useful when there is a single server to increase security</li>
      </ul>
      <h3>Content delivery network</h3>
      <ul>
        <li>Servers closest to the geographic location of users visiting the website responds</li>
        <li>Servers at different geographic locations (CDN) cache the content of original server</li>
        <li>CDN communicates to the original server to deliver contents that have not been cached</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-12">
    <div class="card-body">
      <h2 class="card-title">12. Agile</h2>
      <h3>Waterfall</h3>
      <ul>
        <li>Emphasis on planning to come up with accurate estimates on deliverables</li>
        <li>Fixed deliverables in each phase</li>
        <li>Test and release beome major events in each phase</li>
      </ul>

      <h3>Agile</h3>
      <ul>
        <li>Allows deliverables to move in/out from each sprint (as long as total story points remain the same)</li>
        <li>Test and release happen in much greater frequency for each sprint</li>
        <li>Backlogs are refiend 2-3 sprints ahead and team agrees on each item</li>
      </ul>

      <h3>Agile Manifesto</h3>
      <ul>
        <li>Individuals and interactions</li>
        <li>Working software</li>
        <li>Customer collaboration</li>
        <li>Responding to change</li>
      </ul>
    </div>
    <div class="card-footer text-muted">
        Reference: <a href="https://agilemanifesto.org/">Agile Manifesto</a>
    </div>
  </div>

  <div class="card mb-4" id="devops-13">
    <div class="card-body">
      <h2 class="card-title">13. DevOps Culture and Metrics</h2>
      <p class="card-text">Goal is to achieve efficiency (more outputs with the same amount of time, which translates to value for the organization)</p>

      <h3>These are some characteristics of DevOps culture</h3>
      <ul>
        <li>There are standards of technologies (tools and programming languages) used across the organization</li>
        <li>Teams across the organization have the same sprint cadence</li>
        <li>All members in the team are participating in code reviews, not just few individuals</li>
        <li>Epics are typically delivered in every quarter and all stories and tasks are tied to epics</li>
        <li>All requirements are mapped to branches of code repository</li>
        <li>code is released on planned basis via "fix version"</li>
        <li>Stories and Tasks marked as either Done or Not Done at the end of each sprint</li>
        <li>Standard branching strategies such as git and/or github flows are used</li>
      </ul>

      <h3>DevOps Metrics</h3>
      <ul>
        <li>Deployment frequency and speed</li>
        <li>Size (amount of stories and tasks) delievered in each sprint</li>
        <li>Lead time: time from starting to work on a feature to deploying it in production</li>
        <li>Time from when errors are detected to when they are resolved</li>
        <li>Number of people involved in deployment</li>
        <li>Number of errors found in production</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-14">
    <div class="card-body">
      <h2 class="card-title">14. DB Basic</h2>
      <h3>Delete Vs. Truncate</h3>
      <ul>
        <li>Truncate - DDL (Data Definition Language), does not require commit to make the change permanent, deleted rows cannot be rolled back, always removes all rows from the table (table structure remains intact)</li>
        <li>Delete - DML (Data Manipulation Language), requires commit to make the change permanent, "where" clause can be used</li>
      </ul>
      <h3>DB indexing</h3>
      <ul>
        <li>Applying indexing on a field creates a data structure holding field value and pointer</li>
        <li>Data structure gets sorted so that search time can be O(logn) with binary search</li>
        <li>Fields with lots of duplicate values degrade benefits of indexing</li>
      </ul>
      <h3>Data types</h3>
      <ul>
        <li>Structured - relational data</li>
        <li>Semi-structured - ymal, json, xml</li>
        <li>Unstructured - photo, video, audio, text</li>
      </ul>
      <h3>Transaction (ACID)</h3>
      <ul>
        <li>Atomicity - either all is done or none is done</li>
        <li>Consistency - data is consistent before and after transaction</li>
        <li>Isolation - trasaction doesn't get affected by other transactions</li>
        <li>Durablility - transactions are permanently saved</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="devops-15">
    <div class="card-body">
      <h2 class="card-title">15. Pipelining</h2>
      <p class="card-text">There are few principles when build a good pipeline for large organizations</p>
      <ul>
        <li>Multiple pipelines to deliver each business case is better than one pipeline ruling the whole Enterprise. One pipeline can become a single point of failure. Moreover, product owner of backlog needs to adhere everyone's concern in the Enterprise, which become an impossible task</li>
        <li>Speed is the key. Complex and over-engineered pipeline increases the duration of feedback loop that can defeat the purpose of automation</li>
        <li>Open-source the code. One team owning private repositories of pipeline implementation puts them at indisputable position</li>
        <li>Minimize tooling. Be mindful that each tool put into the pipeline increases complexity and reduces speed</li>
      </ul>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://medium.com/dzerolabs/the-six-horsemen-of-the-devops-apocalypse-a26ee8846f1f">The Six Horsemen of the DevOps Apocalypse</a>
    </div>
  </div>

  <div class="card mb-4" id="devops-16">
    <div class="card-body">
      <h2 class="card-title">16. Message vs. Event</h2>
      <ul>
        <li>Message - used when communication needs guarantee to be processed. Contains raw data. </li>
        <li>Event - used for broadcasting communications (lighter than message). Has publishers and subscribers</li>
      </ul>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://medium.com/dzerolabs/the-six-horsemen-of-the-devops-apocalypse-a26ee8846f1f">The Six Horsemen of the DevOps Apocalypse</a>
    </div>
  </div>
  <!-- DevOps END -->


  <!-- Virtual Box BEGIN -->
  <div class="card mb-4" id="virtualbox">
    <div class="card-body">
      <h2 class="card-title">Virtual Box</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#virtualbox-1">1. How to load a linux VDI into Virtual Box</a></li>
        <li><a href="#virtualbox-2">2. Port mapping (8080) from Virtual machine to local machine</a></li>
        <li><a href="#virtualbox-3">3. Enabling copy and paste between local machine and VM</a></li>
        <li><a href="#virtualbox-4">4. Install dependencies</a></li>
        <li><a href="#virtualbox-5">5. Fixing internet problem inside VirtualBox</a></li>
        <li><a href="#virtualbox-6">6. Convert ISO image to VDI</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="virtualbox-1">
    <div class="card-body">
      <h2 class="card-title">1. How to load a linux VDI into Virtual Box</h2>
      <ul>
        <li>Download the latest VDI (64bit) from https://www.osboxes.org/centos</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-a.png" alt="Card image cap" style="max-width:500px">
        <li>From Virtual Box, create a new VM by pointing to the VDI downloaded</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-b.png" alt="Card image cap" style="max-width:300px">
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-c.png" alt="Card image cap" style="max-width:300px">
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-d.png" alt="Card image cap" style="max-width:300px">
        <li>You can adjust the virtual disk size by File->Virtual Media Manager->Properties</li>
        <li>Start the machine</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-e.png" alt="Card image cap" style="max-width:700px">
        <li>Log into the machines using the password "osboxes.org"</li>
        <li>Complete the OS setup</li>
        <li>Open the terminal and type "ip addr show" (Note the ip address in red box)</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-f.png" alt="Card image cap" style="max-width:500px">
        <li>From Virtual Box, go to File-&gt;Preferences-&gt;Network. Clicking &#34;Add&#34; Icon will make &#34;NatNetwork&#34; show up</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-g.png" alt="Card image cap" style="max-width:500px">
        <li>Click &#34;Edit&#34; Icon. From &#34;Port Forwarding&#34;, add Rule as following (Note the IP found from above steps)</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-h.png" alt="Card image cap" style="max-width:500px">
        <li>From Machine Settings-&gt;Network, choose the name &#34;NatNetwork&#34;</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-i.png" alt="Card image cap" style="max-width:500px">
        <li>SSH into your vm by <strong>ssh -p 2222 root@127.0.0.1</strong>. Password should be &#34;osboxes.org&#34;</li>
        <li>Turn off your machine</li>
        <li>Try starting VM headless <strong>/C/Program\ Files/Oracle/VirtualBox/VBoxManage startvm RHEL7 --type headless</strong></li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-j.png" alt="Card image cap" style="max-width:500px">
        <li>To turn off VM headless <strong>/C/Program\ Files/Oracle/VirtualBox/VBoxManage controlvm RHEL7 poweroff --type headless</strong></li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-k.png" alt="Card image cap" style="max-width:500px">
      </ul>

      <p class="card-text">Alternatively, an ISO disk can be used.</p>
      <ul>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-m.png" alt="Card image cap" style="max-width:500px"><br>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-n.png" alt="Card image cap" style="max-width:500px"><br>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-o.png" alt="Card image cap" style="max-width:500px"><br>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-p.png" alt="Card image cap" style="max-width:500px"><br>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-q.png" alt="Card image cap" style="max-width:500px"><br>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-r.png" alt="Card image cap" style="max-width:500px"><br>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-s.png" alt="Card image cap" style="max-width:500px">
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="virtualbox-2">
    <div class="card-body">
      <h2 class="card-title">2. Port mapping (8080) from Virtual machine to local machine</h2>
      <ul>
        <li>From Port Forwarding screen, add Rule 2. Use similar approach for other ports</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-2-a.png" alt="Card image cap" style="max-width:500px">
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="virtualbox-3">
    <div class="card-body">
      <h2 class="card-title">3. Enabling copy and paste between local machine and VM</h2>
      <ul>
        <li>From Machine Settings-&gt;General, Select &#34;Bidirectional&#34;</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-1-l.png" alt="Card image cap" style="max-width:500px">
        <li>If not working after applying above step, Find <strong>Devices</strong> from the menu bar, then click <strong>Insert Guest Addition CD Image</strong></li>
<pre><code class="bash"># Then from the terminal
sudo reboot</code></pre>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="virtualbox-4">
    <div class="card-body">
      <h2 class="card-title">4. Install dependencies (Ubuntu)</h2>
<pre><code class="bash"># Enabling ssh from local machine to virtual machine
sudo apt update
sudo apt upgrade
sudo apt install openssh-server
sudo systemctl status ssh</code></pre>

<pre><code class="bash"># Install docker
# Create a file at /etc/apt/sources.list.d/docker.list
# And add this line: deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable
sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt update
sudo apt-get install docker-ce docker-ce-cli containerd.io</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="virtualbox-5">
    <div class="card-body">
      <h2 class="card-title">5. Fixing internet problem inside VirtualBox</h2>
      <ul>
        <li>From Settings-&gt;Network, add additional "Bridged Adapter". Enter the information inside the red box. (If you use any other network/adapter, keep the same Advanced settings)</li>
        <img class="img-fluid" class="card-img-top" src="img/virtualbox/virtualbox-5-a.png" alt="Card image cap" style="max-width:500px">
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="virtualbox-6">
    <div class="card-body">
      <h2 class="card-title">6. Convert ISO image to VDI</h2>
<pre><code class="bash">./C/Program\ Files/Oracle/VirtualBox/VBoxManage.exe convertfromraw image.iso image.vdi</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Virtual Box END -->


  <!-- Git BEGIN -->
  <div class="card mb-4" id="git">
    <div class="card-body">
      <h2 class="card-title">GIT</h2>
      <ul class="list-unstyled mb-0">
        <li><a href="#git-1">1. Git flow</a></li>
        <li><a href="#git-2">2. Useful git commands</a></li>
        <li><a href="#git-3">3. Git concets</a></li>
        <li><a href="#git-4">4. Squashing commits</a></li>
        <li><a href="#git-5">5. Fork vs Clone</a></li>
        <li><a href="#git-6">6. Fix corrupt git repository</a></li>
        <li><a href="#git-7">7. Clone and sync</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="git-1">
    <div class="card-body">
      <h2 class="card-title">1. Git flow</h2>
      <p class="card-text"></p>
      <img class="img-fluid" class="card-img-top" src="img/git/git-1-a.png" alt="Card image cap">
      <ul>
        <li><strong>master</strong> - represent the state of production</li>
        <li><strong>release</strong> - br=anch to perform release. Must be merged into both develop and master branches</li>
        <li><strong>develop</strong> - branch for active development. All features branches must be cut from and merged to this branch</li>
        <li><strong>feature</strong> - branch for each developer working on a story/task. Developers should regularly pull from develop branch to keep feature branches up to date</li>
        <li><strong>hotfix</strong> - branch to quickly apply changes to master branch without going through full flow. Must be merged into both master and develop branches</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="git-2">
    <div class="card-body">
      <h2 class="card-title">2. Useful git commands</h2>
      <p class="card-text"></p>
<pre><code class="bash">git remote add origin [remoteUrl] # make the local repository aware of the remote</code></pre>

<pre><code class="bash">git config --list # show the current git config
git config --global user.name &lt;name&gt; # add name
git config --global user.email &lt;email&gt; # add email/code></code></pre>

<pre><code class="bash">git status # show files that have added, modified, and deleted
git add -A # move files to "staged"
git commit -am &lt;message&gt; # move files to "commited"/code>
git push origin &lt;branch&gt; # apply your changes to a particular branch on remote repository</code></pre>

<pre><code class="bash">git pull origin &lt;branch&gt; # pull code from a particular branch on remote repository into your local workspace
git checkout -b &lt;branch&gt; # create a new branch whose code base will be your local workspace/code>
git checkout &lt;branch&gt; # check out code base from a particular branch</code></pre>

<pre><code class="bash">git branch -d &lt;branch&gt; # delete a particular branch from your local
git push origin -d &lt;branch&gt; # delete a particular branch from remote repository
git tag -d &lt;tag&gt; # delete a tag from your local
git push origin -d &lt;tag&gt; # delete a tag from remote repository/code></code></pre>

<pre><code class="bash">git fetch # update tracking of remote branches
git fetch --prune # remove local branches the do not exist in remote
git branch -a # display local and remote branches</code></pre>

<pre><code class="bash">git reflog # Show lost commit
git reset --hard &lt;commit_hash&gt; & git push -f origin [branch] # revert to previous commit in the remote
git fetch --all && git reset --hard origin/[branch_name] # force overwrite local with remote</code></pre>

<pre><code class="bash"># Remove all untracked files.
git clean -f</code></pre>

<!-- <pre><code class="bash">branch=feature; for i in $(git branch | grep $branch); do git branch -D $branch/${i##/*}; done # delete all feature branches in the local
branch=feature; for i in $(git branch -a | grep remotes/origin/$branch); do git push origin --delete $branch/${i##/*} | sort -u; done # delete all feature branches in the remote</code></pre> -->

<!-- probably should use "git branch | grep -v "master" | xargs git branch -D "-->
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="git-3">
    <div class="card-body">
      <h2 class="card-title">3. Git concepts</h2>
      <p class="card-text"></p>
<pre><code class="bash">git add # move files from "untracked/modified" state to "staged" state
git commit # move files from "staged" state to "committed" state</code></pre>

<pre><code class="bash">git fetch # gather commits from remote that don't exist in local
git merge # integrate commits to your branch
git pull # git fetch + git merge</code></pre>

<pre><code class="bash">branch # a version of code
git cherry-pick # get a commit from one branch and integrate to another branch
HEAD # last commit of current branch</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="git-4">
    <div class="card-body">
      <h2 class="card-title">4. Squashing commits</h2>
      <p class="card-text">When there are too many commits, it may be hard for other people to review your pull requests. Squashing commits comes handy</p>
<pre><code class="bash"># Search your commit history and pick the one you want to squash commits from.
git log --oneline

# This opens nano editor. Use reword/pick/squash to specify what you want to do for each commit. Ctrl-O &amp; Ctrl-T will write your changes.
git rebase -p -i &lt;commit_hash&gt;

# Observe that commits have been squashed.
git log --oneline

# This opens nano editor. Enter new commit message. Ctrl-O &amp; Ctrl-T will write your changes.
git commit --amend

# Finally push the changes to your branch.
git push -f origin &lt;branch&gt;</code></pre>

<pre><code class="bash"># How to handle "Cannot 'squash' without a previous commit error"
# Rather than using pick "p", use reword "r" such that
r &lt;commit_hash&gt; &lt;commit_message&gt;
s &lt;commit_hash&gt; &lt;commit_message&gt;
s &lt;commit_hash&gt; &lt;commit_message&gt;
s &lt;commit_hash&gt; &lt;commit_message&gt;
s &lt;commit_hash&gt; &lt;commit_message&gt;
# Then, rename the first commit</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="git-5">
    <div class="card-body">
      <h2 class="card-title">5. Fork vs Clone</h2>
      <p class="card-text">Fork - server side copy of repository</p>
      <p class="card-text">Clone - local copy of repository in a server (include history and branches)</p>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="git-6">
    <div class="card-body">
      <h2 class="card-title">6. Fix corrupt git repository</h2>
<pre><code class="bash">rm -rf .git
git init
git remote add origin &lt;clone_url&gt;
git fetch
git reset origin/master</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="git-7">
    <div class="card-body">
      <h2 class="card-title">7. Clone and sync</h2>
<pre><code class="bash">git clone --bare --quiet $git_clone_url_to_copy_from
git push --mirror --quiet $git_clone_url_to_copy_into</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Git END -->


  <!-- Python BEGIN -->
  <div class="card mb-4" id="python">
    <div class="card-body">
      <h2 class="card-title">Python</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#python-1">1. Python Basic</a></li>
        <li><a href="#python-2">2. PEP 8</a></li>
        <li><a href="#python-3">3. Python useful syntax</a></li>
        <li><a href="#python-4">4. Numpy useful syntax</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="python-1">
    <div class="card-body">
      <h2 class="card-title">1. Python Basic</h2>
      <h3 class="card-title">Installation</h3>
<pre><code class="python"># RHEL
# Install.
yum update -y
yum install python3-pip -y
# Verify.
rpm -qa | grep -i python3-pip
pip3 -V
# Upgrade.
pip3 install --upgrade pip
# Uninstall.
yum remove python3-pip -y</code></pre>

      <h3 class="card-title">Version check</h3>
<pre><code class="python"># From command line, find the default python
which python</code></pre>

<pre><code class="python"># From the script,
# /usr/bin/env python3.6
# OR
# /usr/bin/env python2.7

import sys
print(sys.version_info)</code></pre>

      <h3 class="card-title">Code execution</h3>
      <p class="card-text">No type checking until runtime (dynamically typed)</p>
      <p class="card-text">Code gets compiled before getting executed (but there is no noticible compilation phase so we normally say it is interpreted language)</p>
      <p class="card-text">Written in C language and runs natively (Other variations include Jython, which is written in Java and runs on JVM)</p>
      <p class="card-text">REPL: Read -> Evaluate -> Print -> Loop</p>

      <h3 class="card-title">Syntax</h3>
      <p class="card-text">Numbers : Operators include // (division discarding fraction), % (remainder), ** (power)</p>
      <p class="card-text">String : type "str". immutable. can be indexed. can be sliced[a:b] where a is included, b is excluded</p>
      <p class="card-text">Lists : mutable. list.append(x), list.remove(x), list.count(x), len(list) method</p>
      <p class="card-text">Stack using list : use list.append(x) and list.pop()</p>
      <p class="card-text">Queue using list : inefficient. Instead use "from collections import deque" and deque.append(x) & deque.popleft()</p>
      <p class="card-text">Dictionary : key-value pair data structure</p>
      <p class="card-text">Range : To use range(1,10) as a list, do list(range(1,10))</p>
      <p class="card-text">Tuple : immutable</p>
      <p class="card-text">Set : no duplicate</p>
      <p class="card-text">Types : "int", "float", "None", "bool" (True/False)</p>
      <p class="card-text">Relational Operators : "==", "!=", etc</p>
      <p class="card-text">"break" keyword terminates the loop and jump to first statement after the loop</p>
      <br>
      <p class="card-text">Shebang : identify which interpreter is used for the program. For example, #!/usr/bin/env python3</p>
      <p class="card-text">Value - equivalent content ("==" operator). Identity - same object ("is" operator)</p>
      <p class="card-text">Arguments are passed by object-reference (mutable objects can be modified)</p>
      <p class="card-text">Everything is object</p>
      <br>
      <p class="card-text">built-in types : int, float, str, list, dict</p>
      <p class="card-text">packages - generally directories</p>
      <p class="card-text">modules - generally files</p>
      <br>
      <p class="card-text">Syntactic sugar for normal function definition
<pre><code class="python">lambda a, b: a+b</code></pre></p>
      <p class="card-text">Standard libraries : "math", etc</p>
<pre><code class="python">import module
from module import function
from module import function as alias
</code></pre>
      <p class="card-text">How to execute python script containing functions</p>
<pre><code class="python">if __name__ == "__main__":
function()</code></pre>
      <p class="card-text">How to read command line parameter</p>
<pre><code class="python">import sys
sys.argv[]</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="python-2">
    <div class="card-body">
      <h2 class="card-title">2. PEP 8</h2>
      <p class="card-text">PEP 8 is a guideline for best practices in writing Python code.</p>

      <p class="card-text">1. Use 4 spaces per indention level. Observe "hanging" indentation.</p>
<pre><code class="python"># Good
foo = long_function_name(var_one, var_two,
                     var_three, var_four)

# hanging indent example (no arguments in the first line of the function)
var = function(
arg_one, arg_two,
arg_three, arg_four)

# Bad
foo = long_function_name(var_one, var_two,
var_three, var_four)

# Good
def long_function_name(
    var_one, var_two, var_three,
    var_four):
print(var_one)

# Bad
def long_function_name(
var_one, var_two, var_three,
var_four):
print(var_one)</code></pre>

      <p class="card-text">2. Limit all lines to maximum 79 characters. (72 for docstrings and comments)</p>

      <p class="card-text">3. Watch the line break rule for operators.</p>
<pre><code class="python"># Good
income = (gross_wages
      + taxable_interest)

# Bad
income = (gross_wages +
      taxable_interest)</code></pre>

      <p class="card-text">4. Imports should be on separate lines.</p>
<pre><code class="python"># Good
import os
import sys

from subprocess import Popen, PIPE

# Bad
import sys, os</code></pre>
      <p class="card-text">Order of imports should be (also there should be line breaks between each type of import)</p>
      <ul>
        <li>Standard library imports</li>
        <li>Related third party imports</li>
        <li>Local application/library specific imports</li>
      </ul>
      <p class="card-text">Wildcard imports should be avoided</p>

      <p class="card-text">5. Avoid unnecessary whitespace.</p>
<pre><code class="python"># Good
spam(ham[1], {eggs: 2})

# Bad
spam( ham[ 1 ], { eggs: 2 } )

# Good
x = 1
y = 2
long_variable = 3

# Bad
x             = 1
y             = 2
long_variable = 3

# Good
i = i + 1
submitted += 1
x = x*2 - 1
hypot2 = x*x + y*y
c = (a+b) * (a-b)

# Bad
i=i+1
submitted +=1
x = x * 2 - 1
hypot2 = x * x + y * y
c = (a + b) * (a - b)

# Good
if x>5 and x%2==0:
print('x is larger than 5 and divisible by 2!')

# Bad
if x > 5 and x % 2 == 0:
print('x is larger than 5 and divisible by 2!')

# Good
def complex(real, imag=0.0):
return magic(r=real, i=imag)

# Bad
def complex(real, imag = 0.0):
return magic(r = real, i = imag)</code></pre>

      <p class="card-text">6. Comments should be complete sentences with first character capitalized. Don't use inline comments to explain obvious fact.</p>

      <p class="card-text">Doc string shall look something like</p>
<pre><code class="python">"""Retrive and print words from URL

Usage:
python3 words.py &lt;URL&gt;
"""

def fetch_words(url):
"""Fetch a list of words from URL.

Args:
url: the URL of document

Returns:
A list of strings containing words from the document
"""</code></pre>

      <p class="card-text">7. Naming convention</p>
      <ul>
        <li>Never use l, O, I as variable names.</li>
        <li>Classname should be CapWords. (same convention should be used for Exceptions)</li>
        <li>Functions and variables should be all lowercase separated by spaces.</li>
        <li>Leading underscore is for non-public method only.</li>
        <li>Constants should be all uppercase separated by underscores.</li>
      </ul>

      <p class="card-text">8. Programming convention</p>

<pre><code class="python"># Use ''.startswith() and ''.endswith() instead of string slicing.

# Good
if foo is not None:

# Bad
if not foo is None:

# Good
def f(x): return 2*x

# Bad
f = lambda x: 2*x

# Good
if isinstance(obj, int):

# Bad
if type(obj) is type(1):</code></pre>

      <p class="card-text">For sequences, (strings, lists, tuples), use the fact that empty sequences are false</p>

<pre><code class="python"># Good
if not seq:
# Bad
if len(seq):

# Good
if greeting:

# Bad
if greeting == True:
if greeting is True:</code></pre>

      <p class="card-text">9. Line breaks</p>

      <p class="card-text">Surround top-level functions and classes with two blank lines.</p>

<pre><code class="python">class MyFirstClass:
pass


class MySecondClass:
pass


def top_level_function():
return None</code></pre>

      <p class="card-text">Surround method definitions inside classes with a single blank line.</p>

<pre><code class="python">class MyClass:
def first_method(self):
    return None

def second_method(self):
    return None</code></pre>

      <p class="card-text">10. Spanning multiple lines</p>

<pre><code class="python">x = 5
if (x > 3 and
x < 10):
# Both conditions satisfied
print(x)</code></pre>

<pre><code class="python">string = "I am a long long long long long long long long long" \
     " long long long long string."</code></pre>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://www.python.org/dev/peps/pep-0008">PEP 8 -- Style Guide for Python Code</a>, <a href="https://realpython.com/python-pep8">How to Write Beautiful Python Code With PEP 8</a>
    </div>
  </div>

  <div class="card mb-4" id="python-3">
    <div class="card-body">
      <h2 class="card-title">3. Python useful syntax</h2>
<pre><code class="python"># File

# Read file.
f = open("myfile.txt", "r")
print(f.read())
print(f.readlines())


# String

# Split string by line break and store it in a list.
string.splitlines()

# Convert to lowercase.
string.lower()

# Remove newline char.
string.strip()

all_words = re.findall(r'\w+', string)

# Check type of object.
type(obj)


# Loops

# Loop backward. (the thrid argument represents 'step')
range(start,stop,-1)


# Conditional

# Inline if/else statement.
x = a if b else 0


# List

# Init an array with size 10.
array = [None]*10

# Remove an item from list.
list.remove(element)

# Prepend an item into list.
list.insert(0, element)

# Append an item into list.
list.append(element)


# Dictionary

# Get items in the dictionary by the index.
list(my_dict.keys())[0]

# Check if key exists in dictionary.
if key in my_dict

# Iterate dictionary.
for key, val in dict.items():

# Get keys of dictionary.
dict.keys()

# Get values of dictionary.
dict.values()

# Init a dictionary whose keys are 0,1,2 ... and values are empty lists.
{new_list: [] for new_list in range(10)}


# Json

# Converts Python dictionary into JSON string data.
json.dump()

# Converts Python JSON string into dictionary.
json.loads()


# Try / catch
try:
  # do something
except:
  rause Exception("Exception message")</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="python-4">
    <div class="card-body">
      <h2 class="card-title">4. Numpy useful syntax</h2>
<pre><code class="python">A.T # Transpose a matrix.
np.exp(x) # Take exponent.
np.array(x, ndmin=2) # Convert a list to one dimensional matrix.

norm = np.linalg.norm(array) # Norm of array.
norm = np.linalg.norm(array1-array2) # Euclidean distance between two vectors represented by array1 and array2.

a = np.array([[1, 2], [3, 4]])
np.mean(a)
np.mean(a, axis=0) # [2, 3]
np.mean(a, axis=1) # [1.5, 3.5]

array_sorted = np.sort(array) # Sort in increasing order.
array_sorted_reverse = array_sorted[::-1] # Sort in decreasing order.
index_sorted = np.argsort(array) # Get indexes of sorted array.

A = np.array([[2, 2],[2, 2]])
A_squared = np.square(A)
A_Frobenius = np.sqrt(np.sum(A_squared)) # Compute Frobenius norm.

h = h.astype(int) # Convert True/False array to 0/1 array.
h = np.squeeze(h) # Reduce dimension.

# Create a numpy array with random normally distributed values.
mu, sigma = 0, 0.1 # Mean and standard deviation.
np.random.normal(mu, sigma, 1000)</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Python END -->


  <!-- Anaconda BEGIN -->
  <div class="card mb-4" id="anaconda">
    <div class="card-body">
      <h2 class="card-title">Anaconda</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#anaconda-1">1. Setup Environment</a></li>
        <li><a href="#anaconda-2">2. Delete Kernel</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="anaconda-1">
    <div class="card-body">
      <h2 class="card-title">1. Setup Environment</h2>
      <p class="card-text">From Anaconda Navigator</p>
      <img class="img-fluid" class="card-img-top" src="img/anaconda/1.png" alt="Card image cap">
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="anaconda-2">
    <div class="card-body">
      <h2 class="card-title">2. Delete Kernel</h2>
<pre><code class="bash"># From "Anaconda Prompt"
jupyter kernelspec list
jupyter kernelspec uninstall [unwanted-kernel]</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Anaconda END -->


  <!-- Groovy BEGIN -->
  <div class="card mb-4" id="groovy">
    <div class="card-body">
      <h2 class="card-title">Groovy</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#groovy-1">1. Groovy Basic (used in Jenkins pipeline)</a></li>
      </ul>
    </div>
  </div>


  <div class="card mb-4" id="groovy-1">
    <div class="card-body">
      <h2 class="card-title">1. Groovy Basic (used in Jenkins pipeline)</h2>
<pre><code class="groovy">// Groovy common imports
import com.cloudbees.groovy.cps.NonCPS
import groovy.json.JsonBuilder
import groovy.json.JsonOutput
import groovy.json.JsonSlurper
import groovy.json.JsonSlurperClassic

// Groovy commenting
/**
* Description about the method
* @param param1 description about param1
*        param2 description about param2
* @return return value
*/

// "NonCPS" annotation
// This annotation will tell Groovy not to Serialize the method. During the code execution, unserialized code may not be interruptable.
// This annotation is used for example when a method is called instande a constructor, when working with file stream, etc.

// Groovy map example.
Map map = [
  key: [
      subkey1: "value"
      subkey2: [
          subsubkey1: "value",
          subsubkey2: "value"
      ]
  ]
]

// Initialize a map.
Map map = [:]

// Loop through a map.
map.each {
  // do something with "it" (for example, "it.key" and "it.value")
}

// Find the value by key in a map.
map.find { it.key.toString().trin() == "key" }?.value

// Check if a map/dictionary contains a key.
if (dict.containsKey()) {

}

// Add to a map/dictionary.
dict.put("key", "value")


// Find files in the current directory.
findFiles(glob: '*.yaml')

// Check if file exists.
def absolutePath = "absolute path of the file"
File file = new File(absolutePath)
file.exists()

// Create a file with content.
writeFile(file: "fileName", text: fileContent)

// Read a file into a variable.
readFile "fileName"


// Convert YAML to JSON.
def absolutePath = "absolute path of the YAML file"
def fileInYaml = readYaml file: absolutePath
def fileInJson = new JsonBuilder(fileInYaml).toPrettyString()

// Convert JSON string to JSON object.
jsonObject = new JsonSlurperClassic().parseText(jsonString)

// Convert JSON object to JSON string.
jsonString = new JsonBuilder(jsonObject).toPrettyString()

// Create a JSON string.
String json = new JsonBuilder([
  field1: value1,
  field2: value2,
  field3: value3
]).toString()


// Loop through a list.
for (i in list) {
  // do something with "i"
}

// Convert String to a list.
String myListInString = "['first', 'second', 'third']"
def myList = myListInString[1..-2].split(', ')


// In-line if/else: If a is null, b is assgiend. Else, c is assigned.
def val = (a == null) ? b : c

// Break the outerloop in a nested loop.
loop:
for (foo in foos) {
  for (var in vars) {
      if (condition) {
          break loop
      }
  }
}


// Switch
switch(variable) {
  case "value1":
      // Do something.
      break
  case "value2":
      // Do something.
      break
  default:
      // Do something.
}


// Pipeline methods
stage("stage name")
dir("directory name")
withEnv(["ENV_VAR_NAME1=${variable1}", "ENV_VAR_NAME2=${variable2}"])
withCredentials([usernamePassword(credentialsId: credentialObjectId, passwordVariable: "PASSWORD",  usernameVariable: "USERNAME")])

String credentialId = scm.getUserRemoteConfigs()[0].getCredentialsId()
sshagent([credentialId])

env.getProperty("string_parameter") // Get the value of a parameter to a Jenkins Job


// Http request plugin
httpRequest(
  authentication: credentialObjectId,
  contentYpe: "APPLICATION_JSON",
  httpMode: "GET",
  customHeaders: "",
  url: "",
  ignoreSslErrors: true
)

// Downloads a file
httpRequest(
  url "",
  responseHandle: "NONE",
  outputFile: "",
  timeout: ""
)


// Bash integration
String variable = sh returnStdout: true, script: 'some bash command'</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Groovy END -->


  <!-- Java BEGIN -->
  <div class="card mb-4" id="java">
    <div class="card-body">
      <h2 class="card-title">Java</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#java-1">Search for JAR</a></li>
        <li><a href="#java-2">Work with WAR</a></li>
        <li><a href="#java-3">JDK</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="java-1">
    <div class="card-body">
      <h2 class="card-title">Search for JAR</h2>
      <h3 class="card-title">In linux process</h3>
<pre><code class="bash">ps faux # Shows parent and child processes.
ps aux | grep java # Shows Java processes.
ps aux | grep java | awk '{print $2}' # Only show process ids.
lsof -p &lt;pid&gt; # Show everything about this process.</code></pre>

      <h3 class="card-title">Inside a jar</h3>
<pre><code class="bash">unzip &lt;name&gt;.jar && cd &lt;name&gt;
grep -rnw ./ -e '&lt;jar file to find&gt;'</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="java-2">
    <div class="card-body">
      <h2 class="card-title">Work with WAR</h2>
<pre><code class="bash"># Extract a WAR file.
jar -xvf &lt;name&gt;.war

# Create a WAR file.
jar -cvf &lt;name&gt;.war &lt;directory&gt;</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="java-3">
    <div class="card-body">
      <h2 class="card-title">JDK</h2>
<pre><code class="bash"># Check JDK location.
which java</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Java END -->


  <!-- Hadoop BEGIN -->
  <div class="card mb-4" id="hadoop">
    <div class="card-body">
      <h2 class="card-title">Hadoop</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#hadoop-1">Start with Hadoop</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="hadoop-1">
    <div class="card-body">
      <h2 class="card-title">Start with Hadoop</h2>
<pre><code class="bash"># First, open etc/hadoop/hadoop-env.sh and add JAVA_HOME environment variable.
# If permission error, do the following.
cd ~/.ssh && ssh-keygen -t rsa -p""
cat id_rsa.pub >> authorized_keys

# Start Hadoop service.
sbin/start-dfs.sh

# If needed, add to the path.
export PATH=$PATH:$HADOOP_HOME/bin

# Note that copying/pasting hadoop commands into the terminal may not work.
# Check hadoop version.
hadoop version

# Create a directory /tmp/test
hadoop fs -mkdir -p /tmp/test
hadoop fs -ls /tmp/test
hadoop fs -du -s /tmp/test
hadoop fs -df -h

# Create a file.
hadoop fs -touchz /tmp/test/file

# Empty out the trash.
hadoop fs -expunge</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Hadoop END -->


  <!-- Hadoop BEGIN -->
  <div class="card mb-4" id="spark">
    <div class="card-body">
      <h2 class="card-title">Spark</h2>
      <p class="card-text"></p>
      <ul class="list-unstyled mb-0">
        <li><a href="#spark-1">Start with Spark</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="spark-1">
    <div class="card-body">
      <h2 class="card-title">Start with Spark</h2>
<pre><code class="bash">bin/spark-shell
# Read a file from local file system.
val data = sc.textFile("tmp/test/file")
val num = Array(1,2,3,4,5,6,7,8,9)
val NewData = sc.parallelize(num)
NewData.count()
# Type Ctrl-D to exit.</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Hadoop END -->


  <!-- Terraform BEGIN -->
  <div class="card mb-4" id="terraform">
    <div class="card-body">
      <h2 class="card-title">Terraform</h2>
      <ul class="list-unstyled mb-0">
        <li><a href="#terraform-1">1. Terraform with Google Cloud</a></li>
        <li><a href="#terraform-2">2. Example: main.tf</a></li>
        <li><a href="#terraform-3">3. Example: vpc.tf</a></li>
        <li><a href="#terraform-4">4. Example: network.tf</a></li>
        <li><a href="#terraform-5">5. Example: instance.tf</a></li>
        <li><a href="#terraform-6">6. Install Terraform (version 0.11.13) in CentOS</a></li>
        <li><a href="#terraform-7">7. Terraform with GCP - common errors</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="terraform-1">
    <div class="card-body">
      <h2 class="card-title">1. Terraform with Google Cloud</h2>
      <p class="card-text">Commands to compile and provision infrastructure with Terraform</p>
      <ul>
        <li>terraform init</li>
        <li>terraform plan</li>
        <li>terraform apply</li>
        <li>terraform destroy (this command tears down instances deployed to GCP)</li>
      </ul>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://medium.com/slalom-technology/a-complete-gcp-environment-with-terraform-c087190366f0">A complete GCP environment with Terraform</a>
    </div>
  </div>

  <div class="card mb-4" id="terraform-2">
    <div class="card-body">
      <h2 class="card-title">2. Example: main.tf</h2>

<pre><code class="groovy">provider "google" {
credentials = "${file("../../googlecloud/credential.json")}"
project     = "${var.project}"
}

module "vpc" {
source                 = "../modules/global"
var_env                = "${var.env}"
var_company            = "${var.company}"
var_region_name        = "${var.region_name}"
var_ue1_public_subnet  = "${var.ue1_public_subnet}"
var_ue1_private_subnet = "${var.ue1_private_subnet}"
}

module "ue1" {
source                 = "../modules/ue1"
var_env                = "${var.env}"
var_company            = "${var.company}"
var_region_name        = "${var.region_name}"
var_ue1_public_subnet  = "${var.ue1_public_subnet}"
var_ue1_private_subnet = "${var.ue1_private_subnet}"
network_self_link      = "${module.vpc.vpc_self_link}"
subnetwork1            = "${module.ue1.public_subnet_name}"
}</code></pre>

        <p class="card-text">Source code is available at <a href="https://github.com/riehseun/terraform-ansible/blob/master/main/main.tf">main.tf</a></p>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://medium.com/slalom-technology/a-complete-gcp-environment-with-terraform-c087190366f0">A complete GCP environment with Terraform</a>
      </div>
  </div>

  <div class="card mb-4" id="terraform-3">
    <div class="card-body">
      <h2 class="card-title">3. Example: vpc.tf</h2>

<pre><code class="groovy">resource "google_compute_network" "vpc" {
name                    = "${format("%s","${var.var_company}-vpc")}"
auto_create_subnetworks = "false"
routing_mode            = "GLOBAL"
}

resource "google_compute_firewall" "allow-internal" {
name    = "${var.var_company}-fw-allow-internal"
network = "${google_compute_network.vpc.name}"
allow {
protocol = "icmp"
}
allow {
protocol = "tcp"
ports    = ["0-65535"]
}
allow {
protocol = "udp"
ports    = ["0-65535"]
}
}

resource "google_compute_firewall" "allow-http" {
name    = "${var.var_company}-fw-allow-http"
network = "${google_compute_network.vpc.name}"
allow {
protocol = "tcp"
ports    = ["80"]
}
target_tags = ["http"]
}

resource "google_compute_firewall" "allow-bastion" {
name    = "${var.var_company}-fw-allow-bastion"
network = "${google_compute_network.vpc.name}"
allow {
protocol = "tcp"
ports    = ["22"]
}
target_tags = ["ssh"]
}</code></pre>

        <p class="card-text">Source code is available at <a href="https://github.com/riehseun/terraform-ansible/blob/master/modules/global/vpc.tf">vpc.tf</a></p>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://medium.com/slalom-technology/a-complete-gcp-environment-with-terraform-c087190366f0">A complete GCP environment with Terraform</a>
      </div>
  </div>

  <div class="card mb-4" id="terraform-4">
    <div class="card-body">
      <h2 class="card-title">4. Example: network.tf</h2>

<pre><code class="groovy">resource "google_compute_subnetwork" "public_subnet" {
name          = "${format("%s","${var.var_company}-${var.var_env}-${var.var_region_name}-pub-net")}"
ip_cidr_range = "${var.var_ue1_public_subnet}"
network       = "${var.network_self_link}"
region        = "${var.var_region_name}"
}

resource "google_compute_subnetwork" "private_subnet" {
name          = "${format("%s","${var.var_company}-${var.var_env}-${var.var_region_name}-pri-net")}"
ip_cidr_range = "${var.var_ue1_private_subnet}"
network       = "${var.network_self_link}"
region        = "${var.var_region_name}"
}</code></pre>

        <p class="card-text">Source code is available at <a href="https://github.com/riehseun/terraform-ansible/blob/master/modules/ue1/network.tf">network.tf</a></p>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://medium.com/slalom-technology/a-complete-gcp-environment-with-terraform-c087190366f0">A complete GCP environment with Terraform</a>
      </div>
  </div>

  <div class="card mb-4" id="terraform-5">
    <div class="card-body">
      <h2 class="card-title">5. Example: instance.tf</h2>

<pre><code class="groovy">resource "google_compute_instance" "vm1" {
name          = "k8s-master"
machine_type  = "n1-standard-2"
zone          = "${format("%s","${var.var_region_name}-c")}"

tags          = ["ssh","http"]

boot_disk {
initialize_params {
image = "centos-7-v20180129"
}
}

metadata {
foo = "bar"
}

network_interface {
subnetwork = "${google_compute_subnetwork.public_subnet.name}"

access_config {
// Ephemeral IP
}
}

provisioner "remote-exec" {
# You cannot open interactive session with "sudo -i". You must also run all yum commands with -y flag
inline = [
"sudo yum install ansible -y"
]

connection {
host        = "${self.network_interface.0.access_config.0.nat_ip}"
type        = "ssh"
user        = "${var.ssh_user}"
private_key = "${file("~/.ssh/id_rsa")}"
}
}

provisioner "local-exec" {
# Environment variable can be used inside ansible playbook
environment {
PUBLIC_IP                 = "${self.network_interface.0.access_config.0.nat_ip}"
HOSTNAME                  = "k8s-master"
ANSIBLE_HOST_KEY_CHECKING = false # This is must to avoid the error "The authenticity of host can't be established"
}

# You must install "ansible" on the machine where terraform-ansible suites get executed
# Add "-vvv" for verbose output
command     = "ansible-playbook -u ${var.ssh_user} --private-key ~/.ssh/id_rsa ../ansible/k8s-master.yaml -i $PUBLIC_IP,"
}
}</code></pre>

        <p class="card-text">Source code is available at <a href="https://github.com/riehseun/terraform-ansible/blob/master/modules/ue1/instance.tf">instance.tf</a></p>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://medium.com/slalom-technology/a-complete-gcp-environment-with-terraform-c087190366f0">A complete GCP environment with Terraform</a>
      </div>
  </div>

  <div class="card mb-4" id="terraform-6">
    <div class="card-body">
      <h2 class="card-title">6. Install Terraform (version 0.11.13) in CentOS</h2>
      <ul>
        <li>yum install -y zip unzip</li>
        <li>wget https://releases.hashicorp.com/terraform/0.9.8/terraform_0.11.13_linux_amd64.zip</li>
        <li>unzip terraform_0.11.13_linux_amd64.zip</li>
        <li>mv terraform /usr/local/bin/</li>
        <li>terraform --version</li>
      </ul>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://linuxacademy.com/community/posts/show/topic/18181-can-somebody-explain-how-to-install-terraform">Linux Academy</a>
    </div>
  </div>

  <div class="card mb-4" id="terraform-7">
    <div class="card-body">
      <h2 class="card-title">7. Terraform with GCP - common errors</h2>
      <ul>
        <li><strong>"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe</strong> - This happens when the date and time of OS is out of sync. Run <strong>date +%T -s "10:13:13"</strong> [10: Hour (hh) 13: Minute (mm) 13: Second (ss)] to update it.</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Terraform END -->


  <!-- Salt BEGIN -->
  <div class="card mb-4" id="salt">
    <div class="card-body">
      <h2 class="card-title">Salt</h2>
      <ul class="list-unstyled mb-0">
        <li><a href="#salt-1">1. Salt API</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="salt-1">
    <div class="card-body">
      <h2 class="card-title">1. Salt API</h2>

      <p class="card-text">Test to see if Salt API is callable</p>
<pre><code class="python">salt -a pam \* test.ping</code></pre>

      <p class="card-text">Add credential(s) to call Salt API</p>
<pre><code class="python">/etc/salt/master.d/auth.conf</code></pre>

      <p class="card-text">Restart Salt master</p>
<pre><code class="python">sudo service salt-master restart</code></pre>

      <p class="card-text">Check logs</p>
<pre><code class="python">/var/log/salt/master</code></pre>

      <p class="card-text">Check minion configuration</p>
<pre><code class="python">/etc/salt/minion.d/minion.conf</code></pre>

      <p class="card-text">Salt call</p>
<pre><code class="python"># Sync salt modules from master to minion.
sudo salt-call saltutil.sync

# Run all states.
sudo salt-call state.highstate

# Run only a specific state.
sudo salt-call state.apply &lt;state_name&gt;</code></pre>

    </div>
    <div class="card-footer text-muted">

    </div>
  </div>
  <!-- Salt END -->


    <!-- Ansible BEGIN -->
<!--                 <div class="card mb-4" id="ansible">
        <div class="card-body">
            <h2 class="card-title">Ansible</h2>
            <ul class="list-unstyled mb-0">
                <li><a href="#ansible-1">1. Set up Kubernetes master</a></li>
            </ul>
        </div>
    </div>

    <div class="card mb-4" id="ansible-1">
        <div class="card-body">
            <h2 class="card-title">Set up Kubernetes master</h2>

<pre><code class="groovy">---
- name: Kubernetes master installation
hosts: all # value here is important!
remote_user: Rieh
become: true</code></pre>

        </div>
        <div class="card-footer text-muted"></div>
    </div> -->
    <!-- Ansible END -->


    <!-- Cloudify BEGIN -->
    <!-- <div class="card mb-4" id="cloudify">
        <div class="card-body">
            <h2 class="card-title">Cloudify</h2>
            <ul class="list-unstyled mb-0">
                <li><a href="#cloudify-1">1. Cloudify with Google Cloud</a></li>
            </ul>
        </div>
    </div>

    <div class="card mb-4" id="cloudify-1">
        <div class="card-body">
            <h2 class="card-title">Cloudify with Google Cloud</h2>
            <p class="card-text">How to setup Cloudify Manager on Redhat</p>
            <ul>
                <li>Install docker from <a href="#docker-8">Installing Docker on Redhat</a></li>
                <li>Run - <strong>sudo docker run --name cfy_manager_local -d --restart unless-stopped -v /sys/fs/cgroup:/sys/fs/cgroup:ro --tmpfs /run --tmpfs /run/lock --security-opt seccomp:unconfined --cap-add SYS_ADMIN -p 80:80 -p 8000:8000 cloudifyplatform/community:18.10.4</strong></li>
                <img class="img-fluid" class="card-img-top" src="img/cloudify/cloudify-1-a.png" alt="Card image cap" style="max-width:500px">
                <li>SSH into docker machine - <strong>docker exec -it cfy_manager_local /bin/bash</strong></li>
                <li>Install plugins <strong>cfy plugins bundle-upload</strong></li>

                <li>Create <strong>Service Account Key</strong> from Google Cloud Console. Upon creation, you can download the key in Json format. Open the json file and find out [values] as you run these commands</li>
                <li>cfy secrets create gcp_client_x509_cert_url --secret-string [value]</li>
                <li>cfy secrets create gcp_client_email --secret-string [value]</li>
                <li>cfy secrets create gcp_client_id --secret-string [value]</li>
                <li>cfy secrets create gcp_project_id --secret-string [value]</li>
                <li>cfy secrets create gcp_private_key_id --secret-string [value]</li>
                <li>cfy secrets create gcp_private_key --secret-string [value]</li>
                <li>cfy secrets create gcp_project_id --secret-string [value]</li>
                <li>cfy secrets create gcp_zone --secret-string [value]</li>
                <li>Now deploy a sample app <strong>cfy install https://github.com/cloudify-cosmo/cloudify-hello-world-example/archive/master.zip -n gcp.yaml -b hello-world-gcp region=[YOUR REGION]</strong></li>
                <li>Run - <strong>cfy deployment outputs [DEPLOYMENT ID]</strong></li>
                <li>You can teardown the deployment - <strong>cfy uninstall [DEPLOYMENT ID]</strong></li>
            </ul>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://cloudify.co/knowledge-base/cloudify-examples-hello-world-example-on-google-cloud/">cloudify-examples-hello-world-example-on-google-cloud</a>
        </div>
    </div> -->
    <!-- Cloudify END -->


  <!-- Jenkins BEGIN -->
  <div class="card mb-4" id="jenkins">
    <div class="card-body">
      <h2 class="card-title">Jenkins</h2>
      <ul class="list-unstyled mb-0">
        <!-- <li><a href="#jenkins-0">What is Jenkins</a></li> -->
        <li><a href="#jenkins-1">1. Designing Jenkins Infrastrue</a></li>
        <li><a href="#jenkins-2">2. Setting up Jenkins master on Linux</a></li>
        <li><a href="#jenkins-3">3. Setting up Jenkins agent on Linux</a></li>
              <!-- <li><a href="#jenkins-4">4. Setting up Jenkins agent on Window</a></li> -->
              <!-- <li><a href="#jenkins-5">5. Folderizing & Role Based Access Control</a></li> -->
              <!-- <li><a href="#jenkins-6">6. Managing Credentials</a></li> -->
              <!-- <li><a href="#jenkins-8">Running Jenkins on docker</a></li> -->
<!--                             <li><a href="#jenkins-7">Pipeline and DSL</a></li>
              <ul>
                  <li><a href="#jenkins-7-1">Maven</a></li>
                  <li><a href="#jenkins-7-2">NPM</a></li>
                  <li><a href="#jenkins-7-3">ANT</a></li>
                  <li><a href="#jenkins-7-4">Nexus</a></li>
                  <li><a href="#jenkins-7-5">BitBucket</a></li>
                  <li><a href="#jenkins-7-6">Email</a></li>
                  <li><a href="#jenkins-7-7">SonarQube</a></li>
                  <li><a href="#jenkins-7-8">Sonatype</a></li>
                  <li><a href="#jenkins-7-9">Veracode</a></li>
                  <li><a href="#jenkins-7-10">SOA Test</a></li>
                  <li><a href="#jenkins-7-11">Deploying code to JBoss</a></li>
                  <li><a href="#jenkins-7-12">Running Jenkins job</a></li>
              </ul>
              <li><a href="#jenkins-8">Pipeline using shared library</a></li>
              <li><a href="#jenkins-10">Multibranch Pipeline</a></li>
              <li><a href="#jenkins-9">Multibranch Pipeline with shared library</a></li>
              <ul>
                  <li><a href="#jenkins-9-1">Pipeline with Shared Library - Architecture 1</a></li>
                  <li><a href="#jenkins-9-2">Pipeline with Shared Library - Architecture 2</a></li>
                  <li><a href="#jenkins-9-3">Pipeline with Shared Library - Architecture 3</a></li>
                  <li><a href="#jenkins-9-4">Pipeline with Shared Library - Architecture 4</a></li>
                  <li><a href="#jenkins-9-11">Pipeline with Shared Library - Builder</a></li>
                  <li><a href="#jenkins-9-12">Pipeline with Shared Library - Builder - MavenBuild</a></li>
                  <li><a href="#jenkins-9-13">Pipeline with Shared Library - Builder - NodeBuild</a></li>
                  <li><a href="#jenkins-9-14">Pipeline with Shared Library - Builder - AngularPackage</a></li>
                  <li><a href="#jenkins-9-21">Pipeline with Shared Library - Publisher</a></li>
                  <li><a href="#jenkins-9-22">Pipeline with Shared Library - Publisher - MavenPublish</a></li>
                  <li><a href="#jenkins-9-23">Pipeline with Shared Library - Publisher - AngularPublish</a></li>
                  <li><a href="#jenkins-9-31">Pipeline with Shared Library - Deployer</a></li>
                  <li><a href="#jenkins-9-32">Pipeline with Shared Library - Deployer - JBossDeploy</a></li>
                  <li><a href="#jenkins-9-41">Pipeline with Shared Library - Notifier</a></li>
                  <li><a href="#jenkins-9-42">Pipeline with Shared Library - Notifier - SCMNotification</a></li>
                  <li><a href="#jenkins-9-43">Pipeline with Shared Library - Notifier - EmailNotification</a></li>
                  <li><a href="#jenkins-9-51">Pipeline with Shared Library - Scanner</a></li>
                  <li><a href="#jenkins-9-52">Pipeline with Shared Library - Scanner - SonarQube</a></li>
                  <li><a href="#jenkins-9-53">Pipeline with Shared Library - Scanner - Sonatype</a></li>
                  <li><a href="#jenkins-9-54">Pipeline with Shared Library - Scanner - Veracode</a></li>
                  <li><a href="#jenkins-9-61">Pipeline with Shared Library - Tester</a></li>
                  <li><a href="#jenkins-9-62">Pipeline with Shared Library - Tester - SOATest</a></li>
                  <li><a href="#jenkins-9-71">Pipeline with Shared Library - Utility - CheckJenkinsJobStatus</a></li>
                  <li><a href="#jenkins-9-72">Pipeline with Shared Library - Utility - CheckRunningBuild</a></li>
                  <li><a href="#jenkins-9-73">Pipeline with Shared Library - Utility - Confluence</a></li>
                  <li><a href="#jenkins-9-74">Pipeline with Shared Library - Utility - CreateBranch</a></li>
                  <li><a href="#jenkins-9-75">Pipeline with Shared Library - Utility - CreatePullRequest</a></li>
                  <li><a href="#jenkins-9-76">Pipeline with Shared Library - Utility - GenerateSalesforceCredential</a></li>
                  <li><a href="#jenkins-9-77">Pipeline with Shared Library - Utility - MergePullRequest</a></li>
                  <li><a href="#jenkins-9-78">Pipeline with Shared Library - Utility - PublishReport</a></li>
                  <li><a href="#jenkins-9-79">Pipeline with Shared Library - Utility - Reporter</a></li>
                  <li><a href="#jenkins-9-711">Pipeline with Shared Library - Utility - RunCommand</a></li>
                  <li><a href="#jenkins-9-712">Pipeline with Shared Library - Utility - RunJenkinsJob</a></li>
                  <li><a href="#jenkins-9-713">Pipeline with Shared Library - Utility - Utilities</a></li>
              </ul>
              <li><a href="#jenkins-11">Maven and pom.xml</a></li>
              <li><a href="#jenkins-12">Common Jenkins pipeline issues and resolutions</a></li>
              <li><a href="#jenkins-13">Jenkins job DSL scripts</a></li> -->
      </ul>
    </div>
  </div>

  <!-- <div class="card mb-4" id="jenkins-0">
      <div class="card-body">
          <h2 class="card-title">What is Jenkins</h2>
          <ul>
              <li>CI tool that helps to automated tasks</li>
              <li>Java-based Web tool</li>
              <li>Highly extendable via plugins</li>
          </ul>
      </div>
      <div class="card-footer text-muted">
          Posted on January 26, 2019 by
          <a href="#">Seungmoon Rieh</a>
      </div>
  </div> -->

  <div class="card mb-4" id="jenkins-1">
    <div class="card-body">
      <h2 class="card-title">1. Designing Jenkins Infrastrue</h2>
      <p class="card-text">It is advised to structure Jenkins infrastructure with <Strong>Master</Strong> and <strong>Agents</strong></p>

      <p class="card-text">Jenkins <strong>master</strong> should have the following</p>
      <ul>
          <li>Seed job that runs DSL scripts</li>
          <li>Plugins</li>
      </ul>
      <p class="card-text">Jenkins master must have enough disk space to host growing number of job and plugins. The data on Jenkins master is critical and must be backed up regularly. If Jenkins master is hosted on a virtual machine of Cloud, it is wise to host jenkins direcotry on a cinder volumn so that even if the virtual machine is lost, data is still recoverable.</p>

      <p class="card-text">Jenkins <strong>agents</strong> should have the following</p>
      <ul>
          <li>workspaces where files will be pulled-in and jobs will run</li>
          <li>Tools to run the jobs such as maven, npm, etc</li>
      </ul>
      <p class="card-text">The data on Jenkins agents is not critical because they can always be pulled-in from the job configurations. And workspaces can always be deleted and recreated. Thus, disk space and back up of data are less important on Jenkins agents.</p>

      <p class="card-text">Jenkins agents will be <strong>Linux</strong> (Redhat, JBoss, etc) and/or <strong>Windows</strong> (Windows Server, etc). And Jenkins jobs will be configured to run on a specific agent. However, pipeline jobs can run each of their steps on a different agent.</p>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="jenkins-2">
    <div class="card-body">
      <h2 class="card-title">2. Setting up Jenkins master on Linux</h2>
      <p class="card-text">Assuming you've downloaded "jenkins.war", installed it, and are able to access Jenkins UI via [your_server_ip]:8080, there are other steps you need to follow to complete the setup</p>
      <ul>
        <li>Specify the port in which Jenkins master should talk to its agent. Jenkins->Configure GLobal Security->TCP port for JNLP agents-> Fixed:8443</li>
        <li>Set the # of executor of master at 0 so that no builds run on master. Jenkins->Nodes->master-># of executors:0</li>
        <li>Configure authentication strategy. For exmaple, Jenkins->Configure Global Security->Security Realm: Active Directory, Authorization:Role-Based Strategy</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="jenkins-3">
    <div class="card-body">
      <h2 class="card-title">3. Setting up Jenkins agent on Linux</h2>
      <p class="card-text">Agents are necessary to distribute work load</p>
      <ul>
          <li>You can specify #of executors, directory of workspace, way to launch the agent</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

    <!-- <div class="card mb-4" id="jenkins-8">
        <div class="card-body">
            <h2 class="card-title">Running Jenkins on docker</h2>
            <p class="card-text">https://hub.docker.com/r/library/jenkins</p>
            <ul>
                <li>Must use port mapping to so that user can access Jenkins Web Application</li>
                <li>Must use volumn mapping to persist Jenkins data workspace</li>
            </ul>
        </div>
        <div class="card-footer text-muted">
            Posted on January 26, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div> -->

<!--                 <div class="card mb-4" id="jenkins-7">
        <div class="card-body">
            <h2 class="card-title">Pipeline and DSL</h2>
            <p class="card-text">Jenkins pipeline is a tool to implement CI/CD. DSL (Domain Specifc Language) is the programming language used to write the Jenkins pipeline</p>
            <p class="card-text">DSL has many keywords, which includes</p>
            <ul>
                <li>dir - specifies workspace in which the code runs</li>
                <li>stage - defines each pipeline stage, which are deplayed on Jenkins UI</li>
                <li>sh - can execute bash commands</li>
                <li>withCredentials - can read credentials from Credential Store of Jenkins</li>
                <li>withEnv - can set Environment variables when running commands</li>
            </ul>
            <p class="card-text">All key words must be written inside <strong>node</strong> block. Otherwise, pipeline would throw compilation error</p>

<pre><code class="groovy">node {

dir()

stage()

sh

}</code></pre>

            <p class="card-text">You can also specify on which agent the job should run by</p>

<pre><code class="groovy">node ("Name-of-your-jenkins-agent") {

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 21, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-1">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Maven</h2>
            <p class="card-text">There are three common operations of Maven</p>
            <ul>
                <li>Running unit tests and building artifacts</li>
                <li>Deploying artifacts as SNAPSHOT to artifact repository</li>
                <li>Releasing artifacts as RELEASE to artifact repository</li>
            </ul>
            <p class="card-text">Each operation can be done as following</p>

<pre><code class="groovy">node {

stage("Maven Build") {
withEnv(["PATH=WHATEVER=PATH_TO_MAVEN:PATH_TO_JDK"]) {
sh """ mvn clean install -B """
}
}

stage("Maven Publish") {
withEnv(["PATH=WHATEVER=PATH_TO_MAVEN:PATH_TO_JDK"]) {
sh """ mvn deploy -DskipTests -B """
}
}

stage("Maven Release") {
withEnv(["PATH=WHATEVER=PATH_TO_MAVEN:PATH_TO_JDK"]) {
sh """ mvn -B release:prepare release:perform """
}
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-2">
        <div class="card-body">
            <h2 class="card-title">Pipeline - NPM</h2>
            <p class="card-text"></p>
        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-3">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Ant</h2>
            <p class="card-text"></p>
        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-4">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Nexus</h2>
            <p class="card-text">One common operation with Nexus is to download the latest artfact</p>

<pre><code class="groovy">node {

stage("Download latest artifact from Nexus") {
// These parameters would be specific to artifact you are trying to download
String nexusUrl = "YOUR_NEXUS_URL"
String repository = "YOUR_REPOSITORY"
String groupId = "YOUR_GROUP_ID"
String artifactId = "YOUR_ARTICAT_ID"
String packaging = "PACKAGING"
// Build Nexus end-point using artifact-specific parameters
String nexusLink = nexusUrl+"/"+repository+"/"+groupId.replace(".","/")+"/"+artifactId
sh """
# querying artifact's metadata and
response=\$(curl --silent --compressed ${nexusLink}/maven-metadata.xml)
# parsing xml response to get the version number
version=\$(grep -oPm1 '(?>=&lt;release&gt;)[^<]+' <<< \$response)
# downloading the artifact
wget --no-check-certificate --output-document $DIRECTORY_TO_PLACE_ARTIFACT ${nexusLink}/\$version/${artifactId}-\$version.${packaging}
"""
}

}</code></pre>

            <p class="card-text">You can also upload artifact to nexus using mvn command</p>

<pre><code class="groovy">node {

stage("Upload artifact to Nexus") {
sh """
mvn deploy:deploy-file -Dfile=YOUR_FILE -DgroupId=YOUR_GROUP_ID -DartifactId=YOUR_ARTIFACT_ID -Dversion=YOUR_VERSION -Dpackaging=YOUR_PACKAGING -DgeneratePom=true -DcreateChecksum=true -DrepositoryId=releases -Durl=YOUR_NEXUS_URL_INCLUDING_AUTHENTICATION_AND_PATH_TO_REPOSITORY
"""
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-5">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Bitbucket</h2>
            <p class="card-text">You can send real-time Jenkins build status to Bitbucket. To make http request, you need to install "http_request" plugin</p>

<pre><code class="groovy">node {

stage("Notify Bitbucket") {
String commitHash = sh returnStdout: true, script 'git rev-parse HEAD'
String shortCommitHash = sh returnStdout: true, script 'git rev-parse --short HEAD'
def requestBody = new JsonBuilder([
state: "YOUR_STATE" // can be one of SUCCESSFUL, IN PROGRESS, STOPPED, FAILED
key: env.BRANCH_NAME + "-" + shortCommitHash
url: env.BUILD_URL
])
// Be careful about the endpoint
String requestUrl = "YOUR_BITBUCKET_URL" + "/rest/build-status/1.0/commits/" + commitHash
def response = httpRequest authentication: "YOUR_BITBUCKET_CREDENTIAL", contentType: "APPLICATION_JSON", httpMode: "POST", requestBody: requestBody, url: requestUrl
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-6">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Email</h2>
            <p class="card-text">you need to install "email-ext" plugin</p>

<pre><code class="groovy">node {

stage("Send Email") {
mail bcc: "", body: YOUR_EMAIL_BODY, cc: "", from: "", replyTo: "", subject: YOUR_SUBJECT, to: YOUR_EMAIL_LIST
}

}</code></pre>
        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-7">
        <div class="card-body">
            <h2 class="card-title">Pipeline - SonarQube</h2>
            <p class="card-text">It is possbile to use mvn command with sonar-maven-plugin</p>

<pre><code class="groovy">node {

stage("SonarQube") {
withSonarQubeEnv("SONARQUBE_ENVIRONMENT") {
withEnv(["PATH=WHATEVER=PATH_TO_MAVEN:PATH_TO_JDK"]) {
    sh """
        mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.3.0.603:sonar -B
    """
}
}
def sonarQubeScanResult = waitForQualityGate()
println sonarQubeScanResult
}

}</code></pre>

            <p class="card-text">If not using Maven, you can use sonar-scanner package. In this case, you need to have project properties file in the code repository</p>

<pre><code class="groovy">node {

stage("SonarQube") {
withSonarQubeEnv("SONARQUBE_ENVIRONMENT") {
withEnv(["PATH=WHATEVER=PATH_TO_SONAR_SCANNER"]) {
    sh """
        sonar-scanner -Dsonar.projectBaseDir=$DIRECTORY_WHERE_PROJECT_PROPERTIES_IS_LOCATED
    """
}
}
def sonarQubeScanResult = waitForQualityGate()
println sonarQubeScanResult
}

}</code></pre>

            <p class="card-text">SONARQUBE_ENVIRONMENT should be set up in the Jenkins (Manage Jenkins -> Configure System). You need supply information such as Sonarqube server url, authentication token, etc</p>
        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-8">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Sonatype</h2>
            <p class="card-text">In order to use Sonatype scan, you need to install "nexus-jenkins-plugin"</p>

<pre><code class="groovy">node {

stage("SonaType") {
def result = nexusPolicyEvaluation failBuildOnNetworkError: false, iqApplication: "YOUR_SONATYPE_APP_ID", iqStage: "SonaType", jobCredentialsId: ""
if (result != null) {
def criticalIssues = policyEvaluationResult.criticalComponentCount
def severeIssues = policyEvaluationResult.severeComponentCount
def moderateIssues = policyEvaluationResult.moderateComponentCount
println criticalIssues
println severeIssues
println moderateIssues
}
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-9">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Veracode</h2>
            <p class="card-text">In order to use Veracode scan, you need to install "veracode-jenkins-plugin"</p>

<pre><code class="groovy">node {

stage("Veracode") {
withCredentials([usernamePassword(credentialsId: '', passwordVariable: 'VERACODE_PASSWORD', usernameVariable: 'VERACODE_USERNAME')]) {
veracode applicationName: "YOUR_VERACODE_APP_ID", canFailJob: false, createSandBox: true, criticality: "veryhigh", debug: true, sandboxName: "YOUR_VERACODE_SANDBOX_ID", vuser: env.VERACODE_USERNAME, vpassword: env.VERACODE_PASSWORD
}
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-10">
        <div class="card-body">
            <h2 class="card-title">Pipeline - SOA Test</h2>
            <p class="card-text"></p>

<pre><code class="groovy">node {

stage("SOA Test") {
withEnv(["SOATESTPATH=PATH_TO_SOA, SOA_LOCATION=YOUR_SOA_TEST_FOLDER_LOCATION, OPTIONS=YOUR_SOA_TEST_OPTIONS"]) {
bat '''
    "%SOATESTPATH%\\soatestcli.exe" -data %WORKSPACE% -import %WORKSPACE%\\%SOA_LOCATION%\\.project
    "%SOATESTPATH%\\soatestcli.exe" -data %WORKSPACE% -resource %SOA_LOCATION% -config "user://Example Configuration" %YOUR_SOA_TEST_OPTIONS%
'''
}
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-11">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Deploy to JBoss</h2>
            <p class="card-text"></p>

<pre><code class="groovy">node {

stage("JBoss Deploy") {
withCredentials([usernamePassword(credentialsId: "YOUR_DEPLOYMENT_CREDENTIAL", passwordVariable: "DEPLOYMENT_PASSWORD", usernameVariable: "DEPLOYMENT_USERNAME")]) {
// First create a "stage" folder on Jenkins workspace. And create a folder in the target server to deploy code to
sh """
    if [ ! -d ./stage ]
    then
        mkdir stage
    else
        rm -rv stage
        mkdir stage
    fi
    sshpass -p \$DEPLOYMENT_PASSWORD ssh \$DEPLOYMENT_USERNAME@$YOUR_TARGET_IP_ADDRESS '
        mkdir $env.BUILD_TAG
    '
"""
// Move the artifact to deploy to "stage" folder on Jenkins workspace. And trasnfer the artifact to target server
sh """
    cp -rv $env.WORKSPACE/$YOUR_ARTIFACT stage
    sshpass -p $DEPLOYMENT_PASSWORD scp -v -P 22 $env.WORKSPACE/stage/* $DEPLOYMENT_USERNAME@$YOUR_TARGET_IP_ADDRESS:\"/home/$DEPLOYMENT_USERNAME/$env.BUILD_TAG\"
"""
// Use Jboss cli to deploy the artifact
sh """
    sshpass -p $DEPLOYMENT_PASSWORD ssh $DEPLOYMENT_USERNAME@$YOUR_TARGET_IP_ADDRESS '
        find \"/home/$DEPLOYMENT_USERNAME/$env.BUILD_TAG\" -type -f -regex \"^.*\\.\\(war\\|ear\\|jar\\)]" > to_deploy
        while read APP; do
            APP_NAME=\$(basename \$APP | cut -d\"-\" -f1)
            echo $DEPLOYMENT_PASSWORD | sudo -kS $PATH_TO_JBOSS_CLI/jboss.cli.sh --connect deployment-info > temp
            cat temp | awk \"'FNR ==2 {print \$1}'\" | cut -d\"-\" -f1 > temp1
            EXISTING_APP=\$(cat temp)
            if [ -z \$EXISTING_APP ]
            then
                echo \"FIrst time deployment\"
            else
                echo \"Undeploying \$EXISTING_APP\"
                echo $DEPLOYMENT_PASSWORD | sudo -kS $PATH_TO_JBOSS_CLI/jboss.cli.sh --connect --controller=127.0.0.1:9999 /deployment=\$EXISTING_APP:remove
            fi
            echo \"Deploying \$APP_NAME\"
            echo $DEPLOYMENT_PASSWORD | sudo -kS $PATH_TO_JBOSS_CLI/jboss.cli.sh --commands=\"connect --controller=127.0.0.1:9999, deploy \$APP\"
            echo $DEPLOYMENT_PASSWORD | sudo -kS $PATH_TO_JBOSS_CLI/jboss.cli.sh --connect deployment-info > /home/$DEPLOYMENT_USERNAME/$env.BUILD_TAG/outcome.txt
        done < to_deploy
        echo \"Cleaning up"\
    '
"""
}
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-7-12">
        <div class="card-body">
            <h2 class="card-title">Pipeline - Run Jenkins Job</h2>
            <p class="card-text"></p>

<pre><code class="groovy">node {

stage("Run Jenkins Job") {
Map jobParameterMap = [[$class: 'StringParameterValue', name: 'PARAMETER_NAME1', value: 'PARAMETER_VALUE1'], [$class: 'StringParameterValue', name: 'PARAMETER_NAME2', value: 'PARAMETER_VALUE2']]
def result = build job: PATH_TO_YOUR_JOB, parameters: evaluate(jobParameterMap), wait: true
}

}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-8">
        <div class="card-body">
            <h2 class="card-title">Pipeline using shared library</h2>
            <p class="card-text">Instead of writing DSL directly into Jenkins jobs, you can store DSL in a repository and call them from Jenkins jobs. This is the idea of "shared library" and its structure should be the following</p>
            <img class="img-fluid" class="card-img-top" src="img/jenkins/jenkins-8-a.png" alt="Card image cap">
            <p class="card-text">Note that the pipeline steps under "var" folder must implement "call" method. Each pipeline step should begin with</p>

<pre><code class="groovy">#!/usr/bin/groovy
def call(body) {
// Code goes here
}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-10">
        <div class="card-body">
            <h2 class="card-title">Multibranch Pipeline</h2>
            <p class="card-text">Multibranch pipeline allows Jenkins to build jobs <strong>automatically</strong> whenever any change in a branch of code repository is detected by the <strong>Jenkinsfile</strong>. This <strong>Jenkinsfile</strong> should be located in the root of code repository</p>
        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9">
        <div class="card-body">
            <h2 class="card-title">Multibranch Pipeline with Shared Library</h2>
            <p class="card-text">Multibranch pipeline is where the use of "shared library" becomes a MUST. First of all, the <strong>Jenkinsfile</strong> in the root of code repository should look like</p>

<pre><code class="bash"># NAME_OF_SHARED_LIBRARY should be set in Manage Jenkins -> Configure System
# NAME_OF_BRANCH should be set to a branch used for productionalized code (usually such branch is "master")
# "mainMethod" must be a pipeline step from the shared library. It is a good practice to pass in the name of repository so that repository-specific configuration can be read when executing the pipeline
#!groovy
@Library("NAME_OF_SHARED_LIBRARY@NAME_OF_BRANCH")
mainMethod("NAME_OF_CODE_REPOSITORY")</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-98">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Job Configuration</h2>
            <p class="card-text">Implementation of <strong>resources/com/rieh/jenkins/maven-project/project.yaml</strong></p>

<pre><code class="bash">agent: 'LINUX-AGENT'
tools: ['jdk','maven']
workflow:
branch: 'develop'
steps:
- mavenBuild:
agent: 'LINUX-AGENT'
stage_name: 'MAVEN BUILD'
checkout_scm: true
clean_up_workspace: false
mvn_command: 'mvn clean install'
- sonarQubeScan:
agent: 'LINUX-AGENT'
stage_name: 'SONARQUBE SCAN'
checkout_scm: false
clean_up_workspace: false
sonarqube_strategy: 'MAVEN'
- sonatypeScan:
agent: 'LINUX-AGENT'
stage_name: 'SONATYPE SCAN'
checkout_scm: false
clean_up_workspace: false
sonatype_application_id: 'CFP'
- veracodeScan:
agent: 'LINUX-AGENT'
stage_name: 'VERACODE SCAN'
checkout_scm: false
clean_up_workspace: false
veracode_application_id: ''
veracode_sandbox_id: ''
veracode_upload_pattern: '**/target/**.war'
veracode_wait_for_completion: false
- mavenPublish:
agent: 'LINUX-AGENT'
stage_name: 'MAVEN PUBLISH'
checkout_scm: false
clean_up_workspace: false
mvn_command: 'mvn deploy -DskipTests -B'
version_strategy: 'PATCH'
- jbossDeploy:
agent: 'LINUX-AGENT'
stage_name: 'JBOSS DEPLOY'
checkout_scm: false
clean_up_workspace: false
deployment_env: 'DEV'
deployment_target: ''
deployment_artifact: 'target/**.war'
- soaTest:
agent: 'SOA-AGENT'
stage_name: 'SOA TEST'
checkout_scm: true
clean_up_workspace: true
test_soa_scripts: ''
test_soa_options: ''
- notification:
agent: 'LINUX-AGENT'
stage_name: 'EMAIL NOTIFICATION'
checkout_scm: false
clean_up_workspace: false
notification_type: 'EMAIL'
notification_email_sender: ''
notification_email_recipients: ''</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-1">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Architecture 1</h2>

            <p class="card-text">We want to treat <strong>Jenkinsfile</strong> as a kind of configuration file that projects can choose during runtime. Thus, the content of <strong>Jenkinsfile</strong> should be minimized so that major logic is handled in the main method</p>

            <p class="card-text">There are many things to do in the main methods. First of all, we want to identify the project by parsing the SCM url so that we can pick the right configuration file for that project</p>

<pre><code class="groovy">String scmUrl = this.scm.getUserRemoteConfigs()[0].getUrl()
String scmName = scmUrl.split("/")[scmUrl.split("/").size()-1].replace(".git", "")</code></pre>

            <p class="card-text">Then, we want to go ahead to grap the configuration file for the project. There will always be two kinds of configuration file: 1. Global config that applies to all projects 2. Project config, which is specific for the project and can overide the global config during runtime. The following step shows how these two configs can be consolidated</p>

<pre><code class="groovy">node {
String globalConfigString = this.libraryResource("com/rieh/jenkins/util/default_settings.yaml")
String projectConfigString = this.libraryResource("com/rieh/jenkins/$scmName/jenkinsConfig.yaml")
this.writeFile file: "global_config", text: globalConfigString
this.writeFile file: "project_config", text: projectConfigString
Map globalConfig = this.readYaml file: "global_config"
Map projectConfig = this.readYaml file: "project_config"
config = com.rieh.jenkins.util.Utilities.reconcileConfig(projectConfig, globalConfig)
}</code></pre>

            <p class="card-text">Next step is to find the pipeline workflow for the current branch. We also need to consider the case where there are default steps to run when the pipeline workflow for the current branch is not defined in the project configuration file</p>

<pre><code class="groovy">Map config = null
Map workflow = null
Map defaultWorkflow = null
String currentBranch = env.BRANCH_NAME.split('/')[0]

currentBuild.result = "SUCCESS"
for (wf in config.workflow) {
if (wf.branch == currentBranch) {
workflow = wf
}
else if (wf.branch == config.default_branch) {
defaultWorkflow = wf
}
}
if (workflow == null) {
if (defaultWorkflow == null) {
currentBuild.result = "ABORTED"
return // exit pipeline prematurely
}
else {
workflow = defaultWorkflow
}
}</code></pre>

            <p class="card-text">It is possible that you have multiple Jenkins masters with different Jenkins version and different sets of plugins. This means the syntax of shared pipeline library may work in one Jenkins master but not in the others. Thus, you would need "feature toggle" for the code base such that different methods are triggered depending on which Jenkins master that the code is running. To to so, we first need to identify the Jenkins master</p>

<pre><code class="groovy">String internalHostname = InetAddress.localHost.canonicalHostName
switch(internalHostName) {
case "[internalHostName1]":
config.pipeline_version = "v1"
break
case "[internalHostName2]":
config.pipeline_version = "v2"
break
default:
currentBuild.result = "ABORTED"
return // exit pipeline prematurely
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/var/mainMethod.groovy"/>mainMethod.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 9, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-2">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Architecture 2</h2>

            <p class="card-text">Here we write Utilities class the provide "static" methods</p>

<pre><code class="groovy">package com.rieh.jenkins.util
import java.util.Map

@Singleton
public class Utilities {

}</code></pre>

            <p class="card-text">The implementation of "reconcileConfig" methods from the "mainMethod.groovy" is given here</p>

<pre><code class="groovy">public static Map reconcileConfig(Map projectConfig, Map globalConfig) {
if (projectConfig == null) {
return globalConfig
}
else {
Map config = globalConfig.clone()
for (item in projectConfig) {
config[item.key] = projectConfigp[item.key]
}
return config
}
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/Utilities.groovy"/>Utilities.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 9, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>

    <div class="card mb-4" id="jenkins-9-3">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Architecture 3</h2>

            <p class="card-text">Io structure the shared pipeline library, we will need an abstract class that represents what we are trying to do. We are really writing pipeline steps, so lets create an abstract class "Step". Implemeting the interface "Serializable" is very important when writing Jenkins pipeline, which we will explore in a separate section</p>

<pre><code class="groovy">package com.rieh.jenkins
public abstract class Step implements Serializable {

}</code></pre>

            <p class="card-text">On top of declaring variables and abstract methods, we want to have some methods that can be used by children classes that extends it (Thus the "protected" scope). An example of useful method is to run Bash or Shell command depending on which OS the command is run</p>

<pre><code class="groovy">protected void runOsCMD(Object scope, String command) {
if (scope.isUnix()) {
scope.sh(command)
} else {
scope.bat(command)
}
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/Step.groovy"/>Step.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 9, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-4">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Architecture 4</h2>

            <p class="card-text">We also need a class that will produce reports on execution of Jenkins pipeline. This report can be sent via email after each pipeline workflow finishes</strong></p>

<pre><code class="groovy">package com.rieh.jenkins.util

@Singleton
public class Reporter {

}</code></pre>

            <p class="card-text">This class should contain methods such as</p>

<pre><code class="groovy">public static void setupReporting(Object scope) {
scope.writeFile file: 'reporting/build_report.html', text: ""
scope.stach includes: 'reporting/*', name: java.net.URLDecoder.decode(scope.env.BUILD_TAG).replace('/','-')
}</code></pre>

<pre><code class="groovy">public static void addToReport(Object scope, String report, String agent) {
scope.unstash name: java.net.URLDecoder.decode(scope.env.BUILD_TAG).replace('/','-')
def appender = scope.readFile file: 'reporting/build_report.html'
appender += report
scope.writeFile file: 'reporting/build_report.html', text: appender
scope.stash includes: 'reporting/*', name: java.net.URLDecoder.decode(scope.env.BUILD_TAG).replace('/','-')
}</code></pre>

<pre><code class="groovy">public static String consolidateReport(Object scope) {
scope.unstash name: java.net.URLDecoder.decode(scope.env.BUILD_TAG).replace('/','-')
def report = this.openReport(scope)
report += scope.readFile('reporting/build_report.html')
report += this.closeReport()
scope.stash includes: 'reporting/*', name: java.net.URLDecoder.decode(scope.env.BUILD_TAG).replace('/','-')

return report
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/Reporter.groovy"/>Reporter.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 10, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-11">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Builder</h2>

            <p class="card-text">"Building the code package" is one of the initial steps for the pipeline workflow. We can first write another abstract class "Builder" that extends earlier "Step" class. </p>

<pre><code class="groovy">package com.rieh.jenkins.build

public abstract class Builder extends com.rieh.jenkins.Step {

protected abstract void build(Map config)

protected void execute(Map config) throws Exception {
build(config)
}

}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/build/Builder.groovy"/>Builder.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 10, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-12">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Builder - MavenBuild</h2>
            <p class="card-text">We can write "MavenBuild" class that extends above "Builder" abstract class. This "MavenBuild" class will implement the abstract "build" method from "Builder" class and abstract "report" method from "Step class"</p>

<pre><code class="groovy">package com.rieh.jenkins.build.java

public class MavenBuild extends com.rieh.jenkins.build.Builder {

public MavenBuild(Object scope, String name) {
this.scope = scope
this.name = name
}

protected String report(Map config, String status) {
return com.rieh.jenkins.util.Reporter.simpleReport(name, status)
}

protected void build(Map config) throws Exception {
switch(config.pipeline_version) {
case "v1":
    buildWithEnv(config)
    break
case "v2":
    buildWithMaven(config)
    break
default:
    status = "FAILURE"
}
}

}</code></pre>

            <p class="card-text">Here we have the use case of "feature toggle" we've implemented in the "mainMethod". Depending on the version, "MavenBuild" class will execute different method that executes maven build in different way</p>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/build/java/MavenBuild.groovy"/>MavenBuild.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 10, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-13">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Builder - NodeBuild</h2>
            <p class="card-text">We can also perform npm build just like we did for maven. Following code will remove "node_modules" folder using the pipeline syntax</p>

<pre><code class="groovy">Boolean result = fileExists "node_modules"
if (result) {
dir("node_modules") {
deleteDir()
}
}</code></pre>

            <p class="card-text">Then we can run the npm command (config.install_command) passed through configuration after removing the cache folder</p>

<pre><code class="groovy">private final String NPM_CACHE_FOLDER = '.cache'

String command = """
if [ -d ${NPM_CACHE_FOLDER} ] ; then
rm -rf ${NPM_CACHE_FOLDER}
fi
mkdir ${NPM_CACHE_FOLDER}
${config.install_command} --cache=${NPM_CACHE_FOLDER}
"""
runOsCMD(scope, command)</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/build/node/NodeBuild.groovy"/>NodeBuild.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 14, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-14">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Builder - AngularPackage</h2>
            <p class="card-text">This step shows how to package Angular code into an artifact</p>

<pre><code class="groovy">def pack = scope.readJSON file: "${currentDirectory}${config.workspace}/package.json"
String artifact = "${pack.name}"
if (scope.isUnix()) {
command = """
zip -r target/${artifact}.zip ${config.package_directory} ${config.exclude_string}
"""
runOsCMD(scope, command)
} else {
scope.zip dir: '.', glob: '', zipFile: "target/${artifact}.zip"
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/build/node/AngularPackage.groovy"/>AngularPackage.groovy</p>

        </div>
        <div class="card-footer text-muted">
            Posted on February 16, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>


    <div class="card mb-4" id="jenkins-9-21">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Publisher</h2>

            <p class="card-text">Here we will cover how to do pubish code into artifact repository</p>

<pre><code class="groovy">package com.rieh.jenkins.publish

public abstract class Publisher extends com.rieh.jenkins.Step {

protected abstract void publish(Map config)

protected void execute(Map config) throws Exception {
publish(config)
}

}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/publish/Publisher.groovy"/>Publisher.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 16, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-22">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Publisher - Maven Publish</h2>

            <p class="card-text">We want to publish artifact during the pipeline workflow. The following shows how to do it with maven in two ways</p>

<pre><code class="groovy">String toolString = setupTools(config)
scope.withEnv(["PATH+WHATEVER=${toolString}"]) {
runOsCMD(scope, "${config.maven_command}")
}</code></pre>

<pre><code class="groovy">scope.withMaven(maven: config.maven, globalMavenSettingsConfig: config.global_maven_setting) {
runOsCMD(scope, "${config.maven_command}")
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/publish/java/MavenPublish.groovy"/>MavenPublish.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 16, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-22">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Publisher - Maven Release</h2>

            <p class="card-text">Similar to Maven Publish, we have the following for Maven Release</p>

<pre><code class="groovy">String credentialId = scope.scm.getUserRemoteConfigs()[0].getCredentialsId()
scope.sshagent([credentialId]) {
cleanRelease(config, currentDirectory+config.workspace+"/pom.xml")
String currentVersion = getCurrentVersion(config, currentDirectory+config.workspace+"/pom.xml")
String toolString = setupTools(config)
scope.withEnv(["PATH=WHATEVER=${toolString}"]) {
runOsCMD(scope, "${config.maven_command} -DreleaseVersion=${currentVersion}")
}
}</code></pre>

<pre><code class="groovy">String credentialId = scope.scm.getUserRemoteConfigs()[0].getCredentialsId()
scope.sshagent([credentialId]) {
cleanRelease(config, currentDirectory+config.workspace+"/pom.xml")
String currentVersion = getCurrentVersion(config, currentDirectory+config.workspace+"/pom.xml")
scope.withMaven(maven: config.maven, globalMavenSettingsConfig: config.global_maven_setting) {
runOsCMD(scope, "${config.maven_command} -DreleaseVersion=${currentVersion}")
}
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/publish/java/MavenRelease.groovy"/>MavenRelease.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 16, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-23">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Publisher - Angular Publish</h2>

            <p class="card-text">For projects without pom.xml files, we will use "mvm" commands fo publish artifact. For example of Angular, the following can be used</p>

<pre><code class="groovy">incrementNodeVersion(config)
String command = """
RELEASE_VERSION=\$(cat package.json | jq -r \'.version\')
NAME=\$(cat package.json | jq -r \'name\')
mvn deploy:deploy-file -DgroupId=${config.group_id} -DartifactId=\$NAME -Dversion=\$RELEASE_VERSION -DuniqueVersion=false -Dpackaging=${config.packaging} -DrepositoryId=${config.repository} -Durl=${config.nexus_url}/${config.repository} -Dfile=target/\$NAME.zip -B
"""
runOsCMD(scope, command)</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/publish/node/AngularPublish.groovy"/>AngularPublish.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 16, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-31">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Deployer</h2>
            <p class="card-text">Here, we will cover various type of depoyment</p>

<pre><code class="groovy">package com.rieh.jenkins.deploy

public abstract class Deployer extends com.rieh.jenkins.Step {

protected abstract void deploy(Map config)

protected void execute(Map config) throws Exception {
deploy(config)
}

}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/deploy/Deployer.groovy"/>Deployer.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 16, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-32">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Deployer - JBossDeploy</h2>
            <p class="card-text">Deploying war/ear files to jboss server is a common operation</p>

<pre><code class="groovy">private void sendApplication(Map config) throws Exception {
scope.withCredentials([scope.usernamePassword(credentialsId: config.get("deployment_"+config.deployment_env.toLowerCase()+"_credentials"), passwordVariable: 'DEPLOY_PW', usernameVariable: 'DEPLOY_ACCOUNT')]) {
String command = """
if [ ! -d ./stage ] ; then
    mkdir stage
else
    rm -rv stage
    mkdir stage
fi
sshpass -p \$DEPLOY_PW ssh ${scope.env.DEPLOY_ACCOUNT.toLowerCase()}@${config.deployment_target} '
    mkdir \"${scope.env.BUILD_TAG}\"
'
cp -rv ${currentDirectory}/${config.deployment_artifact} ${currentDirectory}/stage
sshpass -p \$DEPLOY_PW scp -v -P 22 ${currentDirectory}/stage/* ${scope.env.DEPLOY_ACCOUNT.toLowerCase()}@${config.deployment_target}:\"/home/${scope.env.DEPLOY_ACCOUNT.toLowerCase()}/${scope.env.BUILD_TAG}\"
"""
runOsCMD(scope, command)
}
}</code></pre>

<pre><code class="groovy">private void installApplication(Map config) throws Exception {
scope.withCredentials([scope.usernamePassword(credentialsId: config.get("deployment_"+config.deployment_env.toLowerCase()+"_credentials"), passwordVariable: 'DEPLOY_PW', usernameVariable: 'DEPLOY_ACCOUNT')]) {
String command = """
sshpass -p \$DEPLOY_PW ssh ${scope.env.DEPLOY_ACCOUNT.toLowerCase()}@${config.deployment_target} '
    cd ${scope.env.BUILD_TAG}
    find \"/home/${scope.env.DEPLOY_ACCOUNT.toLowerCase()}/${scope.env.BUILD_TAG}\" -type f -regex \"^.*\\.\\(war\\|ear\\|jar\\)\" > to_deploy
    while read APP; do
        APP_NAME=\$(basename \$APP)
        echo ${scope.env.DEPLOY_PW} | sudo -kS ${config.jboss_cli_path} --connect deployment-info > temp
        cat temp | grep \$(basename \$APP) | cut -d\" \" -f1 > temp1
        EXISTING_APP=\$(cat temp1)
        if [ -z \$EXISTING_APP ]
        then
            echo \"First time deployment\"
        else
            echo \"Undeploying \$EXISTING_APP\"
            echo ${scope.env.DEPLOY_PW} | sudo -kS ${config.jboss_cli_path} --connect --controller=127.0.0.1:9999 /deployment=\$EXISTING_APP:remove
            echo ${scope.env.DEPLOY_PW} | sudo -kS ${config.jboss_cli_path} --connect deployment-info
        fi
        echo \"Deploying \$APP_NAME\"
        echo ${scope.env.DEPLOY_PW} | sudo -kS ${config.jboss_cli_path} --commands=\"connect --controller=127.0.0.1:9999, deploy \$APP\"
        echo ${scope.env.DEPLOY_PW} | sudo -kS ${config.jboss_cli_path} --connect deployment-info > /home/${scope.env.DEPLOY_ACCOUNT.toLowerCase()}/${scope.env.BUILD_TAG}/outcome.txt
    done < to_deploy
    echo \"Cleaning up\"
'
"""
runOsCMD(scope, command)
}
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/deploy/jboss/JBossDeploy.groovy"/>JBossDeploy.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on September 22, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-41">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Notifier</h2>
            <p class="card-text">Notifying users with build information via scm/email/etc is very useful</p>

<pre><code class="groovy">package com.rieh.jenkins.notify

public abstract class Notifier extends com.rieh.jenkins.Step {

protected abstract void notify(Map config)

protected void execute(Map config) throws Exception {
notify(config)
}

protected boolean sendNotification(Map config) throws Exception {
config.notification_cases.contains(scope.currentBuild.result) ? true : false
}

}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/notify/Notifier.groovy"/>Notifier.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-42">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Notifier - SCMNotification</h2>
            <p class="card-text"></p>

<pre><code class="groovy">String state = null
switch(scope.currentBuild.result) {
case "FAILURE":
state = "FAILED"
break
case "ABORTED":
state = "STOPPED"
break
case "SUCCESS":
state = "SUCCESSFUL"
break
case "UNSTABLE":
state = "SUCCESSFUL"
break
}
if (config.in_progress) {
state = "INPROGRESS"
}
String commitHash = scope.sh returnStdout: true, script: 'git rev-parse HEAD'
String shortCommitHash = scope.sh returnStdout: true, script: 'git rev-parse --short HEAD'
def json = new JSONBuilder([
name: "${currentBranch} ${buildNumber}",
state: state,
key: currentBranch + "-" + shortCommitHash,
url: scope.env.BUILD_URL
]).toString()
def response = scope.httpRequest authentication: config.notification_scm_account_id, contentType: 'APPLICATION_JSON', httpMode: 'POST, requestBody: json, url: "https://YOUR_BITBUCKET_URL/rest/build-status/1.0/commits/${commitHash}", consoleLogResponseBody: true</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/notify/scm/SCMNotification.groovy"/>SCMNotification.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-43">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Notifier - EmailNotification</h2>
            <p class="card-text"></p>

<pre><code class="groovy">String report = com.rieh.jenkins.util.Reporter.consolidateReport(scope)
String subject = getSubject(config)
scope.mail bcc: '', body: report, cc: '', from: config.notification_email_sender, reployTo: '', subject: subject, to: config.notification_email_recipients, mimeType: 'text/html'</code></pre>

<pre><code class="groovy">private String getSubject(Map config) throws Exception {
def priorStatus = scope.currentBuild.getPreviousBuild()?.getResult()
def currentStatus = scope.currentBuild.result

String status = null
if (currentStatus == "SUCCESS" && priorStatus != "SUCCESS") {
status = "FIXED"
} else if (priorStatus == "SUCCESS" && currentStatus != "SUCCESS") {
status = "BROKEN"
} else {
status = scope.currentBuild.result
}

return config.mal_code + " => " + status
}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/notify/email/EmailNotification.groovy"/>EmailNotification.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-51">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Scanner</h2>
            <p class="card-text">Various code scan can also be pipeline steps</p>

<pre><code class="groovy">package com.rieh.jenkins.scan

public abstract class Scanner extends com.rieh.jenkins.Step {

protected abstract void scan(Map config)

protected void execute(Map config) throws Exception {
scan(config)
}

}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/scan/Scanner.groovy"/>Scanner.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-52">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Scanner - SonarQube</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/scan/sonarqube/SonarQube.groovy"/>SonarQube.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-53">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Scanner - Sonatype</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/scan/sonatype/Sonatype.groovy"/>Sonatype.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-54">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Scanner - Veracode</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>
            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/scan/veracode/Veracode.groovy"/>Veracode.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-61">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Tester</h2>
            <p class="card-text"></p>

<pre><code class="groovy">package com.rieh.jenkins.test

public abstract class Tester extends com.rieh.jenkins.Step {

protected abstract void runTests(Map config)

protected void execute(Map config) throws Exception {
runTests(config)
}

}</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/test/Tester.groovy"/>Tester.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 20, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-62">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Tester- SOATest</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/test/soatest/SOATest.groovy"/>SOATest.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 20, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-71">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - CheckJenkinsJobStatus</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/CheckJenkinsJobStatus.groovy"/>CheckJenkinsJobStatus.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on February 20, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-72">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - CheckRunningBuild</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/CheckRunningBuild.groovy"/>CheckRunningBuild.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-73">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - Confluence</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/Confluence.groovy"/>Confluence.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-74">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - CreateBranch</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/CreateBranch.groovy"/>CreateBranch.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-75">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - CreatePullRequest</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/CreatePullRequest.groovy"/>CreatePullRequest.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-76">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - GenerateSalesforceCredential</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/GenerateSalesforceCredential.groovy"/>GenerateSalesforceCredential.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-77">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - MergePullRequest</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/MergePullRequest.groovy"/>MergePullRequest.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-78">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - PublishReport</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/PublishReport.groovy"/>PublishReport.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-79">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - Reporter</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/Reporter.groovy"/>Reporter.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-711">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - RunCommand</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/RunCommand.groovy"/>RunCommand.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-712">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - RunJenkinsJob</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/RunJenkinsJob.groovy"/>RunJenkinsJob.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-9-713">
        <div class="card-body">
            <h2 class="card-title">Pipeline with Shared Library - Utility - Utilities</h2>
            <p class="card-text"></p>

<pre><code class="groovy">

</code></pre>

            <p class="card-text">Source code is available at <a href="https://github.com/riehseun/shared-pipeline-library/blob/master/src/com/rieh/jenkins/util/Utilities.groovy"/>Utilities.groovy</p>
        </div>
        <div class="card-footer text-muted">
            Posted on March 3, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-11">
        <div class="card-body">
            <h2 class="card-title">Maven and pom.xml</h2>
            <p class="card-text">pom.xml manages dependencies and deployment. An example pom.xml can look like</p>
            <pre><code class="xml">
&lt;&amp;xml version="1.0" encoding="UTF-8?"&gt;
&lt;project&gt;
&lt;groupId&gt;&lt;/groupId&gt;
&lt;artifactId&gt;&lt;/artifactId&gt;
&lt;version&gt;&lt;/version&gt;
&lt;packaging&gt;&lt;/packaging&gt;
&lt;name&gt;&lt;/name&gt;

&lt;properties&gt;

&lt;/properties&gt;

&lt;build&gt;
&lt;pluginManagement&gt;
&lt;plugins&gt;
&lt;plugin&gt;
    &lt;groupId&gt;&lt;/groupId&gt;
    &lt;artifactId&gt;&lt;/artifactId&gt;
    &lt;version&gt;&lt;/version&gt;
    &lt;configuration&gt;&lt;/configuration&gt;
    &lt;executions&gt;
        &lt;execution&gt;
            &lt;id&gt;&lt;/id&gt;
            &lt;goals&gt;
                &lt;goal&gt;&lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
    &lt;/executions&gt;
&lt;/plugin&gt;
&lt;plugin&gt;
    &lt;groupId&gt;&lt;/groupId&gt;
    &lt;artifactId&gt;&lt;/artifactId&gt;
    &lt;version&gt;&lt;/version&gt;
    &lt;configuration&gt;&lt;/configuration&gt;
    &lt;executions&gt;
        &lt;execution&gt;
            &lt;id&gt;&lt;/id&gt;
            &lt;goals&gt;
                &lt;goal&gt;&lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
    &lt;/executions&gt;
&lt;/plugin&gt;
&lt;plugin&gt;
    &lt;groupId&gt;&lt;/groupId&gt;
    &lt;artifactId&gt;&lt;/artifactId&gt;
    &lt;version&gt;&lt;/version&gt;
    &lt;configuration&gt;&lt;/configuration&gt;
    &lt;executions&gt;
        &lt;execution&gt;
            &lt;id&gt;&lt;/id&gt;
            &lt;goals&gt;
                &lt;goal&gt;&lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
    &lt;/executions&gt;
&lt;/plugin&gt;
&lt;/plugins&gt;
&lt;/pluginManagement&gt;
&lt;/build&gt;

&lt;distributionManagement&gt;
&lt;repository&gt;
&lt;id&gt;&lt;/id&gt;
&lt;url&gt;&lt;/url&gt;
&lt;/repository&gt;
&lt;snapshotRepository&gt;
&lt;id&gt;&lt;/id&gt;
&lt;url&gt;&lt;/url&gt;
&lt;/snapshotRepository&gt;
&lt;/distributionManagement&gt;

&lt;scm&gt;
&lt;url&gt;&lt;/url&gt;
&lt;connection&gt;&lt;/connection&gt;
&lt;developerConnection&gt;&lt;/developerConnection&gt;
&lt;tag&gt;&lt;/tag&gt;
&lt;/scm&gt;
            </code></pre>
        </div>
        <div class="card-footer text-muted">
            Posted on October 13, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-12">
        <div class="card-body">
            <h2 class="card-title">Common Jenkins pipeline issues and resolutions</h2>
            <p class="card-text"><strong>1. Maven release - unables to tag scm</strong><br/>Check if the tag generated by pomx.xml already exists in the remote. If it exists, delete the tag in the remote by executing "git push origin --delete [tagname]"</p>
            <p class="card-text"><strong>2. User not able to execute commands</strong><br/>Check if the "user" executing the command is part of one of the groups added to one of the files under "/etc/sudoers.d". If so yet still cannot execute commands, refresh the configuration on the vm (In case of Salt, it would be sudo salt-call state.highstate)</p>
            <p class="card-text"><strong>3. Permission denied (public key)</strong><br/>Go to Jenkins job configuration -> git congiration, and select user that has access to Code Repository</p>
            <p class="card-text"><strong>4. Maven release - 401 Unauthorized</strong><br/>Review credentials in "settings.xml" under JENKINS_HOME/.m2 of the Jenkins agent on which the job is running</p>
            <p class="card-text"><strong>5. Host key verification failed</strong><br/>Go to the Jenkins agent and replace the host key by executing "ssh-keygen -R [IP_ADDRESS]" and "ssh-keyscan -H >> ~/.ssh/known_hosts"</p>
            <p class="card-text"><strong>6. Unables to commit files / git-push command failed</strong><br/>In the Code Repository settings, check if direct push to certain branches are disabled. Watch for plugins like "Yet Another Commit Checker", which denies commits that don't follow certain message pattern</p>
            <p class="card-text"><strong>7. Maven release - 400 Bad Request</strong><br/>Check if the artifact with same group id, artifact id, and version already exists in Artifact Repository. If so, increment the version of try again</p>
            <p class="card-text"><strong>8. Multibranch pipeline scan fails with "unable to resolve reference"</strong><br/>Under JENKINS_HOME/cashes of Jenkins master, there are directories whose names are hash strings. Scan the Multibranch pipeline job, order directories under JENKINS_HOME/cashes by timestamp, go into few folders with the latest timestamps. and execute "git branch -a" to see if it the repo you are looking for. Remove the folder upon finding it</p>
            <p class="card-text"><strong>9. Failed to fetch from ssh</strong><br/>It is likely that the Code Repository is too big and Jenkins cannot finish cloning before timeout occurs. Go to Git Configuration -> Additional Behaviors -> Timeout (in minutes) for clone and fetch operations. Increase the timeout</p>
            <p class="card-text"><strong>10. SonarQube Error - is already part of project</strong><br/>SonarQube identifies each project by its key. Key is constructed by the combination of group id and artifact id of the module itself and its parent module. When SonarQube sees duplicate keys, it gets confused and cannot perform analysis. Potetial cause of this problem is moving sub-modules from one project to another without updating sub-module's pom.xml. In such case, pom.xml of the sub-module(s) must be updated with the correct group id(s) and artifact id(s)</p>
            <p class="card-text"><strong>11. groovy.lang.MissingPropertyException</strong><br/>It is likely that there is syntax error in "Jenkinsfile"</p>
            <p class="card-text"><strong>12. No such file or directory</strong><br/>Check if "checkout scm" step is missing from "Jenkinsfile"</p>
            <p class="card-text"><strong>13. WorkflowScript: Loading libraries failed</strong><br/>From Jenkins, go to Configure System -> Global Pipeline Lbraries. Check the authentication of your library</p>
            <p class="card-text"><strong>14. mvn: command not found</strong><br/>From Jenkins, go to Global Tool Configuration -> Maven -> Maven Installation. Find the name of the tool and use that name for Tool Locations of Jenkins Agent Configuration</p>
            <p class="card-text"><strong>15. HEAD is not a symbolic ref</strong><br/>From Git Configuration, set "Check out to matching local branch"</p>
            <p class="card-text"><strong>16. Maven release is happening twice</strong><br/>Visit "maven-release-plugin" section of pom.xml and make sure it has right configuration and execution sections</p>
            <p class="card-text"><strong>17. SOA Tests cannot execute</strong><br/>THe project name in ".project" file has to match the name of folder where SOA test suites are located</p>
        </div>
        <div class="card-footer text-muted">
            Posted on October 13, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div>

    <div class="card mb-4" id="jenkins-13">
        <div class="card-body">
            <h2 class="card-title">Jenkins job DSL scripts</h2>
            <p class="card-text">Writing Jenkins job as code gives strong advantages - jobs will be backed up in a form of code in Repository and they are easily reproducible. The following "createAllJobs.groovy" can be used as an example</p>

<pre><code class="groovy">import com.rieh.dsl.JobDSLUtils

/**
* To add a folder in Jenkins, just add a folder name to the "folders" list
*/
def folders = [
"PROJECT-1",
"PROJECT-2",
"PROJECT-3"
]
JobDSLUtils.createFOlder(this, folder)

/**
* To add a multi-branch pipeline job in Jenkins, follow this guideline
* 1st item: add name of the job including its path
* 2nd item: add git clone url
* 3rd item: add ID of Credential stored in Jenkins that has read-access to the git repository
* 4th item: if you only want to build particular branches, include them in this list. Otherwise, leave it empty
*/
def multiBranchJobs = [
["PROJECT-1", "project-1-git-clone-url", "sshkey-for-project-1", ["branch-1-for-project-1"]],
["PROJECT-2", "project-2-git-clone-url", "sshkey-for-project-2", []]
["PROJECT-3", "project-3-git-clone-url", "sshkey-for-project-3", []]
]
JobDSLUtils.createMultibranchPipelineJob(this, multiBranchJobs)</code></pre>

            <p class="card-text">JobDSLUtils.groovy can look like</p>

<pre><code class="groovy">package com.rieh.dsl

class JobDSLUtils {
static void createFolder(Object context, List folders) {
context.with {
folders.each { item ->
    folder(item)
}
}
}

static void createMultibranchPipelineJob(Object context, List jobs) {
context.with {
jobs.each { job ->
    String jobName = job[0]
    String gitCloneUrl = job[1]
    String credential = job[2]
    List branchesToPull = job[3]
    multibranchPipelineJob(jobName) {
        branchSources {
            git {
                remote(gitCloneUrl)
                credentialsId(credential)
                if (branchesToPull.size() > 0) {
                    String branches = ""
                    branchesToPull.each { branch ->
                        branches += branch
                        branches += " "
                    }
                    branches = branches.substring(0, branches.length() - 1)
                    includes(branches)
                }
            }
        }
        orphanedItemStrategy {
            discardOldItem {
                numToKeep(10)
            }
        }
    }
}
}
}
}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Posted on January 17, 2019 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div> -->
    <!-- Jenkins END -->


  <!-- Docker BEGIN -->
  <div class="card mb-4" id="docker">
    <div class="card-body">
      <h2 class="card-title">Docker</h2>
      <ul class="list-unstyled mb-0">
        <li><a href="#docker-1">1. Docker basic</a></li>
        <li><a href="#docker-2">2. Useful Docker commands</a></li>
        <li><a href="#docker-3">3. Writing Dockerfile</a></li>
        <li><a href="#docker-4">4. Docker Examples</a></li>
        <li><a href="#docker-5">5. Docker exit codes</a></li>
        <li><a href="#docker-6">6. Configure Docker in Ubuntu</a></li>
        <li><a href="#docker-7">7. Docker storage</a></li>
        <li><a href="#docker-8">8. Docker service</a></li>
      </ul>
    </div>
  </div>

  <div class="card mb-4" id="docker-1">
    <div class="card-body">
      <h2 class="card-title">1. Docker basic</h2>
      <p class="card-text">Container - isolated environment to build/run software packages (container image is immutable)</p>
      <p class="card-text">Container benefits</p>
      <ul>
        <li>Efficient use of hardware since they run w/o VM</li>
        <li>Isolation</li>
        <li>Application portability and ease of delievery</li>
      </ul>
      <p class="card-text">Containters are highly configured processes (it is not lightweight). They leverage kernal features to isolate processes and shared OS kernal at the same time. cgroupd controls resources it can consume and namespaces control what process can see</p>
      <p class="card-text">Each layer represents each instruction in Dockerfile. all layers except the last one is read-only. docker image is consisted with a series of layers</p>
      <p class="card-text">Docker lifecycle</p>
      <ul>
        <li>CREATED -> (docker run) -> RUNNING -> (docker rm) -> REMOVE</li>
        <li>RUNNING -> (docker stop) -> STOPPED, STOPPED -> (docker restart) -> RUNNING</li>
        <li>RUNNING -> (docker pause) -> PAUSED, PAUSED -> (docker unpause) -> RUNNING</li>
      </ul>
      <p class="card-text">Kernel</p>
      <ul>
        <li>Namespaces - isolation (like hypervisor for VMs) like pid, net, mnt, ipc, user</li>
        <li>Control groups - setting the resource limits (for each container, for example)</li>
        <li>Containers, although isolated, shared the single OS Kernel</li>
        <li>Containers get their own namespaces</li>
      </ul>
      <p class="card-text">Docker Engine</p>
      <ul>
        <li>Docker Engine - client-server implementation where they run on the same host and communicate via REST API</li>
        <li>Docker client - provides docker CLI</li>
        <li>Docker server - daemon named dockerd, responds to client request</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="docker-2">
    <div class="card-body">
      <h2 class="card-title">2. Useful Docker commands</h2>
<pre><code class="bash"># Builds Dockerfile and create new image.
docker build -f [DockerfileName] -t [DockerImageName] .

# Tag and push image
docker tag &lt;image_name&gt;:&lt;tag&gt; &lt;registry_name&gt;/&lt;image_name&gt;:&lt;tag&gt;
docker push &lt;registry_name&gt;/&lt;image_name&gt;:&lt;tag&gt;

# See all containers in all states.
docker ps -a

# Stop all images, remove all images, and show images.
docker stop $(docker ps --latest --quiet) && docker rm $(docker ps -a -f status=exited -q) && docker ps -a

# Restart a container
docker restart &lt;image_name&gt;

# Login to the container.
docker exec -it [container_name] bash

# Run an image as container.
docker run -i -t &lt;image_name&gt;:&lt;tag&gt; /bin/bash</code></pre>

<pre><code class="bash"># Login to the container as root user.
docker exec -u 0 -it [container_name] bash

# Login to the latest container.
docker exec -it $(docker ps --latest --quiet) bash

# Map directories.
docker run -v [dir1]:[dir2] -u 0 -dit [container_name]</code></pre>

<pre><code class="bash"># Remove all exited containers.
docker rm -f $(docker ps -a -f status=exited -q)

# Remove all exited containers including its volumes.
docker rm -vf $(docker ps -a -f status=exited -q)</code></pre>

<pre><code class="bash"># Remove an image.
docker rmi &lt;Image_id&gt;

# Remove dangling (tagged with &lt;none&gt;) images.
docker image prune -f

# Remove unused (including dangling) images.
docker image prune -f -a

# Remove all images.
docker rmi -f $(docker images -a -q)</code></pre>

<pre><code class="bash"># Export an image.
docker save &lt;image_name&gt;:&lt;tag&gt; | gzip > my_image.tar.gz

# Import an image.
docker load -i &lt;image_name&gt;.tar.gz</code></pre>

<pre><code class="bash"># Tag an image.
docker image tag [IMAGE_ID] [TAG_NAME]

# Remove all unused containers, volumes, networks and images.
docker system prune -a --volumes

# Flag to map container port to host port.
--publish 80:8080

# Assuming docker-compose.yml exists
docker-compose up # Create images and run

# Recreate images and run
docker-compose stop $CONTAINER
docker-compose rm -f $CONTAINER
docker volume prune -f
docker-compose create $CONTAINER
docker-compose start $CONTAINER

docker inspect [container_name] # display container information
docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' [container_name] # get the container IP
docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq) # get All container IPs

# Investigate docker logs
docker logs -f [container_name]
journalctl -u docker.service

# Copy file from container to host.
docker cp &lt;container_id&gt;:/container/path/file /host/path/</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="docker-3">
    <div class="card-body">
      <h2 class="card-title">3. Writing Dockerfile</h2>
      <ul>
        <li>FROM - pulls base image</li>
        <li>WORKDIR - sets current working directory in container</li>
        <li>COPY - copies files from host to container</li>
        <li>RUN - executes commands in container</li>
        <li>EXPOSE - open ports in container</li>
        <li>ADD - similar to copy but has extra features such as local-only tar extraction. Should not be used fetch packages from remote URLs due to creating unnecessary layers (use wget and curl instead)</li>
        <li>ENV - environment variables that can be accessed in running applications</li>
        <li>ARG - environment variables that can be accessed in only during image creation</li>
        <li>ENTRYPOINT - allows configuring container that will run as an executable</li>
        <li>USER - set UID when running the image</li>
      </ul>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="docker-4">
    <div class="card-body">
      <h2 class="card-title">4. Docker Examples</h2>

<pre><code class="bash"># EX1: Privision and configure MSSQL with docker
# Assume the following environment variables
# SQL_USER="sqladmin"
# SQL_PASSWORD="changeMe0!"
# SQL_SERVER="changeme.database.windows.net"
# SQL_DBNAME="mydrivingDB"

# Install sqlcmd
curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -
curl https://packages.microsoft.com/config/ubuntu/20.10/prod.list | sudo tee /etc/apt/sources.list.d/msprod.list # Carefully watch out the ubuntu version you are using
sudo apt-get update
sudo apt-get install mssql-tools unixodbc-dev

docker pull mcr.microsoft.com/mssql/server
sudo docker run -e "ACCEPT_EULA=Y" -e "SA_PASSWORD=changeMe0!" -p 1433:1433 --name sql1 -h changeme.database.windows.net -d mcr.microsoft.com/mssql/server:2019-latest # Password must include uppercase, lowercase, number, and special character
sudo docker exec -it sql1 "bash"
/opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P "changeMe0!" # This should lead to sqlcmd command prompt
CREATE DATABASE mydrivingDB

# Find container IP of MSSQL container
SQL_CONTAINER_IP=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' sql1)
# Test connecting to SQL server outside the container
/opt/mssql-tools/bin/sqlcmd -S $SQL_CONTAINER_IP,1433 -U SA -P "changeMe0!"
QUIT

# Assume there is an app running under container name &lt;container_name&gt;. How to connect to SQL DB from the app
docker run --network host -e SQLFQDN=$SQL_CONTAINER_IP,1433 -e SQLUSER=sqladmin -e SQLPASS=changeMe0! -e SQLDB=mydrivingDB &lt;container_name&gt;
</code></pre>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-docker?view=sql-server-ver15&pivots=cs1-bash">Run SQL Server container images with Docker</a> | <a href="https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-setup-tools?view=sql-server-ver15">Install sqlcmd and bcp the SQL Server command-line tools on Linux</a>
    </div>
  </div>

  <div class="card mb-4" id="docker-5">
    <div class="card-body">
      <h2 class="card-title">5. Docker exit codes</h2>
      <ul>
        <li>Code 0 - container does not have a foreground process attached</li>
        <li>Code 1 - there is an application error</li>
        <li>Code 137 - container received SIGKILL (docker kill)</li>
        <li>Code 139 - container received SIGSEGV (segmentation fault)</li>
        <li>Code 143 - container received SIGTERM (docker stop)</li>
      </ul>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://medium.com/better-programming/understanding-docker-container-exit-codes-5ee79a1d58f6#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6ImZkYjQwZTJmOTM1M2M1OGFkZDY0OGI2MzYzNGU1YmJmNjNlNGY1MDIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MTM1NzM4MTAsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNDg0MzY5NzAyODQxMjQzODc2MyIsImVtYWlsIjoic2V1bmdtb29ucmllaEBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6IlNldW5nbW9vbiBSaWVoIiwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS8tYnpBOWplbjNkTzgvQUFBQUFBQUFBQUkvQUFBQUFBQUFBQUEvQU1adXVjbTZIUlo0aFdsS2h5R25LRFo4VTdaVC1FaHZady9zOTYtYy9waG90by5qcGciLCJnaXZlbl9uYW1lIjoiU2V1bmdtb29uIiwiZmFtaWx5X25hbWUiOiJSaWVoIiwiaWF0IjoxNjEzNTc0MTEwLCJleHAiOjE2MTM1Nzc3MTAsImp0aSI6IjY1NGE2YzQ1MGNkODMyNDJmNDI2ZDU1MjA5MGQzNDkxMTRhMzBlNDMifQ.HwDGYYQfaBy1ngNtOE1bGM97e5hkt2-uDqVtp54YFG_LUV7TzGDx3EDPojGNAV3SIRJ_BovhzKCHBuso8UclCntHjpQ0T1QjB6hJg_i8i9cU_7eJRMlM1SKxkEIBAxua_APLJwzI0f3eTUAnScg7AwRI3tu_TJ9Ip5T3u5F-7uheXbivqqEol0Z6GcaVZv3kHDdG-SzvDZ5h1NylmvQGyJOpoKXebyC6SIJzUZogicMWGnn6mAxt7dL87q-4wMM0T5k2FPhS2EXJLqTvSiIOtWMQ-FJ8UB7nzQJDT6eNrpHHCaokSeoQKTlLBA0M4iSPjMghru1LnXBy5FoJHJtNUg">Understanding Docker Container Exit Codes</a>
    </div>
  </div>

  <div class="card mb-4" id="docker-6">
    <div class="card-body">
      <h2 class="card-title">6. Configure Docker in Ubuntu</h2>
      <p class="card-text">To use a private docker repository, add the following in <strong>/etc/docker/daemon.json</strong></p>
<pre><code class="bash">{
"insecure-registries": [&lt;YOUR_REPO_ADDRESS_INCLUDING_PORT_NUMBER&gt;]
}</code></pre>
      <p class="card-text">If you want to use secure repo with proper certificates, create this directory <strong>/etc/docker/cert.d/&lt;YOUR_REPO_ADDRESS&gt;</strong> and copy certificates to this directory</p>
      <p class="card-text"><strong>Do docker login &lt;YOUR_REPO_ADDRESS&gt;</strong></p>
      <p class="card-text">Finally, issue <strong>sudo service docker restart</strong></p>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>

  <div class="card mb-4" id="docker-7">
    <div class="card-body">
      <h2 class="card-title">7. Docker storage</h2>
      <p class="card-text">Docker images are stored in <strong>/var/lib/docker/overlay2</strong></p>
<pre><code class="bash">docker system prune -a # Clean up container, network, image, build cache
docker volumes prune # Remove unused volumes</code></pre>

      <p class="card-text">Find an artifact (For example, log4j) in <strong>/var/lib/docker/overlay2</strong> that matches running images</p>
<pre><code class="bash">find /var/lib/docker/overlay2 -name "log4j-core-2" > overlay.txt
sed -i 's\merged.*/merged/' overlay.txt
sed -i 's\diff.*/diff/' overlay.txt
docker inspect $(docker ps -qa) | jq -r 'map([.Name, .GraphDriver.Data.MergedDir]) | .[] | "\(.[0])\t\(.[1])"' > docker-mappings.txt
grep -Fwf overlay.txt docker-mappings.txt</code></pre>
    </div>
    <div class="card-footer text-muted">
      Reference: <a href="https://fabianlee.org/2021/04/08/docker-determining-container-responsible-for-largest-overlay-directories/">Docker: determining container responsible for largest overlay directories</a>
    </div>
  </div>

  <div class="card mb-4" id="docker-8">
    <div class="card-body">
      <h2 class="card-title">8. Docker service</h2>
<pre><code class="bash">docker service ls
docker service rm &lt;service name&gt;
docker service rm inspect --pretty &lt;service id&gt;</code></pre>
    </div>
    <div class="card-footer text-muted">

    </div>
  </div>


    <!-- <li>cd docker-ssh-slave && docker rmi jenkins/ssh-slave #This is to ensure that we remove the image with same name if it exists</li>
    <li>docker load -i openjdk_8-jdk.tar #Before doing this, you must obtain openjdk_8-jdk.tar file from the Internet</li>
    <li>#Prepare your &#34;Dockerfile&#34;</li>
    <li>docker build . -t jenkins/ssh-slave #This command actually builds the docker image</li>
    <li>docker run -u 0 -dit jenkins/ssh-slave</li>
    <li>docker exec -u 0 -it $(docker ps --latest --quiet) bash #After this command, you should test the image</li>
    <li>exit #exit the image when done the testing</li>
    <li>docker stop $(docker ps --latest --quiet) && docker rm $(docker ps -a -f status=exited -q)</li>
    <li>docker save -o jenkins-ssh-slave.tar jenkins/ssh-slave</li>
    <li>scp jenkins-ssh-slave.tar [your_username]@[your_docker_registry_server_ip]:/[your_registry_directory]</li>
    <li>ssh [your_username]@[your_docker_registry_server_ip]</li>
    <li>cd [your_registry_directory] && docker load -i jenkins-ssh-slave.tar</li>
    <li>docker tag jenkins/ssh-slave [your_image_name]:5000/jenkns/ssh-slave #To push your image to registry, you must tag it first</li>
    <li>docker push [your_image_name]:5000/jenkns/ssh-slave</li> -->

    <!-- <p class="card-text">An example of Dockerfile could look like the following</strong></p>
            <pre><code class="groovy">
FROM openjdk:8-jdk
LABEL MAINTAINER="Seungmoon Rieh &lt;seungmoon.rieh@gmail.com&gt;"

ARG user=jenkins
ARG group=jenkins
ARG uid=10000
ARG gid=10000
ARG JENKINS_AGENT_HOME=/home/${user}

ENV JENKINS_AGENT_HOME ${JENKINS_AGENT_HOME}

RUN groupadd -g ${gid} ${group} && useradd -d "${JENKINS_AGENT_HOME}" -u "${uid}" -g "${gid}" -m -s /bin/bash "${user}"

# Write unix command to install necessary tools

RUN sed -i /etc/ssh/sshd_config \
-e 's/#PermitRootLogin.*/PermitRootLogin no/' \
-e 's/#RSAAuthentication.*/RSAAuthentication yes/' \
-e 's/#PasswordAuthentication.*/PasswordAuthentication no/' \
-e 's/#SyslogFacility.*/SyslogFacility AUTH/' \
-e 's/#LogLevel.*/LogLevel INFO/'  && \
mkdir /var/run/sshd

VOLUME "${JENKINS_AGENT_HOME}" "/tmp" "/run" "/var/run"
WORKDIR "${JENKINS_AGENT_HOME}"

COPY setup-sshd /usr/local/bin/setup-sshd

EXPOSE 22

ENTRYPOINT ["setup-sshd"]</code></pre> -->

    <!-- <div class="card mb-4" id="docker-4">
        <div class="card-body">
            <h2 class="card-title">4. Setting up Docker registry on Linux</h2>
<pre><code class="bash">docker pull registry:2
docker save -o registry_2.tar registry:2
docker load -i registry.tar
docker run -d --net=host -p 5000:5000 -v []/docker-registry-data:[]/registry --name registry --restart always registry:2</code></pre>
            </ul>
        </div>
        <div class="card-footer text-muted"></div>
    </div> -->

    <!-- <div class="card mb-4" id="docker-5">
        <div class="card-body">
            <h2 class="card-title">5. Setting up Dockerhost</h2>
            <p class="card-text">This is to show how to construct a Jenkins "build server" where all work would be done inside docker container (for RedHat 7 distribution)</p>
<pre><code class="bash">sudo subscription-manager repos-enable rhel-7-server-extras-rpms
sudo yum update
sudo yum list docker\*
sudo yum install docker.x86_64
sudo groupadd docker
sudo usermod -aG docker [your_username_or_service_account]
sudo systemctl enable docker
sudo chkconfig docker on
sudo systemctl start docker
From &#34;/lib/systemd/system/docker.service&#34;, add this line &#34;-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock&#34;
sudo systemctl daemon-reload<
sudo service docker restart
>curl http://localhost:4243/version</code></pre>
        </div>
        <div class="card-footer text-muted"></div>
    </div> -->

    <!-- <div class="card mb-4" id="docker-9">
        <div class="card-body">
            <h2 class="card-title">9. Installing Docker on Redhat</h2>
            <p class="card-text"></p>
            <ul>
                <li>To install RedHat from Windows, follow this guide <a href="#virtualbox-1">Virtual Box</a></li>
                <li>Install docker from yum repo - <strong>sudo yum install docker</strong></li>
                <li>Enable docker service - <strong>sudo systemctl enable docker.service</strong></li>
                <img class="img-fluid" class="card-img-top" src="img/docker/docker-8-a.png" alt="Card image cap" style="max-width:700px">
                <li>Start docker service - <strong>sudo systemctl start docker.service</strong></li>
                <li>Check docker status - <Strong>sudo systemctl status docker.service</Strong></li>
                <img class="img-fluid" class="card-img-top" src="img/docker/docker-8-b.png" alt="Card image cap" style="max-width:700px">
            </ul>
        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://www.cyberciti.biz/faq/install-use-setup-docker-on-rhel7-centos7-linux/">install-use-setup-docker-on-rhel7-centos7-linux</a>
        </div>
    </div> -->

    <!-- <div class="card mb-4" id="docker-10">
        <div class="card-body">
            <h2 class="card-title">10. Writing Dockerfile for Jenkins master</h2>
            <p class="card-text">Dockerfile-jenkins-master</p>

<pre><code class="groovy">FROM jenkins/jenkins:lts

# Plugins for better UX (not mandatory)
RUN /usr/local/bin/install-plugins.sh ansicolor
RUN /usr/local/bin/install-plugins.sh greenballs

# Plugin for scaling Jenkins agents
RUN /usr/local/bin/install-plugins.sh kubernetes

USER jenkins</code></pre>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://rancher.com/blog/2018/2018-11-27-scaling-jenkins/">Deploying and Scaling Jenkins on Kubernetes</a>
        </div>
    </div>

    <div class="card mb-4" id="docker-11">
        <div class="card-body">
            <h2 class="card-title">11. Writing Dockerfile for Jenkins agent</h2>
            <p class="card-text">touch empty-test-file</p>
            <p class="card-text">Dockerfile-jenkins-slave-jnlp1 (Do this for each agent with different name)</p>

<pre><code class="groovy">FROM jenkins/jnlp-slave

# For testing purpose only
COPY empty-test-file /jenkins-slave1

ENTRYPOINT ["jenkins-slave"]</code></pre>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://rancher.com/blog/2018/2018-11-27-scaling-jenkins/">Deploying and Scaling Jenkins on Kubernetes</a>
        </div>
    </div>

    <div class="card mb-4" id="docker-12">
        <div class="card-body">
            <h2 class="card-title">12. Build and push images</h2>
            <p class="card-text">Replace [dockerhub_user] with appropriate username</p>
<pre><code class="bash">docker build -f Dockerfile-jenkins-master -t [dockerhub_user]/jenkins-master .</li>
docker images
docker login
docker push [dockerhub_user]/jenkins-master
docker build -f Dockerfile-jenkins-slave-jnlp1 -t [dockerhub_user]/jenkins-slave-jnlp1 .
docker push [dockerhub_user]/jenkins-slave-jnlp1
docker build -f Dockerfile-jenkins-slave-jnlp2 -t [dockerhub_user]/jenkins-slave-jnlp2 .
docker push [dockerhub_user]/jenkins-slave-jnlp2</code></pre>
            </ul>
        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://rancher.com/blog/2018/2018-11-27-scaling-jenkins/">Deploying and Scaling Jenkins on Kubernetes</a>
        </div>
    </div> -->
    <!-- Docker END -->


    <!-- Kubernetes BEGIN -->
    <div class="card mb-4" id="kubernetes">
      <div class="card-body">
        <h2 class="card-title">Kubernetes</h2>

        <ul class="list-unstyled mb-0">
          <li><a href="#kubernetes-1">1. Kubectl</a></li>
        </ul>

        <ul>
          <li>Deployment - declarative updates for Pod and ReplicaSet including rollouts and rollbacks</li>
          <li>ReplicationController - no longer used</li>
          <li>ReplicaSet - creates Pods (should not be manipulated, Deployment should be used instead)</li>
          <li>StatefulSet - similar to Deployment, but provides uniqueness and ordering of Pods</li>
          <li>DaemonSet - exactly one Pod per Node. Deleting it clean up Pods.</li>
          <li>Job - create short living Pods. Deleting it clean up Pods.</li>
          <li>Cron Job - create Jobs on repeating schedule</li>
          <li>Pod - smallest deployable unit
            <ul>
              <li>Init container - runs before app containers</li>
            </ul>
          </li>
        </ul>

        <ul>
          <li>Ingress Controller - specification of Ingress</li>
          <li>Ingress - provides external access to Service</li>
          <li>Service - manages traffic to Pods</li>
          <ul>
            <li>Cluster IP - Service is accessible only within the cluster</li>
            <li>Node Port - expose Service at each Node's IP and port</li>
            <li>LoadBalancer - expose Service using external load balancer</li>
            <li>External Name - map Service to an existing DNS FQDN</li>
          </ul>
          <li>Network Policy - denie/allows traffic to/from Pods</li>
        </ul>

        <ul>
          <li>Storage Class - configuration for storage</li>
          <li>Persistent Volumes - piece of storage, simialr to Node</li>
          <li>Persistent Volumes Claim - request for storage, simialr to Pod. Can request size and access mode. Pods mount this</li>
          <li>Volume Snapshot Class - simialr to Storage Class but for Volume Snapshot</li>
          <li>Volume Snapshot Content - snapshot taken from a volume</li>
          <li>Volume Snapshot - request for a snapshot</li>
          <li>ConfigMap - configuration data separate from app code. Must be in the same namespace with Pod</li>
          <li>Secret - similar to ConfigMap but specifically for confidential data</li>
          <li>emptyDir - temp storage created when Pod is assigned to Node. Deleted when Pod is removed</li>
        </ul>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Deployments</h2>
        <p class="card-text">Provides declarative updates for Pods and ReplicaSets. Deployment Controller change an actual state to a desired state at a controlled rate</p>
        <p class="card-text">Usecase</p>
        <ul>
          <li>Create a Deployment to rollout a ReplicaSet, which creates Pods in the background</li>
          <li>Declare the new state of Pods by updating the PodTemplateSpec of the Deployment</li>
          <li>Rollback to an earlier Deployment version</li>
          <li>Scale up the Deployments</li>
          <li>Clean up old ReplicaSets</li>
        </ul>
        <p class="card-text">Create a Deployment</p>
<pre><code class="yaml">apiVersion: apps/v1 # Mandatory field
kind: Deployment # Mandatory field
metadata: # Mandatory field
name: nginx-deployment # Deployment named ".metadata.name" is created
labels:
app: nginx
spec:
replicas: 3 # Three replicated Pods. If this field does not exist, it will default to 1
selector: # Required field for "spec". This specifies the label selector of Pod targeted by this Deployment
matchLabels:
  app: nginx # How Deployment finds which Pods to manage
template: # Required field for "spec". This is a Pod template, which has the same schema as Pod
metadata:
  labels:
    app: nginx # Pod label. This must match ".spec.selector"
spec:
  containers: # nginx container runs nginx image version 1.14.2
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80</code></pre>
        <ul>
          <li>To create Deployment
<pre><code class="bash">kubectl apply -f nginx-deployment.yaml</pre></code></li>
          <li>To check Deployment
<pre><code class="bash">kubectl get deployments</code></pre></li>
<img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-4-a.png" alt="Card image cap">
          <ul>
            <li>NAME - names of Deployments in the namespace</li>
            <li>READY - how many replicas of the application are available to users</li>
            <li>UP TO DATE - number of replicas updated to achieve the desired state</li>
            <li>AVAILABLE - how many replicas of the application are available to users</li>
            <li>AGE - amount of time the appliation has been running</li>
          </ul>
          <li>To check Deployment rollout status
<pre><code class="bash">kubectl rollout status deployment/nginx-deployment</code></pre></li>
          <li>To see the ReplicaSet created by Deployment
<pre><code class="bash">kubectl get rs</code></pre></li>
<img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-4-a.png" alt="Card image cap">
          <ul>
            <li>NAME - names of ReplicaSets in the namespace</li>
            <li>DESIRED - desired number of replicas in the application</li>
            <li>CURRENT - how many applications are currently running</li>
            <li>READY - how many replicas of the application are available to users</li>
            <li>AGE - amount of time the appliation has been running</li>
          </ul>
          <li>To see the labels generated for each Pod
<pre><code =>kubectl get pods --show-labels</code></pre></li>
          <li>To update iamge from nginx:1.14.2 to nginx:1.16.1, run one of the following
<pre><code class="bash">kubectl --record deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1</code></pre>
<pre><code class="bash">kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 --record</code></pre></li>
          <li>To see the rollout status
<pre><code class="bash">kubectl rollout status deployment/nginx-deployment</code></pre></li>
        </ul>
        <p class="card-text">Deployment ensures that at least 75% of Pods are up while they are being updated. It also ensures that at most 125% of the desired number of Pods are up</p>

        <p class="card-text">Rollover</p>
        <ul>
          <li>Everytime a new Deployment is observed by Deployment Controller, a ReplicaSet is created to bring up the desired Pods</li>
          <li>If Deployment is updated, the existing ReplicaSet that control Pods whose labels match <code>.spec.selector</code> but whose template does not match <code>.spec.template</code> are scaled down</li>
          <li>Eventually, new ReplicaSet is scaled to <code>.spec.replicas</code> and all old ReplicaSets is scaled to 0</li>
        </ul>

        <p class="card-text">Rollback</p>
        <ul>
          <li>Check the revisions of Deployment</li>
<pre><code class="bash">kubectl rollout history deployment.v1.apps/nginx-deployment</code></pre>
          <li>To see the details of each revision</li>
<pre><code class="bash">kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2</code></pre>
          <li>Rollback to a specific version</li>
<pre><code class="bash">kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2</code></pre>
        </ul>

        <p class="card-text">Scaling</p>
        <ul>
          <li>Scale a Deployment</li>
<pre><code class="bash">kubectl scale deployment.v1.apps/nginx-deployment --replicas=10</code></pre>
          <li>Setup autoscaler for Deployment and choose the minimum and maximum number of Pods</li>
<pre><code class="bash">kubectl autoscale deployment.v1.apps/nginx-deployment --min=10 --max=15 --cpu-percent=80</code></pre>
          <li>Rollback to a specific version</li>
<pre><code class="bash">kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2</code></pre>
        </ul>

        <p class="card-text">Proportional scaling</p>
        <ul>
          <li>Deployment Controller balances additional replicas in the existing ReplicaSets</li>
        </ul>

        <p class="card-text">Pause and resume Deployment</p>
        <ul>
          <li>Can apply multiple fixes in between pausing and resuming without triggering unnecessary rollouts</li>
          <li>To pause the Deployment</li>
<pre><code class="bash">kubectl rollout pause deployment.v1.apps/nginx-deployment</code></pre>
          <li>Can update the image</li>
<pre><code class="bash">kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1</code></pre>
          <li>Can update the resources</li>
<pre><code class="bash">kubectl set resources deployment.v1.apps/nginx-deployment -c=nginx --limits=cpu=200m,memory=512Mi</code></pre>
          <li>To resume the Deployment</li>
<pre><code class="bash">kubectl rollout resume deployment.v1.apps/nginx-deployment</code></pre>
        </ul>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">ReplicaSet</h2>
        <p class="card-text">Generally, ReplicaSet should not be manipulated. Rather, Deployment should be used.</p>
        <p class="card-text">ReplicaSet is mapped to Pod by Pod's metadata.ownerReferences field.</p>
<pre><code class="yaml">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # modify replicas according to your case
  replicas: 3
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google_samples/gb-frontend:v3</code></pre>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: pod1
  labels:
    tier: frontend
spec:
  containers:
  - name: hello1
    image: gcr.io/google-samples/hello-app:2.0

---

apiVersion: v1
kind: Pod
metadata:
  name: pod2
  labels:
    tier: frontend
spec:
  containers:
  - name: hello2
    image: gcr.io/google-samples/hello-app:1.0</code></pre>
        <p class="card-text">These Pods do not have Controller as their owner reference. And they match the selector of frontend ReplicaSet (right above). This means these Pods will be acquired by that ReplicaSet. Moreover, if the frontend ReplicaSet is already deployed, creating these two additional Pods cause them to immediately terminate because the ReplicaSet exceeds the desired count.</p>
        <p class="card-text">Delete ReplicaSet and its Pods.</p>
<pre><code class="bash">kubectl proxy --port=8080
curl -X DELETE  'localhost:8080/apis/apps/v1/namespaces/default/replicasets/frontend' \
> -d '{"kind":"DeleteOptions","apiVersion":"v1","propagationPolicy":"Foreground"}' \
> -H "Content-Type: application/json"</code></pre>
        <p class="card-text">Delete just a ReplicaSet</p>
<pre><code class="bash">kubectl proxy --port=8080
curl -X DELETE  'localhost:8080/apis/apps/v1/namespaces/default/replicasets/frontend' \
> -d '{"kind":"DeleteOptions","apiVersion":"v1","propagationPolicy":"Orphan"}' \
> -H "Content-Type: application/json"</code></pre>
        <p class="card-text">Scale-down a ReplicaSet</p>
        <ul>
          <li>Pending Pods are scaled-down first</li>
          <li>If controller.kubernetes.io/pod-deletion-cost annotation is set, Pods with lower value are scaled-down second</li>
          <li>Pods on Nodes with more replicas are scaled-down thrid</li>
          <li>Pods created recently are scaled-down fourth</li>
        </ul>
      </div>

      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">StatefulSet</h2>
        <p class="card-text">Similar to Deployment, but guarantees ordering and uniqueness of Pods.</p>
        <p class="card-text">Usecase</p>
        <ul>
          <li>Stable, unique network identifier</li>
          <li>Stable, persistent storage</li>
          <li>Ordered, graceful deployment and scaling</li>
          <li>Ordered, automated rolling updates</li>
        </ul>
        <p class="card-text">Limitations</p>
        <ul>
          <li>Storage for a Pod must be provisioned by PersistentVolumns Provsioner</li>
          <li>Deleting StatefulSet does not delete volumns associated with it</li>
          <li>StatefulSet requires Headless Service for the network identity of the Pods</li>
          <li>StatefulSet does not guarantee on the termination of Pods when Statefulset gets deleted</li>
        </ul>
        <p class="card-text">Example</p>
        <ul>
          <li>Headless service named "nginx" is used to control the network domain</li>
          <li>3 replicas of nginx container will be launched in unique Pods</li>
          <li>volumeClaimTemplates will provide stable storage using PersistentVolumns</li>
        </ul>
<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx # has to match .spec.template.metadata.labels
  serviceName: "nginx"
  replicas: 3 # by default is 1
  template:
    metadata:
      labels:
        app: nginx # has to match .spec.selector.matchLabels
    spec:
      terminationGracePeriodSeconds: 10
      containers:
      - name: nginx
        image: k8s.gcr.io/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: www
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "my-storage-class"
      resources:
        requests:
          storage: 1Gi</code></pre>
          <ul>
            <li>Three Pods will be deployed in the order web-0, web-1, web-2</li>
            <li>web-1 will not be deployed until web-0 is Running and Ready</li>
            <li>When scaling down, web-1 will not be terminated until web-2 is fully shutdown</li>
          </ul>
        </div>
        <div class="card-footer text-muted">
          Reference: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a>
        </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">DaemonSet</h2>
        <p class="card-text">DaemonSet ensures that as Nodes are added Pods are added them, and as Nodes are added Pods are garbage collected.</p>
<pre><code class="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      tolerations:
      # this toleration is to have the daemonset runnable on master nodes
      # remove it if your masters can't run pods
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      containers:
      - name: fluentd-elasticsearch
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Jobs</h2>
        <p class="card-text">A Job creates one more more Pods. It reliably runs one Pod to completion. Deleting a Job will clean up Pods it created. Suspending a Job will delete its active Pods</p>
        <p class="card-text">A Job is better than bare Pod because it can automatically replace failed Pod with new one. While Replication Controller manages Pods that are not expected to terminate, Job manages Pods that are expected to terminate</p>
        <p class="card-text">Example</p>
<pre><code class="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
  backoffLimit: 4</code></pre>
        <p class="card-text">To list all the Pods that belong to a Job</p>
<pre><code class="bash">run pods=$(kubectl get pods --selector=job-name=pi --output=jsonpath='{.items[*].metadata.name}') && echo $pods"</code></pre>
        <p class="card-text">Three types of tasks suitable to run as a Job</p>
        <ul>
          <li>Non-parallel Jobs - normally only one Pod is started. Job is complete as soon as its Pod terminates successfully. Can leave both <code>.spec.completions</code> and <code>.spec.parallelism</code> unset (they will default to 1)</li>
          <li>Parallel Jobs with a fixed completion count - Job is complete when there is one successful Pod for each value in the range 1 to <code>.spec.completions</code></li>
          <li>Parallel Jobs with a work queue - when any Pod from the Job terminates with success, no new Pods are created. Once at least one Pod is terminated with success and all Pods are terminated, Job succeeds. Must leave <code>.spec.completions</code> unset and set <code>.spec.parallelism</code> to a non-negative integer</li>
        </ul>
        <p class="card-text">Requested parallelism <code>.spec.parallelism</code> is set to 1 if not specified. Setting it to 0 makes Job effective paused</p>
        <ul>
          <li>Fixed completion count Jobs - actual number of Pods running in parallel will not exceed the number of remaining completions. Higher value of <code>.spec.parallelism</code> is ignored</li>
          <li>Work queue Jobs - no new Pods are started after any Pod has succeeded</li>
        </ul>
        <p class="card-text">Pod and container failure</p>
        <ul>
          <li>If container fails and <code>.spec.template.spec.restartPolicy = "OnFailure"</code>, Pod stays on the node but container re-runs. You can avoid this by <code>.spec.template.spec.restartPolicy = "Never"</code></li>
          <li>If Pod fails, then Job Controller starts a new Pod</li>
          <li><code>.spec.backoffLimit</code> is specifiy number fo retries before marking Job as failure (default is 6)</li>
        </ul>
        <p class="card-text">Job termination and cleaup</p>
        <ul>
          <li>Delete the Job, all the Pods created by that Job are deleted too</li>
          <li>Setting <code>.spec.activeDeadlineSeconds</code> will make Job fail and terminate all running Pods once <code>activeDeadlineSeconds</code> is reached</li>
        </ul>
<pre><code class="yaml">apiVersion: batch/v1
kind: JobapiVersion: batch/v1
kind: Job
metadata:
  name: pi-with-timeout
spec:
  backoffLimit: 5
  activeDeadlineSeconds: 100
  template:
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/">Jobs</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Cron Job</h2>
        <p class="card-text">It can create Jobs on a repeating schedule or any individual tasks</p>
        <p class="card-text">Example</p>
<pre><code class="yaml">apiVersion: batch/v1beta1
kind: CronJob
metadata:
name: hello
spec:
schedule: "*/1 * * * *"
jobTemplate:
  spec:
    template:
      spec:
        containers:
        - name: hello
          image: busybox
          imagePullPolicy: IfNotPresent
          command:
          - /bin/sh
          - -c
          - date; echo Hello from the Kubernetes cluster
        restartPolicy: OnFailure</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">CronJob</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Pods</h2>
        <p class="card-text">Its the smallest deployable unit</p>
        <ul>
          <li>Can contain an init container tha runs during Pod startup</li>
          <li>Similar to Docker containers with shared namespace and volumn</li>
          <li>Pod gets created by resources such as Deployment, Job, or StatefulSet</li>
          <li>Controller for those resources handles Pod replication, rollout, and failure</li>
          <li>Controllers create Pod from Pod Template</li>
<pre><code class="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  template:
    # This is the pod template
    spec:
      containers:
      - name: hello
        image: busybox
        command: ['sh', '-c', 'echo "Hello, Kubernetes!" && sleep 3600']
      restartPolicy: OnFailure
    # The pod template ends here</code></pre>
            <li>Modifying the Pod Template will make StatefulSet to create new Pods, which then will replace old Pods</li>
            <li>Every container in a Pod share the same IP address and port. These containers can communicate to each other using localhost</li>
            <li>Any container in a Pod can enable privileged mode to use OS admin level capabilities</li>
            <li>Static Pods are managed directly by kubelet without API server. Kubelet though will create mirror Pods on API server for each static Pod</li>
          </ul>

          <h3 class="card-title">Pod Lifecycle</h3>
          <ul>
            <li>Pods are created, assinged a unique ID (UUID), and scheduled to nodes. They can never be rescheduled to different nodes</li>
          </ul>
          <p class="card-text">Pod lifecycle</p>
          <ul>
            <li>Pending - containers have not been setup yet</li>
            <li>Running - Pod is bounded to a node. Containers are created but still running</li>
            <li>Succeeded (Completed when <strong>restartPloicy:Never</strong>) - Containers are terminated with success</li>
            <li>Failed (CrashLoopBackoff when Pod fails or exits unexpectedly) - At least one container is terminated with failure</li>
            <li>Unknown - Pod status cannot be obtained. Most often error communicating with the node</li>
          </ul>
          <p class="card-text">Container lifecycle</p>
          <ul>
            <li>Waiting - running operations to complete startup</li>
            <li>Running - executing without issues</li>
            <li>Terminated - either ran to completion or failed</li>
          </ul>
          <p class="card-text">Container restart policy</p>
          <ul>
            <li><code>spec</code> of Pod has <code>restartPolicy</code>, which has Always, OnFailure, Never. Default is Always</li>
          </ul>
          <p class="card-text">Pod condition</p>
          <ul>
            <li>PodScheduled - Pod is scheduled to a node</li>
            <li>ContainersReady - all containers in Pod are ready</li>
            <li>Initialized - all init containers are started</li>
            <li>Ready - Pod can serve requests</li>
          </ul>
          <p class="card-text">Pod readiness</p>
          <ul>
            <li><code>spec</code> of Pod has <code>readinessGates</code>, that allows additional conditions to be specified</li>
          </ul>
<pre><code class="yaml">kind: Pod
...
spec:
  readinessGates:
    - conditionType: "www.example.com/feature-1"
status:
  conditions:
    - type: Ready                              # a built in PodCondition
      status: "False"
      lastProbeTime: null
      lastTransitionTime: 2018-01-01T00:00:00Z
    - type: "www.example.com/feature-1"        # an extra PodCondition
      status: "False"
      lastProbeTime: null
      lastTransitionTime: 2018-01-01T00:00:00Z
  containerStatuses:
    - containerID: docker://abcd...
      ready: true
...</code></pre>
          <p class="card-text">Container probe</p>
          <ul>
            <li>Kubelet performs diagnostic on a container periodically (this is call Probe)</li>
            <li>Kubelet calls Handler, which is implemented by the container</li>
            <li>ExecAction Handler - executes a command inside container. Diagnostic successful if command exits with 0</li>
            <li>TCPSocketAction Handler - TCP check on IP address on specified port. Diagnostic successful if port is open</li>
            <li>HTTPGetAction Handler - HTTP GET check on IP address on specified port and path. Diagnostic successful if  200 &le; response &lt; 400</li>
          </ul>
          <p class="card-text">livenessProbe</p>
          <ul>
            <li>Indicates whether the container is running. If liveenss probe fails, the kubelet kills the container, and container is subject to its restart policy</li>
          </ul>
          <p class="card-text">readinessProbe</p>
          <ul>
            <li>Indicates whether the container is ready to respond to requests. If readiness probe fails, then endpoint controller removes Pod IP address from Service endpoints that match the Pod</li>
            <li>Used when container needs to load large data, configuration files</li>
          </ul>
          <p class="card-text">startupProbe</p>
          <ul>
            <li>Indicates whether the application within the container has started. If starup probe fails, the kubelet kills the container, and container is subject to its restart policy</li>
            <li>Used when containers take long time to come into service</li>
          </ul>
          <p class="card-text">Pod Termination</p>
          <ul>
            <li>Kubelet tool to delete Pod, with default graceful period of 30 seconds</li>
            <li>Control plane removes shutting-down Pods from Endpoints</li>
            <li>Resources no longer trest shutting-down Pods valid</li>
            <li>When the grace period expires, kubelet triggeres forcible shutdown (contrainer runtime sends SIGKILL to any running processes in containers)</li>
            <li>API server deletes Pod's object</li>
          </ul>

          <h3 class="card-title">Labels, Selectors, and Annotations</h3>
          <p class="card-text">Labels - key/value pairs enabling users to map their own structures to system objects (for example, Pods) in loosely coupled fashion. Labels do not need to be unique.</p>
<pre><code class="yaml">"metadata": {
  "labels": {
    "key1" : "value1",
    "key2" : "value2"
  }
}</code></pre>
          <p class="card-text">Example, Pods with two labels <code>environment: production</code> and <code>app: nginx</code></p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: label-demo
  labels:
    environment: production
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80</code></pre>
          <p class="card-text">Selectors - equality-based allows filtering by label keys and values while set-based allows filtering keys according to a set of values. For example,</p>
<pre><code class="bash">kubectl get pods -l environment=production,tier=frontend # equality based
kubectl get pods -l 'environment in (production),tier in (frontend)' # set based</code></pre>
          <p class="card-text">Service and Replication Controller only support equality-based selector</p>
<pre><code class="yaml">selector:
  component: redis</code></pre>
          <p class="card-text">Job, Deployment, ReplicaSet, DaemonSet also support set-based selector</p>
<pre><code class="yaml">selector:
matchLabels:
  component: redis
matchExpressions:
  - {key: tier, operator: In, values: [cache]}
  - {key: environment, operator: NotIn, values: [dev]}</code></pre>
          <p class="card-text">Annotations - allows attaching arbitrary non-identifying metadata to objects (while Labels are used to select objects, annotations are for recording metadata)</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: annotations-demo
  annotations:
    imageregistry: "https://hub.docker.com/"
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80</code></pre>

          <h3 class="card-title">Init Containers</h3>
          <p class="card-text">Specialized containers that run before app containers in Pod</p>
          <ul>
            <li>Init containers always run to completion</li>
            <li>Each init container must succeed before next one can run</li>
            <li>If init container fails, kubelet repeatly restarts the container</li>
            <li>Init containers do not support lifecycle, livenessProbe, readinessProbe, startupProbe because they must run to completion before Pod can be ready</li>
            <li>Init containers can have custom code and no need to use FROM</li>
            <li>Init containers can be given access to Secret (unlike app containers)</li>
            <li>If Pod restarts, all init containers must run again</li>
            <li>Init container code must be idempotent (because they can be re-run)</li>
          </ul>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: ['sh', '-c', "until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"]
  - name: init-mydb
    image: busybox:1.28
    command: ['sh', '-c', "until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done"]</code></pre>
          <p class="card-text">Init containters would be waiting to discover Services named myservice and mydb. </p>
<pre><code class="yaml">---
apiVersion: v1
kind: Service
metadata:
  name: myservice
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9376
---
apiVersion: v1
kind: Service
metadata:
  name: mydb
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9377</code></pre>

          <h3 class="card-title">Pod Topology Spread Constraints</h3>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-a.png" alt="Card image cap">
<pre><code class="yaml">kind: Pod
apiVersion: v1
metadata:
  name: mypod
  labels:
    foo: bar
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        foo: bar
  containers:
  - name: pause
    image: k8s.gcr.io/pause:3.1</code></pre>
          <p class="card-text">If a new Pod goes to Zone A, then the skew will be 3-1=2, which will exceed the maxSkew of 1. Thus, it can only go to Zone B such that</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-b.png" alt="Card image cap">

          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-c.png" alt="Card image cap">
<pre><code class="yaml">kind: Pod
apiVersion: v1
metadata:
  name: mypod
  labels:
    foo: bar
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        foo: bar
  - maxSkew: 1
    topologyKey: node
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        foo: bar
  containers:
  - name: pause
    image: k8s.gcr.io/pause:3.1</code></pre>
          <p class="card-text">A new Pod can only go to Zone B to meet the maxSkew of 1 in the first constraint. However at the same time, it can only go to Node 2 to meet the maxSkew of 1 in the second constraint. Because whenUnsatisfiable is DoNotSchedule in both constraints, new Pod cannot be scheduled. (it would be scheduled if whenUnsatisfiable is ScheduleAnyway)</p>

          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-d.png" alt="Card image cap">
<pre><code class="yaml">kind: Pod
apiVersion: v1
metadata:
  name: mypod
  labels:
    foo: bar
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        foo: bar
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: zone
            operator: NotIn
            values:
            - zoneC
  containers:
  - name: pause
    image: k8s.gcr.io/pause:3.1</code></pre>
          <p class="card-text">This will exclude Zone C from the constraint such that a new Pod goes to Zone B rather than Zone C</p>

          <h4 class="card-title">Cluster-Level Default Constraints</h4>
<pre><code class="yaml">apiVersion: kubescheduler.config.k8s.io/v1beta1
kind: KubeSchedulerConfiguration

profiles:
  - pluginConfig:
      - name: PodTopologySpread
        args:
          defaultConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: ScheduleAnyway
          defaultingType: List</code></pre>
          <ul>
            <li>Pod Affinity - can place any number of Pods into qualifying topology domains</li>
            <li>Pod Anti-Affinity - can only place one Pod into a single topology domain</li>
          </ul>

          <h3 class="card-title">Multi-container pod design</h3>
          <p class="card-text">Each pod can have multiple containers (which would run on the same node). This make communication between containers faster and securer, and allow them to share volumns and file systems</p>

          <p class="card-text"><strong>Sidecar</strong></p>
          <p class="card-text">Enhance/extend existing functionality of container</p>
          <p class="card-text">For example, an app container can stream logs to a particular location while the sidecar container mounts the logs to some other directory</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: sidecar-pod
spec:
  volumes:
  - name: logs
    emptyDir: {}
  containers:
  - name: app-container
    image: alpine
    command: ["/bin/sh"]
    args: ["-c", "while true; do date >> /var/log/app.log; sleep 2;done"]
    volumeMounts:
    - name: logs
      mountPath: /var/log
  - name: log-exporter-sidecar
    image: nginx
    ports:
      - containerPort: 80
    volumeMounts:
    - name: logs
      mountPath: /usr/share/nginx/html</code></pre>
          <p class="card-text">"app-container" streams logs to /var/log/app.log while "log-exporter-sidecar" mounts those logs into /usr/share/nginx/html</p>

          <p class="card-text"><strong>Ambassador</strong>
          <p class="card-text">Serves as a proxy to external worlds (this for for legacy apps, ConfigMap should be used for new apps)</p>
          <p class="card-text">For example, when connecting to a DB server and that server config changes across different environments, the ambassador container can act as a TCP proxy to the database, which can be connected via localhost. The sysadmin can use config maps and secrets with the proxy container to inject the correct connection and auth information</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: ambassador-pod
  labels:
    app: ambassador-app
spec:
  volumes:
  - name: shared
    emptyDir: {}
  containers:
  - name: app-container-poller
    image: yauritux/busybox-curl
    command: ["/bin/sh"]
    args: ["-c", "while true; do curl 127.0.0.1:81 > /usr/share/nginx/html/index.html; sleep 10; done"]
    volumeMounts:
    - name: shared
      mountPath: /usr/share/nginx/html
  - name: app-container-server
    image: nginx
    ports:
      - containerPort: 80
    volumeMounts:
    - name: shared
      mountPath: /usr/share/nginx/html
  - name: ambassador-container
    image: bharamicrosystems/nginx-forward-proxy
    ports:
      - containerPort: 81</code></pre>
          <p class="card-text">"app-container-poller" call on port 81 and send stuff to /usr/share/nginx/html/index.html. "app-container-server" listens on  port 80. These two containers share the same mount point. Lastly, "ambassador-container" listens on port 81, so that when users curl on 80 they get response from html page</p>

          <p class="card-text"><strong>Adaptor</strong>
          <p class="card-text">Help standarized heterogeneous system</p>
          <p class="card-text">For example, when there are multiple applications running on separate containers that are outputing logs in different formats, the adaptor container can standardize logs</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: adapter-pod
  labels:
    app: adapter-app
spec:
  volumes:
  - name: logs
    emptyDir: {}
  containers:
  - name: app-container
    image: alpine
    command: ["/bin/sh"]
    args: ["-c", "while true; do date >> /var/log/app.log; sleep 2;done"]
    volumeMounts:
    - name: logs
      mountPath: /var/log
  - name: log-adapter
    image: alpine
    command: ["/bin/sh"]
    args: ["-c", "tail -f /var/log/app.log|sed -e 's/^/Date /' > /var/log/out.log"]
    volumeMounts:
    - name: logs
      mountPath: /var/log</code></pre>
          <p class="card-text">"app-container" outputs stream of dates in log file while "log-adapter" appends a word to those stream of dates</p>

          <h3 class="card-title">Disruptions</h3>
          <p class="card-text">There are involuntary disruptions</p>
          <ul>
            <li>Hardware failure</li>
            <li>Kernal panic</li>
            <li>Cloud provider issue</li>
            <li>Network issue</li>
            <li>Pod eviction due to Node having out of resource</li>
          </ul>
          <p class="card-text">There are voluntary disruptions. Application owners can</p>
          <ul>
            <li>Delete the Deployment</li>
            <li>Update the Deployment, causing a restart</li>
            <li>Directly delete Pods by accident</li>
          </ul>
          <p class="card-text">Cluster admins can</p>
          <ul>
            <li>Drain a Node for repair or scale down</li>
            <li>Remove a Pod from a Node to fit in something else</li>
          </ul>
          <p class="card-text">Pod description budgets (PDB)</p>
          <ul>
            <li>Limits the number of Pods down simultaneously from voluntary disruptions</li>
          </ul>
          <p class="card-text">Consider the following scenario where Pod-a, Pod-b, Pod-c are subject to PDB (whose requirement is that at least 2 out of 3 Pods must be available) while Pod-x is not</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-e.png" alt="Card image cap">
          <p class="card-text">Now the cluster admin drains Node 1, which will cause Pod-a and Pod-x to start terminating</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-f.png" alt="Card image cap">
          <p class="card-text">Deployment notices that Pods are terminating, and to reinstate the desired state, it creates replacement Pods (Pod-d and Pod-y)</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-g.png" alt="Card image cap">
          <p class="card-text">The cluster admin now attempts to drain Node 2 and Node 3. However, the drain command will block because of PDB</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-h.png" alt="Card image cap">
          <p class="card-text">At this point, there are three availabe Pods that are subject to PDB</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-i.png" alt="Card image cap">
          <p class="card-text">The cluster admin now attempts to drain Node 2. Either one of Pod-b or Pod-d will be evicted but both cannot be eviced due to PDB. Assuming Pod-b got evicted, the Deployment will create a replacement Pod-e. But since there are not enough resources in Node 2 and 3, the drain will block</p>
          <img class="img-fluid" class="card-img-top" src="img/kubernetes/kubernetes-2-j.png" alt="Card image cap">

          <h3 class="card-title">Application Resource Requirement</h3>
          <p class="card-text"><code>Mib</code> indicates the momory size based on 2's power.</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: memory-demo
  namespace: mem-example
spec:
  containers:
  - name: memory-demo-ctr
    image: polinux/stress
    resources:
      limits:
        memory: "200Mi" # Containers cannot exceed this.
      requests:
        memory: "100Mi" # Containers are gunaranteed to have this much.
    command: ["stress"]
    args: ["--vm", "1", "--vm-bytes", "150M", "--vm-hang", "1"] # Attempt to allocate 150MiB of memory. Containers can exceed the memory requests as long as Node has memory available.</code></pre>
          <p class="card-text">If containers allocate more memory than its limit, they will eventually terminate.</p>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: cpu-demo
  namespace: cpu-example
spec:
  containers:
  - name: cpu-demo-ctr
    image: vish/stress
    resources:
      limits:
        cpu: "1"
      requests:
        cpu: "0.5"
    args:
    - -cpus
    - "2"</code></pre>
          <p class="card-text">If specify limit but no request, K8s automatically assigns CPU request that matches the limit.</p>

          <h4 class="card-title">If no CPU/memory limit</h4>
          <ul>
            <li>Container can use all the CPU/memory in the Node. (until it invokes OOM killer)</li>
            <li>Or, container is running in namespace with a default CPU/memory limit.</li>
          </ul>

          <h3 class="card-title">LivenesProbe and ReadinessProbe</h3>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe: # kubelet executes command "cat /tmp/healthy" in the target container. If 0 is returned, then container is healthy. Otherwise, kubelet kills the container and restarts it.
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5 # kubelet should wait 5 seconds before performing the first probe.
      periodSeconds: 5 # kubelet should perform liveness probe every 5 seconds.</code></pre>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/liveness
    args:
    - /server
    livenessProbe: # kubelet sends HTTP GET request to the server running in the container and listening on port 8080. If status code between 200 and 400 is returned, then container is healthy. Otherwise, kubelet kills the container and restarts it.
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 3 # kubelet should wait 3 seconds before performing the first probe.
      periodSeconds: 3 # kubelet should perform liveness probe every 3 seconds.</code></pre>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: goproxy
  labels:
    app: goproxy
spec:
  containers:
  - name: goproxy
    image: k8s.gcr.io/goproxy:0.1
    ports:
    - containerPort: 8080
    readinessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
    livenessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 15
      periodSeconds: 20</code></pre>

          <h3 class="card-title">Service Account</h3>
          <p class="card-text">When creating Pod, when service account is not specified, it is automatically assigned <code>default</code> service account in the same namespace.</p>

          <p class="card-text">Opt-out of automatic service account assignment.</h3>
<pre><code class="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: build-robot
automountServiceAccountToken: false
...</code></pre>

          <p class="card-text">Opt-out of automatic service account assignment for a specific Pod.</h3>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  serviceAccountName: build-robot
  automountServiceAccountToken: false
  ...</code></pre>

          <p class="card-text">Manually create service account API token.</h3>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
  name: build-robot-secret
  annotations:
    kubernetes.io/service-account.name: build-robot
type: kubernetes.io/service-account-token</code></pre>

          <h3 class="card-title">SecurityContext</h3>
          <p class="card-text">Defines provilege and access control for Pod and Container.</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000 # All processes run with user ID 1000 in containers. (if omitted, defaults to root(0))
    runAsGroup: 3000 # Any file created in containers is owned by user 1000 and group 3000.
    fsGroup: 2000 # All processes of containers are also part of supplementary group 2000.
  volumes:
  - name: sec-ctx-vol
    emptyDir: {}
  containers:
  - name: sec-ctx-demo
    image: busybox
    command: [ "sh", "-c", "sleep 1h" ]
    volumeMounts:
    - name: sec-ctx-vol
      mountPath: /data/demo
    securityContext:
      allowPrivilegeEscalation: false</code></pre>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo-2
spec:
  securityContext:
    runAsUser: 1000
  containers:
  - name: sec-ctx-demo-2
    image: gcr.io/google-samples/node-hello:1.0
    securityContext:
      runAsUser: 2000 # This overrides setting made at Pod level.
      allowPrivilegeEscalation: false</code></pre>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo-4
spec:
  containers:
  - name: sec-ctx-4
    image: gcr.io/google-samples/node-hello:1.0
    securityContext:
      capabilities:
        add: ["NET_ADMIN", "SYS_TIME"] # Linux capabilities.</code></pre>
        </div>
        <div class="card-footer text-muted">
          Reference: <a href="https://kubernetes.io/docs/concepts/workloads/pods/">Pods | <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/">Pod Lifecycle</a> | <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">Labels and Selectors</a> | <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/">Annotations</a> | <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/">Init Containers</a> | <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">Pod Topology Spread Constraints</a> | <a href="https://betterprogramming.pub/understanding-kubernetes-multi-container-pod-patterns-577f74690aee">Understanding Kubernetes Multi-Container Pod Patterns</a> | <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">Disruptions</a> | <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/">Assign Memory Resources to Containers and Pods</a> | <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/">Assign CPU Resources to Containers and Pods</a> | <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">Configure Liveness, Readiness and Startup Probes</a> | <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/">Configure Service Accounts for Pods</a> | <a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">Configure a Security Context for a Pod or Container</a>
        </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Service</h2>
        <p class="card-text">Service is an abstraction for logical set of Pods. The set of Pods targeted by Service is determined by selector.</p>
<pre><code class="yaml"># Suppose there are Pods where each of them listens to port 9376 and has label "app=MyApp".
apiVersion: v1
kind: Service
metadata:
name: my-service
spec:
selector:
app: MyApp
ports:
- protocol: TCP
  port: 80
  targetPort: 9376
# Service named "my-service" targets TCP port 9376 on any Pod with label "app=MyApp".</code></pre>

        <h3 class="card-title">Service without selectors</h3>
        <ul>
          <li>Ex. External database in production, but your own database in test environment.</li>
          <li>Ex. Point Service to another Service in different namespace.</li>
        </ul>
<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
name: my-service
spec:
ports:
  - protocol: TCP
    port: 80
    targetPort: 9376
# Service needs to be manually mapped to network address and port</code></pre>

        <h3 class="card-title">Virtual IPs and service proxies</h3>
        <p class="card-text">Every Node runs <code>kube-proxy</code>, which implementes virtual IP. ConfigMap is used to configure <code>kube-proxy</code>.</p>
        <h4 class="card-title">iptables proxy mode</h4>
        <p class="card-text"><code>kube-proxy</code> watches for Kubernetes control plane for addition and removal of Service and Endpoint objects. It installs iptable rules and redirect traffics to Service's backend sets (for Service) or backend Pod. (for EndPoint) It chooses backend at random.</p>

        <h3 class="card-title">Publishing Service</h3>
        <ul>
          <li><code>ClusterIP</code> is the default <code>ServiceTypes</code>. Expose Service on cluster-internal IP. Service beomes only reachable from within the cluster.</li>
          <li><code>NodePort</code> exposes Service on each Node's IP at a static port. <code>ClusterIP</code> is automatically created.</li>
          <li><code>LoadBalancer</code> exposes Service externally using cloud provider's load balancer. <code>ClusterIP</code> and <code>NodePort</code> are automatically created.</li>
        </ul>
        <h4 class="card-title">NodePort</h4>
<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
name: my-service
spec:
type: NodePort
selector:
  app: MyApp
ports:
    # By default and for convenience, the `targetPort` is set to the same value as the `port` field.
  - port: 80
    targetPort: 80
    # Optional field
    # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)
    nodePort: 30007</code></pre>
        <h4 class="card-title">LoadBalancer</h4>
<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
name: my-service
spec:
selector:
  app: MyApp
ports:
  - protocol: TCP
    port: 80
    targetPort: 9376
clusterIP: 10.0.171.239
type: LoadBalancer
status:
loadBalancer:
  ingress:
  - ip: 192.0.2.127</code></pre>

        <h2 class="card-title">Connecting Applications with Services</h2>
        <p class="card-text">Docker: containers can talk to other containers only if they are on the same machine. Containers must be allowed ports on machine's own IP address. Kubernetes: Pods can talk to other Pods regardless of Nodes. Every Pod gets cluster-private IP address and all Pods in a cluster can see each other.</p>

        <h3 class="card-title">Accessing the Service</h3>
        <p class="card-text">There is a DNS cluster addon Service that automatically assigns DNS names to other Services.</p>
<pre><code class="bash">kubectl get services kube-dns --namespace=kube-system</code></pre>

        <h3 class="card-title">Securing the Service</h3>
  <pre><code class="bash"># Create a public private key pair
  openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /d/tmp/nginx.key -out /d/tmp/nginx.crt -subj "/CN=my-nginx/O=my-nginx"
  # Convert the keys to base64 encoding
  cat /d/tmp/nginx.crt | base64
  cat /d/tmp/nginx.key | base64

  make keys KEY=/tmp/nginx.key CERT=/tmp/nginx.crt
  kubectl create secret tls nginxsecret --key /tmp/nginx.key --cert /tmp/nginx.crt
  kubectl create configmap nginxconfigmap --from-file=default.conf</code></pre>
  <pre><code class="yaml">apiVersion: "v1"
  kind: "Secret"
  metadata:
    name: "nginxsecret"
    namespace: "default"
  type: kubernetes.io/tls
  data:
    tls.crt: &lt;encrypted key output from above&gt;
    tls.key: &lt;encrypted key output from above&gt;</code></pre>
  <pre><code class="yaml">apiVersion: v1
  kind: Service
  metadata:
    name: my-nginx
    labels:
      run: my-nginx
  spec:
    type: NodePort
    ports:
    - port: 8080
      targetPort: 80
      protocol: TCP
      name: http
    - port: 443
      protocol: TCP
      name: https
    selector:
      run: my-nginx
  ---
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: my-nginx
  spec:
    selector:
      matchLabels:
        run: my-nginx
    replicas: 1
    template:
      metadata:
        labels:
          run: my-nginx
      spec:
        volumes:
        - name: secret-volume
          secret:
            secretName: nginxsecret
        - name: configmap-volume
          configMap:
            name: nginxconfigmap
        containers:
        - name: nginxhttps
          image: bprashanth/nginxhttps:1.0
          ports:
          - containerPort: 443
          - containerPort: 80
          volumeMounts:
          - mountPath: /etc/nginx/ssl
            name: secret-volume
          - mountPath: /etc/nginx/conf.d
            name: configmap-volume</code></pre>

      <p class="card-text">Can reach the nginx server from any node.</p>
<pre><code class="bash">kubectl get pods -o yaml | grep -i podip
      podIP: 10.244.3.5
  node $ curl -k https://10.244.3.5
  ...
  &lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</code></pre>

              <p class="card-text">Setup Pod such that</p>
<pre><code class="yaml">apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: curl-deployment
  spec:
    selector:
      matchLabels:
        app: curlpod
    replicas: 1
    template:
      metadata:
        labels:
          app: curlpod
      spec:
        volumes:
        - name: secret-volume
          secret:
            secretName: nginxsecret
        containers:
        - name: curlpod
          command:
          - sh
          - -c
          - while true; do sleep 1; done
          image: radial/busyboxplus:curl
          volumeMounts:
          - mountPath: /etc/nginx/ssl
            name: secret-volume</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a> | <a href="https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/">Connecting Applications with Services</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Network Policies</h2>
        <p class="card-text">Pods are non-isolated by default and accept traffics from any source. Pods become isolated by Network Policy; they reject any connections that are not allowed by any NetworkPolicy.</p>
<pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: test-network-policy
namespace: default
spec:
podSelector: # Empty podSelector selects all pods in the namespace.
  matchLabels:
    role: db # Selects pods with the label "role=db"
policyTypes:
- Ingress
- Egress
ingress:
- from:
  - ipBlock:
      cidr: 172.17.0.0/16
      except:
      - 172.17.1.0/24
  - namespaceSelector:
      matchLabels:
        project: myproject
  - podSelector:
      matchLabels:
        role: frontend
  ports:
  - protocol: TCP
    port: 6379
egress:
- to:
  - ipBlock:
      cidr: 10.0.0.0/24
  ports:
  - protocol: TCP
    port: 5978</code></pre>

        <h3 class="card-title">Default deny all ingress traffic</h3>
<pre><code class="yaml">---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: default-deny-ingress
spec:
podSelector: {}
policyTypes:
- Ingress</code></pre>

        <h3 class="card-title">Default allow all ingress traffic</h3>
<pre><code class="yaml">---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: allow-all-ingress
spec:
podSelector: {}
ingress:
- {}
policyTypes:
- Ingress</code></pre>

        <h3 class="card-title">Default deny all egress traffic</h3>
<pre><code class="yaml">---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: default-deny-egress
spec:
podSelector: {}
policyTypes:
- Egress</code></pre>

        <h3 class="card-title">Default allow all egress traffic</h3>
<pre><code class="yaml">---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: allow-all-egress
spec:
podSelector: {}
egress:
- {}
policyTypes:
- Egress</code></pre>

        <h3 class="card-title">Default allow all egress traffic</h3>
<pre><code class="yaml">---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: default-deny-all
spec:
podSelector: {}
policyTypes:
- Ingress
- Egress</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Network Policies</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Volumes</h2>
        <p class="card-text">Docker images are the root of filesystem hierarchy. Volumes mount at specific path within the image.</p>
        <p class="card-text">ConfigMap allows injecting configration data into Pods. <code>log-config</code> ConfigMap is mounted as a volume at path <code>/etc/config/log_level</code> with Pod called <code>configmap-pod</code></p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: configmap-pod
spec:
containers:
  - name: test
    image: busybox
    volumeMounts:
      - name: config-vol
        mountPath: /etc/config
volumes:
  - name: config-vol
    configMap:
      name: log-config
      items:
        - key: log_level
          path: log_level</code></pre>
        <p class="card-text"><code>emptyDir</code> is created when Pod is assigned to Node. When Pod is removed from Node, data is deleted permanently</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: test-pd
spec:
containers:
- image: k8s.gcr.io/test-webserver
  name: test-container
  volumeMounts:
  - mountPath: /cache
    name: cache-volume
volumes:
- name: cache-volume
  emptyDir: {}</code></pre>

        <h3 class="card-title">Dynamic Volume Provisioning</h3>
        <p class="card-text">To enable dynamic provisioning, cluster admin must pre-create StorageClass object for users.</p>
<pre><code class="yaml"> # Create storage class "slow" that provisions persistent disks like standard disk.
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
name: slow
provisioner: kubernetes.io/gce-pd
parameters:
type: pd-standard</code></pre>
<pre><code class="yaml"> # Create storage class "fast" that provisions persistent disks like SSD.
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
name: fast
provisioner: kubernetes.io/gce-pd
parameters:
type: pd-ssd</code></pre>
        <p class="card-text">Users request dynamically provisioned storage by including a storage class in their <code>PersistentVolumeClaim</code>. When this claim is deleted, the volume gets destroyed.</p>
<pre><code class="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: claim1
spec:
accessModes:
  - ReadWriteOnce
storageClassName: fast
resources:
  requests:
    storage: 30Gi</code></pre>
        <p class="card-text">Cluster admin can make Claims to use dynamic provisioning by default. This is done by marking a specific StorageClass as default by adding <code>storageclass.kubernetes.io/is-default-class</code> annotation to it.</p>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/storage/volumes/">Volumes</a> | <a href="https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/">Dynamic Volume Provisioning</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Persistent Volumes</h2>
        <p class="card-text">PersistentVolume (PV) is a piece of storage in a cluster. It is similar to Node. PersistentVolumeClaim (PVC) a request for storage by a user. It is similar to Pod. PVC comsume PV resources. While Pod can request CPU and memory, PVC can request specific size and access mode.</p>
        <h3 class="card-title">Binding</h3>
        <p class="card-text">If PV was dynamically provisioned for a PVC, those PV and PVC will bind together. Otherwise, users will get at least what they asked for but volumes maybe at the excess.</p>
        <h3 class="card-title">Storage Object in Use Protection</h3>
        <p class="card-text">If user deletes PVC, deletion is postponed until PVC is not in use by any Pods. If admin deletes PV, deletion is postponed until PV is not bound to PVC.</p>
        <h3 class="card-title">Reserving PV</h3>
<pre><code class="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
name: foo-pv
spec:
storageClassName: ""
claimRef:
  name: foo-pvc
  namespace: foo
...</code></pre>
        <h3 class="card-title">PV</h3>
<pre><code class="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
name: pv0003
spec:
capacity:
  storage: 5Gi
volumeMode: Filesystem # Filesystem - default, Block - raw block device
accessModes:
  - ReadWriteOnce # ReadWriteOnce, ReadWriteMany, ReadOnlyMany. Once - mounted by single Node, Many - mounted by many Nodes
persistentVolumeReclaimPolicy: Recycle # Retain, Recycle, Delete
storageClassName: slow
mountOptions:
  - hard
  - nfsvers=4.1
nfs:
  path: /tmp
  server: 172.17.0.2</code></pre>
        <h3 class="card-title">PVC</h3>
<pre><code class="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: myclaim
spec:
accessModes:
  - ReadWriteOnce
volumeMode: Filesystem
resources:
  requests:
    storage: 8Gi
storageClassName: slow
selector:
  matchLabels: # volumn must have a label with this value
    release: "stable"
  matchExpressions: # a list of requirements
    - {key: environment, operator: In, values: [dev]}</code></pre>
        <h3 class="card-title">Claims as Volumns</h3>
        <p class="card-text">Pods access storage by using Claim as volume. Claim must exist in the same namespace as Pod. The cluster finds Claim in Pods's namespace and uses it to get PV.</p>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: mypod
spec:
containers:
  - name: myfrontend
    image: nginx
    volumeMounts:
    - mountPath: "/var/www/html"
      name: mypd
volumes:
  - name: mypd
    persistentVolumeClaim:
      claimName: myclaim</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Volume Snapshots</h2>
        <p class="card-text"><code>VolumeSnapshotContent</code> - snapshot taken from a volumn. <code>VolumeSnapshot</code> - request for a snapshot by a user. <code>VolumeSnapshot</code> is only available for CSI (Container Storage Interface) drivers. </p>
        <h3 class="card-title">VS</h3>
<pre><code class="yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
name: new-snapshot-test
spec:
volumeSnapshotClassName: csi-hostpath-snapclass
source:
  persistentVolumeClaimName: pvc-test # name of PVC data source for the snapshot</code></pre>
        <h3 class="card-title">VSC</h3>
<pre><code class="yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotContent
metadata:
name: snapcontent-72d9a349-aacd-42d2-a240-d775650d2455
spec:
deletionPolicy: Delete
driver: hostpath.csi.k8s.io
source:
  volumeHandle: ee0cfb94-f8d4-11e9-b2d8-0242ac110002 # unique identifier creatd on the storage (returned by CSI driver druing volume creation)
volumeSnapshotClassName: csi-hostpath-snapclass
volumeSnapshotRef:
  name: new-snapshot-test
  namespace: default
  uid: 72d9a349-aacd-42d2-a240-d775650d2455</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/storage/volume-snapshots/">Volume Snapshots</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">ConfigMap</h2>
        <p class="card-text">Provides configuration data, which is separate from application code. Data stored in configMap cannot exceed 1MB.</p>
        <h3 class="card-title">ConfigMap and Pod</h3>
        <p class="card-text">ConfigMap and Pod must be in the same namespace. There are four ways to use ConfigMap.</p>
        <ul>
          <li>Container commands (and args)</li>
          <li>Environment variables</li>
          <li>Add a file in read-only volume</li>
          <li>Code inside Pod that uses K8s API to read ConfigMap</li>
        </ul>
<pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
name: game-demo
data:
# property-like keys; each key maps to a simple value
player_initial_lives: "3"
ui_properties_file_name: "user-interface.properties"

# file-like keys
game.properties: |
  enemy.types=aliens,monsters
  player.maximum-lives=5
user-interface.properties: |
  color.good=purple
  color.bad=yellow
  allow.textmode=true</code></pre>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: configmap-demo-pod
spec:
containers:
  - name: demo
    image: alpine
    command: ["sleep", "3600"]
    env:
      # Define the environment variable
      - name: PLAYER_INITIAL_LIVES # Notice that the case is different here
                                   # from the key name in the ConfigMap.
        valueFrom:
          configMapKeyRef:
            name: game-demo           # The ConfigMap this value comes from.
            key: player_initial_lives # The key to fetch.
      - name: UI_PROPERTIES_FILE_NAME
        valueFrom:
          configMapKeyRef:
            name: game-demo
            key: ui_properties_file_name
    volumeMounts:
    - name: config
      mountPath: "/config"
      readOnly: true
volumes:
  # You set volumes at the Pod level, then mount them into containers inside that Pod
  - name: config
    configMap:
      # Provide the name of the ConfigMap you want to mount.
      name: game-demo
      # An array of keys from the ConfigMap to create as files
      items:
      - key: "game.properties"
        path: "game.properties"
      - key: "user-interface.properties"
        path: "user-interface.properties"</code></pre>

      <h3 class="card-title">Using ConfigMap as file</h3>
      <ul>
        <li>Create a ConfigMap.</li>
        <li>Update Pod to add a volume under <code>.spec.volumes[]</code> whose name can be anything. Make this field <code>spec.volumes[].configMap.name</code> reference ConfigMap object.</li>
        <li>Add <code>.spec.containers[].volumeMounts[]</code> to each container that needs configMap. Set <code>.spec.containers[].volumeMounts[].readOnly = true</code>. Specify <code>.spec.containers[].volumeMounts[].mountPath</code> to your ConfigMap location.</li>
        <li>Look for ConfigMap from the image. Each key in ConfigMap <code>data</code> becomes filename under <code>mountPath</code>.</li>
      </ul>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: mypod
spec:
containers:
- name: mypod
  image: redis
  volumeMounts:
  - name: foo
    mountPath: "/etc/foo"
    readOnly: true
volumes:
- name: foo
  configMap:
    name: myconfigmap</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">ConfigMap</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Secret</h2>
        <p class="card-text">Similar to ConfigMap but specifically for confidential data. Secret can be used in three ways.</p>
        <ul>
          <li>File in a volumn mounted on containers</li>
          <li>Container envinronment variable</li>
          <li>By Kubelet when pulling images for Pod</li>
        </ul>
        <h3 class="card-title">Secret types</h3>
        <table>
          <tr>
            <td>Opaque</td>
            <td>arbitrary user-defined data (default Secret type if omitted)</td>
          </tr>
          <tr>
            <td>kubernetes.io/service-account-token</td>
            <td>service account token</td>
          </tr>
          <tr>
            <td>kubernetes.io/dockercfg</td>
            <td>~/.dockercfg file</td>
          </tr>
          <tr>
            <td>kubernetes.io/dockerconfigjson</td>
            <td>~/.docker/config.json file</td>
          </tr>
          <tr>
            <td>kubernetes.io/basic-auth</td>
            <td>credentials for basic authentication</td>
          </tr>
          <tr>
            <td>kubernetes.io/ssh-auth</td>
            <td>credentials for SSH authentication</td>
          </tr>
          <tr>
            <td>kubernetes.io/tls</td>
            <td>data for a TLS client or server</td>
          </tr>
        </table>

        <h3 class="card-title">Opaque Secret</h3>
<pre><code class="bash">kubectl create secret generic empty-secret
kubectl get secret empty-secret</code></pre>
        <h3 class="card-title">Service account token Secret</h3>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
name: secret-sa-sample
annotations:
  kubernetes.io/service-account.name: "sa-name" # Existing service account name
type: kubernetes.io/service-account-token
data:
# You can include additional key value pairs as you do with Opaque Secrets
extra: YmFyCg==</code></pre>

        <h3 class="card-title">Docker config Secret</h3>
        <p class="card-text">~/.dockercfg is legacy, ~/.docker/config.json is the new format.</p>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
name: secret-dockercfg
type: kubernetes.io/dockercfg
data:
.dockercfg: | # This would be ".dockerconfigjson" for ~/.docker/config.json
      "&lt;base64 encoded ~/.dockercfg file&gt;" # Or &lt;base64 encoded ~/.docker/config.json&gt;</code></pre>

        <h3 class="card-title">Basic authentication Secret</h3>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
name: secret-basic-auth
type: kubernetes.io/basic-auth
stringData:
username: admin
password: t0p-Secret</code></pre>

        <h3 class="card-title">SSH authentication Secret</h3>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
name: secret-ssh-auth
type: kubernetes.io/ssh-auth
data:
# the data is abbreviated in this example
ssh-privatekey: |
        MIIEpQIBAAKCAQEAulqb/Y ...</code></pre>

        <h3 class="card-title">TLS secrets</h3>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
name: secret-tls
type: kubernetes.io/tls
data:
# the data is abbreviated in this example
tls.crt: |
      MIIC2DCCAcCgAwIBAgIBATANBgkqh ...
tls.key: |
      MIIEpgIBAAKCAQEA7yn3bRHQ5FHMQ ...</code></pre>

        <h3 class="card-title">Editing Secret</h3>
<pre><code class="bash">kubectl edit secrets mysecret</code></pre>

        <h3 class="card-title">Using Secret as File</h3>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: mypod
spec:
containers:
- name: mypod
  image: redis
  volumeMounts: # Add this to each container that needs Secret.
  - name: foo
    mountPath: "/etc/foo" # Should be an unused directory where you want Secret to appear.
    readOnly: true
volumes:
- name: foo
  secret:
    secretName: mysecret # Name of Secret object.
    defaultMode: 0400 # Default is 0644 if not specified. All files created by Secret volumn mount will have 0400.
    items:
    - key: username
      path: my-group/my-username # "username" Secret is stored in "/etc/foo/my-group/my-username" instead of "/etc/foo/username".
      mode: 0777 # Files in /etc/foo/my-group/my-username will have 0777.</code></pre>

        <h3 class="card-title">Using Secret as environment variables</h3>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: secret-env-pod
spec:
containers:
- name: mycontainer
  image: redis
  env:
    - name: SECRET_USERNAME
      valueFrom:
        secretKeyRef:
          name: mysecret
          key: username
    - name: SECRET_PASSWORD
      valueFrom:
        secretKeyRef:
          name: mysecret
          key: password
restartPolicy: Never</code></pre>
        <p class="card-text">Updating Secret will not update environment variables in the containers unless containers are restarted.</p>

        <h3 class="card-title">Immutable Secret</h3>
        <p class="card-text">Prevents accidental deletion/update of Secret.</p>
<pre><code class="yaml">apiVersion: v1
kind: Secret
metadata:
...
data:
...
immutable: true</code></pre>

        <h3 class="card-title">Risk</h3>
        <ul>
          <li>Secret data is stored etcd of API server. Admin should enable encryption-at-rest for cluster data and limit access to etcd.</li>
          <li>Secret written as base64 in manifest files must not be shared or checked-in. (Base64 encoding is not an encryption method and is the same as plain text)</li>
          <li>Users who can create Pod using the Secret can also see the Secret.</li>
        </ul>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Secret</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Kubernetes Objects and API</h2>
        <p class="card-text">Persistent entities that represent the cluster desired state. Each object has <code>spec</code> and <code>status</code></p>
        <p class="card-text">Namespaces - virtual clusters supported by the same physical cluster.6. Archive</p>

        <h3 class="card-title">Standard API terminology</h3>
        <p class="card-text">Most K8s resource types are objects, which have unique name to allow idempotent creation (virtual types may not have unique name, for example "permission check")</p>
        <ul>
          <li>Resource type - name used in the URLs (pods, namespaces, services)</li>
          <li>Kind - JSON representation of resource types</li>
          <li>Collection - list of instances of a resource type</li>
          <li>Resource - single instance of the resource type</li>
        </ul>
        <p class="card-text">All resource types are either <strong>cluster-scoped</strong> or <strong>namespace-scoped</strong>. namespace-scoped resource types will be deleted when the namespace is deleted</p>
        <p class="card-text">cluster-scoped</p>
        <ul>
          <li>GET /apis/GROUP/VERSION/RESOURCETYPE</li>
          <li>GET /apis/GROUP/VERSION/RESOURCETYPE/NAME</li>
        </ul>
        <p class="card-text">namespace-scoped</p>
        <ul>
          <li>GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE</li>
          <li>GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME</li>
          <li>GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME</li>
        </ul>
        <p class="card-text">A namespace is a cluster-scoped resource type. Retrive all namespaces with "GET /api/v1/namespaces" and particular namespace with "GET /api/v1/namespaces/NAME"</p>
        <p class="card-text">K8s uses "list" to return a collection of resource and "get" to return a single resource</p>
        <p class="card-text">Some resources have sub-resource(s)</p>
        <ul>
          <li>GET /apis/GROUP/VERSION/RESOURCETYPE/NAME/SUBRESOURCE</li>
          <li>GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME/SUBRESOURCE</li>
        </ul>

        <h3 class="card-title">Efficient detection of changes</h3>
        <p class="card-text"><strong>watch</strong> - detects incremental changes in cluster state. Use "resourceVersion" to store the state of resources</p>
        <ul>
          <li>GET /api/v1/namespaces/test/pods - list all pods in given namespace</li>
          <li>GET /api/v1/namespaces/test/pods?watch=1&resourceVersion=10245 - starting resource version 10245, receive notifications for create/delete/update as JSON</li>
        </ul>
        <p class="card-text">K8s server can only store history for a limted time. Clusters using etcd3 preserve changes for the last 5 mins by default. Clients are expected to handle http status code "410 Gone"</p>
        <p class="card-text"><strong>bookmarks</strong> - marks that all changes up to given "resourceVersion" has already been sent. (in an attempt to mitigate the short history window problem)</p>
        <ul>
          <li>GET /api/v1/namespaces/test/pods?watch=1&resourceVersion=10245&allowWatchBookmarks=true</li>
        </ul>

        <h3 class="card-title">Retrieving large results sets in chunks</h3>
        <p class="card-text">Break single large collection requests into small chunks by parameters "limit" and "continue"</p>
        <ul>
          <li>GET /api/v1/pods?limit=500 - retrive all pods in cluster, up to 500</li>
          <li>GET /api/v1/pods?limit=500&continue=ENCODED_CONTINUE_TOKEN - continue from the previous call to get 501-1000 pods</li>
          <li>GET /api/v1/pods?limit=500&continue=ENCODED_CONTINUE_TOKEN_2 - continue from the previous call to get last set of pods</li>
        </ul>

        <h3 class="card-title">Receiving resources as Tables</h3>
        <ul>
          <li>GET /api/v1/pods<br>
              Accept: application/json;as=Table;g=meta.k8s.io;v=v1beta1<br>
              - retrive all pods in cluster in table format</li>
        </ul>
        <p class="card-text">Because there are resource types that don't support Table response, client should handle both Table/non-Table case by using content-type</p>
        <ul>
          <li>Accept: application/json;as=Table;g=meta.k8s.io;v=v1beta1, application/json</li>
        </ul>

        <h3 class="card-title">Receiving resources as Protobuf</h3>
        <p class="card-text">This is for better performance at scale</p>
        <ul>
          <li>GET /api/v1/pods
              Accept: application/vnd.kubernetes.protobuf<br>
              - retrive all pods in cluster in Protobuf format</li>
          <li>POST /api/v1/namespaces/test/pods
              Content-Type: application/vnd.kubernetes.protobuf
              Accept: application/json
              - create a pod with Protobuf encoded data, but receive response in JSON</li>
        </ul>
        <p class="card-text">Similar to Table response, multiple content-types are needed in the "Accept" header to support resource types that don't have Protobuf support</p>
        <ul>
          <li>Accept: application/vnd.kubernetes.protobuf, application/json</li>
        </ul>

        <h3 class="card-title">Resource deletion</h3>
        <p class="card-text">Takes place in two phases 1. finalization 2. removal. Finalizers are removed in any order. Once the last finalizer is removed, the resource is removed from etcd.</p>

        <h3 class="card-title">Dry-run</h3>
        <p class="card-text">dry-run executes the request up until persisting objects in storage. The reponse body should be as close as possible to the actual run. Authorization of dry and non-dry runs are identical</p>
        <ul>
          <li>POST /api/v1/namespaces/test/pods?dryRun=All<br>
              Content-Type: application/json<br>
              Accept: application/json<br>
              - ALL: every stage runs normal except the final stage of persisting objects in storage</li>
        </ul>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/">Understanding Kubernetes Objects</a> | <a href="https://kubernetes.io/docs/reference/using-api/api-concepts/">Kubernetes API Concepts</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">RBAC</h2>
        <p class="card-text">To enable RBAC, start the API server with such that</p>
<pre><code class="bash">kube-apiserver --authorization-mode=Example,RBAC --other-options --more-options</code></pre>
        <p class="card-text">RBAC API declares four objects: Role, ClusterRole, RoleBinding, CLusterRoleBinding</p>

        <h3 class="card-title">Role</h3>
        <p class="card-text">Role sets permission with a particular namespace.</p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
namespace: default
name: pod-reader
rules:
- apiGroups: [""] # "" indicates the core API group
resources: ["pods"]
verbs: ["get", "watch", "list"]</code></pre>

        <h3 class="card-title">ClusterRole</h3>
        <p class="card-text">ClusterRole is a cluster-wide, non-namespaced resource.</p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
# "namespace" omitted since ClusterRoles are not namespaced
name: secret-reader
rules:
- apiGroups: [""]
#
# at the HTTP level, the name of the resource for accessing Secret
# objects is "secrets"
resources: ["secrets"]
verbs: ["get", "watch", "list"]</code></pre>

        <h3 class="card-title">RoleBidning</h3>
        <p class="card-text">RoleBinding grants permissions defined in a Role to users.</p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
# This role binding allows "dave" to read secrets in the "development" namespace.
# You need to already have a ClusterRole named "secret-reader".
kind: RoleBinding
metadata:
name: read-secrets
#
# The namespace of the RoleBinding determines where the permissions are granted.
# This only grants permissions within the "development" namespace.
namespace: development
subjects:
- kind: User
name: dave # Name is case sensitive
apiGroup: rbac.authorization.k8s.io
roleRef:
kind: ClusterRole
name: secret-reader
apiGroup: rbac.authorization.k8s.io</code></pre>

        <h3 class="card-title">ClusterRoleBinding</h3>
        <p class="card-text">ClusterRoleBinding grants permission across the whole cluster.</p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
# This cluster role binding allows anyone in the "manager" group to read secrets in any namespace.
kind: ClusterRoleBinding
metadata:
name: read-secrets-global
subjects:
- kind: Group
name: manager # Name is case sensitive
apiGroup: rbac.authorization.k8s.io
roleRef:
kind: ClusterRole
name: secret-reader
apiGroup: rbac.authorization.k8s.io</code></pre>

        <h3 class="card-title">Aggregated ClusterRole</h3>
        <p class="card-text">Aggregate serveral ClusterRoles into one ClusterRole.</p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
name: aggregate-cron-tabs-edit
labels:
  # Add these permissions to the "admin" and "edit" default roles.
  rbac.authorization.k8s.io/aggregate-to-admin: "true"
  rbac.authorization.k8s.io/aggregate-to-edit: "true"
rules:
- apiGroups: ["stable.example.com"]
resources: ["crontabs"]
verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: aggregate-cron-tabs-view
labels:
  # Add these permissions to the "view" default role.
  rbac.authorization.k8s.io/aggregate-to-view: "true"
rules:
- apiGroups: ["stable.example.com"]
resources: ["crontabs"]
verbs: ["get", "list", "watch"]</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">Using RBAC Authorization</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Container logging</h2>
        <h3 class="card-title">Pod with two sidecar containers</h3>
<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: counter
spec:
containers:
- name: count
  image: busybox
  args:
  - /bin/sh
  - -c
  - >
    i=0;
    while true;
    do
      echo "$i: $(date)" >> /var/log/1.log;
      echo "$(date) INFO $i" >> /var/log/2.log;
      i=$((i+1));
      sleep 1;
    done
  volumeMounts:
  - name: varlog
    mountPath: /var/log
- name: count-log-1
  image: busybox
  args: [/bin/sh, -c, 'tail -n+1 -f /var/log/1.log']
  volumeMounts:
  - name: varlog
    mountPath: /var/log
- name: count-log-2
  image: busybox
  args: [/bin/sh, -c, 'tail -n+1 -f /var/log/2.log']
  volumeMounts:
  - name: varlog
    mountPath: /var/log
volumes:
- name: varlog
  emptyDir: {}</code></pre>
        <p class="card-text">Access two separate log streams.</h3>
<pre><code class="bash">kubectl logs counter count-log-1
kubectl logs counter count-log-2</code></pre>

        <h3 class="card-title">Sidecar container with logging agent</h3>
<pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
name: fluentd-config
data:
fluentd.conf: |
  &lt;source&gt;
    type tail
    format none
    path /var/log/1.log
    pos_file /var/log/1.log.pos
    tag count.format1
  &lt;/source&gt;

  &lt;source&gt;
    type tail
    format none
    path /var/log/2.log
    pos_file /var/log/2.log.pos
    tag count.format2
  &lt;/source&gt;

  &lt;match **&gt;
    type google_cloud
  &lt;/match&gt;</code></pre>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
name: counter
spec:
containers:
- name: count
  image: busybox
  args:
  - /bin/sh
  - -c
  - >
    i=0;
    while true;
    do
      echo "$i: $(date)" >> /var/log/1.log;
      echo "$(date) INFO $i" >> /var/log/2.log;
      i=$((i+1));
      sleep 1;
    done
  volumeMounts:
  - name: varlog
    mountPath: /var/log
- name: count-agent
  image: k8s.gcr.io/fluentd-gcp:1.30
  env:
  - name: FLUENTD_ARGS
    value: -c /etc/fluentd-config/fluentd.conf
  volumeMounts:
  - name: varlog
    mountPath: /var/log
  - name: config-volume
    mountPath: /etc/fluentd-config
volumes:
- name: varlog
  emptyDir: {}
- name: config-volume
  configMap:
    name: fluentd-config</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">Logging Architecture</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Monitoring</h2>
        <h3 class="card-title">Enable Node Problem Detector</h3>

<pre><code class="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
name: node-problem-detector-v0.1
namespace: kube-system
labels:
  k8s-app: node-problem-detector
  version: v0.1
  kubernetes.io/cluster-service: "true"
spec:
selector:
  matchLabels:
    k8s-app: node-problem-detector
    version: v0.1
    kubernetes.io/cluster-service: "true"
template:
  metadata:
    labels:
      k8s-app: node-problem-detector
      version: v0.1
      kubernetes.io/cluster-service: "true"
  spec:
    hostNetwork: true
    containers:
    - name: node-problem-detector
      image: k8s.gcr.io/node-problem-detector:v0.1
      securityContext:
        privileged: true
      resources:
        limits:
          cpu: "200m"
          memory: "100Mi"
        requests:
          cpu: "20m"
          memory: "20Mi"
      volumeMounts:
      - name: log
        mountPath: /log
        readOnly: true
      - name: config # Overwrite the config/ directory with ConfigMap volume
        mountPath: /config
        readOnly: true
    volumes:
    - name: log
      hostPath:
        path: /var/log/
    - name: config # Define ConfigMap volume
      configMap:
        name: node-problem-detector-config</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/">Monitor Node Health</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Application inspection and debugging</h2>
<pre><code class="bash">kubectl get pods
kubectl get pod &lt;POD-NAME&gt; -o yaml
kubectl describe pod &lt;POD-NAME&gt;
kubectl get events
kubectl get events --namespace=&lt;MY-NAMESPACE&gt;
kubectl get nodes
kubectl describe node &lt;NODE-NAME&gt;
kubectl get node &lt;NODE-NAME&gt; -o yaml</code></pre>

        <h3 class="card-title">List all the pods which belong to a StatefulSet, which have a label app=myapp.</h3>
<pre><code class="bash">kubectl get pods -l app=myapp</code></pre>

        <h3 class="card-title">Debug init container.</h3>
<pre><code class="bash">kubectl get pod nginx --template '{{.status.initContainerStatuses}}'
kubectl logs &lt;POD-NAME&gt; -c &lt;INIT-CONTAINER-NAME&gt;</code></pre>

        <h3 class="card-title">Check node capacity.</h3>
<pre><code class="bash">kubectl get nodes -o yaml | egrep '\sname:|cpu:|memory:'
kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, cap: .status.capacity}'</code></pre>

        <h3 class="card-title">Examine pod log.</h3>
<pre><code class="bash">kubectl logs &lt;POD-NAME&gt; &lt;CONTAINER-NAME&gt;
# If container has previously crashed.
kubectl logs --previous &lt;POD-NAME&gt; &lt;CONTAINER-NAME&gt;</code></pre>

        <h3 class="card-title">Debug running Pod.</h3>
<pre><code class="bash">kubectl exec &lt;POD-NAME&gt; -- cat /path/to/log/your_log.log
kubectl exec -it &lt;POD-NAME&gt; -- sh</code></pre>

        <h3 class="card-title">Debug using ephemeral container.</h3>
<pre><code class="bash">kubectl run &lt;POD-NAME&gt; --image=&lt;IMAGE-NAME-TO-PULL-FOR-THIS-POD&gt; --restart=Never
# Add debug container.
kubectl debug -it &lt;POD-NAME&gt; --image=&lt;IMAGE-NAME&gt; --target=&lt;POD-NAME&gt;</code></pre>

        <h3 class="card-title">Debug using copy of Pod.</h3>
<pre><code class="bash">kubectl run &lt;POD-NAME&gt; --image=&lt;IMAGE-NAME&gt; --restart=Never -- sleep 1d
kubectl debug &lt;POD-NAME&gt; -it --image=&lt;NEW-CONTAINER-NAME-FOR-DEBUGGING&gt; --share-processes --copy-to=&lt;POD-NAME&gt;-debug</code></pre>

        <h3 class="card-title">Copying Pod while changing its command.</h3>
<pre><code class="bash">kubectl run --image=&lt;IMAGE-NAME&gt; &lt;POD-NAME&gt; -- false
kubectl debug &lt;POD-NAME&gt; -it --copy-to=&lt;POD-NAME&gt; -debug --container=&lt;POD-NAME&gt;-- sh</code></pre>

        <h3 class="card-title">Copying Pod while changing container image.</h3>
<pre><code class="bash">kubectl run &lt;POD-NAME&gt; --image=&lt;IMAGE-NAME&gt; --restart=Never -- sleep 1d
kubectl debug &lt;POD-NAME&gt; --copy-to=&lt;POD-NAME&gt;-debug --set-image=*=&lt;IMAGE-NAME&gt;</code></pre>

        <h3 class="card-title">Debug via shell on Node.</h3>
<pre><code class="bash">kubectl debug node/mynode -it --image=&lt;IMAGE-NAME&gt;</code></pre>

        <h3 class="card-title">Debug Deployment</h3>
<pre><code class="bash"># Create Deployment.
kubectl create deployment &lt;DEPLOYMENT-NAME&gt;
# Scale Deployment to 3 replicas.
kubectl scale deployment &lt;DEPLOYMENT-NAME&gt; --replicas=3
# Confirm Pods are running.
kubectl get pods -l &lt;DEPLOYMENT-NAME&gt;
# Get list of Pod IP addresses.
kubectl get pods -l &lt;DEPLOYMENT-NAME&gt; -o go-template='{{range .items}}{{.status.podIP}}{{"\n"}}{{end}}'</code></pre>

        <h3 class="card-title">Debug Service</h3>
<pre><code class="bash"># From Pod within the same namespace.
nslookup &lt;SERVICE-NAME&gt;
nslookup &lt;SERVICE-NAME&gt;.default
nslookup &lt;SERVICE-NAME&gt;.default.svc.cluster.local
# Within the Pod, check.
cat /etc/resolv.conf
nslookup kubernetes.default
# Within the Node.
nslookup &lt;SERVICE-NAME&gt;.default.svc.cluster.local &lt;CLUSTER-DNS-SERVICE-IP&gt;
# Check if Service is defined correctly.
kubectl get service &lt;SERVICE-NAME&gt; -o json
# Check if Service has endpoint.
kubectl get pods -l app=&lt;SERVICE-NAME&gt;
# Check if kube-proxy is running.
ps auxw | grep kube-proxy</code></pre>

        <h3 class="card-title">Determin reasons for Pod failure</h3>
<pre><code class="bash">kubectl get pod termination-demo -o go-template="{{range .status.containerStatuses}}{{.lastState.terminated.message}}{{end}}"</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/">Application Introspection and Debugging | <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-stateful-set/">Debug a StatefulSet</a> | <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-init-containers/">Debug Init Containers</a> | <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-pod-replication-controller/">Debug Pods and ReplicationControllers</a> | <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-running-pod/">Debug Running Pods</a> | <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/">Debug Services</a> | <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/">Determine the Reason for Pod Failure</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Create cluster with kubeadm</h2>
        <p class="card-text">Control plan is the node where <code>etcd</code> and <code>API server</code> run. Initialize the control plane node,</p>
<pre><code class="bash">kubeadm init &lt;args&gt;</code></pre>
<pre><code class="bash"># To make kubectl work for your non-root user
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
# If you are root user
export KUBECONFIG=/etc/kubernetes/admin.conf</code></pre>

        <h3 class="card-title">Install a Pod network add-on</h3>
<pre><code class="bash">kubectl apply -f &lt;add-on.yaml&gt;
# Confirm it is working by checking if CoreDNS is running.
kubectl get pods --all-namespaces</code></pre>

        <h3 class="card-title">Join a Node</h3>
<pre><code class="bash"># Get token.
kubeadm token list

# Get --discovery-token-ca-cert-hash.
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | \
openssl dgst -sha256 -hex | sed 's/^.* //'

kubeadm join --token &lt;token&gt; &lt;control-plane-host&gt;:&lt;control-plane-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;</code></pre>

        <h3 class="card-title">Remove a Node</h3>
<pre><code class="bash">kubectl drain &lt;node name&gt; --delete-emptydir-data --force --ignore-daemonsets
# Reset the state installed by kubeadm.
kubeadm reset
# Reset iptables.
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X
# Reset IPVS tables.
ipvsadm -C
kubectl delete node &lt;node name&gt;</code></pre>
        </div>
        <div class="card-footer text-muted">
          Reference: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">Creating a cluster with kubeadm</a>
        </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Create HA cluster with kubeadm</h2>

        <h3 class="card-title">Create a load balancer for kube-apiserver</h3>
        <p class="card-text">Place control plane nodes behind a TCP forwarding load balancer. Address of load balancer must match the address of kubeadm's <code>ControlPlaneEndpoint</code>. Then add control planes to the load balancer and test.</p>
<pre><code class="bash"># Connection refused error is expected since apiserver is not running yet. However, timeout means a real problem.
nc -v LOAD_BALANCER_IP PORT</code></pre>

        <h3 class="card-title">Option #1. Stacked control plane and etcd nodes</h3>
<pre><code class="bash"># 1. Initialize the control plane.
sudo kubeadm init --control-plane-endpoint "LOAD_BALANCER_DNS:LOAD_BALANCER_PORT" --upload-certs

# 2. Apply a CIN plugin. (For example, Weave Net)
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"

# 3. Verify control plane.
kubectl get pod -n kube-system -w

# 4. Join Nodes (Use outputs from step #1)</code></pre>

        <h3 class="card-title">Option #2. External etcd nodes</h3>
<pre><code class="bash"># 1. Setup etcd cluster.
# 1.1. Do this on every host where etcd should be running.
cat << EOF > /etc/systemd/system/kubelet.service.d/20-etcd-service-manager.conf
[Service]
ExecStart=
#  Replace "systemd" with the cgroup driver of your container runtime. The default value in the kubelet is "cgroupfs".
ExecStart=/usr/bin/kubelet --address=127.0.0.1 --pod-manifest-path=/etc/kubernetes/manifests --cgroup-driver=systemd
Restart=always
EOF

systemctl daemon-reload
systemctl restart kubelet

# 1.2. Ensure kubectl is running.
systemctl status kubelet

# 1.3. Create configuration file for kubeadm.
# Update HOST0, HOST1, and HOST2 with the IPs or resolvable names of your hosts.
export HOST0=10.0.0.6
export HOST1=10.0.0.7
export HOST2=10.0.0.8

# Create temp directories to store files that will end up on other hosts.
mkdir -p /tmp/${HOST0}/ /tmp/${HOST1}/ /tmp/${HOST2}/

ETCDHOSTS=(${HOST0} ${HOST1} ${HOST2})
NAMES=("infra0" "infra1" "infra2")

for i in "${!ETCDHOSTS[@]}"; do
HOST=${ETCDHOSTS[$i]}
NAME=${NAMES[$i]}
cat << EOF > /tmp/${HOST}/kubeadmcfg.yaml
apiVersion: "kubeadm.k8s.io/v1beta3"
kind: ClusterConfiguration
etcd:
  local:
      serverCertSANs:
      - "${HOST}"
      peerCertSANs:
      - "${HOST}"
      extraArgs:
          initial-cluster: ${NAMES[0]}=https://${ETCDHOSTS[0]}:2380,${NAMES[1]}=https://${ETCDHOSTS[1]}:2380,${NAMES[2]}=https://${ETCDHOSTS[2]}:2380
          initial-cluster-state: new
          name: ${NAME}
          listen-peer-urls: https://${HOST}:2380
          listen-client-urls: https://${HOST}:2379
          advertise-client-urls: https://${HOST}:2379
          initial-advertise-peer-urls: https://${HOST}:2380
EOF
done

# 1.4. Generate the certificate authority. (This will create two files /etc/kubernetes/pki/etcd/ca.crt and /etc/kubernetes/pki/etcd/ca.key)
kubeadm init phase certs etcd-ca

# 1.5. Create certificates for each member.

kubeadm init phase certs etcd-server --config=/tmp/${HOST2}/kubeadmcfg.yaml
kubeadm init phase certs etcd-peer --config=/tmp/${HOST2}/kubeadmcfg.yaml
kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST2}/kubeadmcfg.yaml
kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST2}/kubeadmcfg.yaml
cp -R /etc/kubernetes/pki /tmp/${HOST2}/
# cleanup non-reusable certificates
find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete

kubeadm init phase certs etcd-server --config=/tmp/${HOST1}/kubeadmcfg.yaml
kubeadm init phase certs etcd-peer --config=/tmp/${HOST1}/kubeadmcfg.yaml
kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST1}/kubeadmcfg.yaml
kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST1}/kubeadmcfg.yaml
cp -R /etc/kubernetes/pki /tmp/${HOST1}/
find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete

kubeadm init phase certs etcd-server --config=/tmp/${HOST0}/kubeadmcfg.yaml
kubeadm init phase certs etcd-peer --config=/tmp/${HOST0}/kubeadmcfg.yaml
kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST0}/kubeadmcfg.yaml
kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST0}/kubeadmcfg.yaml
# No need to move the certs because they are for HOST0

# clean up certs that should not be copied off this host
find /tmp/${HOST2} -name ca.key -type f -delete
find /tmp/${HOST1} -name ca.key -type f -delete

# 1.6. Copy certificates and kubeadm configs.
USER=ubuntu
HOST=${HOST1}
scp -r /tmp/${HOST}/* ${USER}@${HOST}:
ssh ${USER}@${HOST}
USER@HOST $ sudo -Es
root@HOST $ chown -R root:root pki
root@HOST $ mv pki /etc/kubernetes/

# 1.7. Create the static pod manifests.
root@HOST0 $ kubeadm init phase etcd local --config=/tmp/${HOST0}/kubeadmcfg.yaml
root@HOST1 $ kubeadm init phase etcd local --config=/tmp/${HOST1}/kubeadmcfg.yaml
root@HOST2 $ kubeadm init phase etcd local --config=/tmp/${HOST2}/kubeadmcfg.yaml

# 2. Create a file called kubeadm-config.yaml.
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: stable
controlPlaneEndpoint: "LOAD_BALANCER_DNS:LOAD_BALANCER_PORT"
etcd:
  external:
      endpoints:
      - https://ETCD_0_IP:2379
      - https://ETCD_1_IP:2379
      - https://ETCD_2_IP:2379
      caFile: /etc/kubernetes/pki/etcd/ca.crt
      certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
      keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key

# Rest steps are similar to Option #1</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">Creating Highly Available clusters with kubeadm</a> | <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/">Set up a High Availability etcd cluster with kubeadm</a>
      </div>
    </div>

    <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Upgrade kubeadm clusters</h2>

        <h3 class="card-title">Upgrade kubeadm</h3>
<pre><code class="bash"># Ubuntu
# replace x in 1.22.x-00 with the latest patch version
apt-get update && \
apt-get install -y --allow-change-held-packages kubeadm=1.22.x-00

# RHEL
# replace x in 1.22.x-0 with the latest patch version
yum install -y kubeadm-1.22.x-0 --disableexcludes=kubernetes

# Verify.
kubeadm version
kubeadm upgrade plan</code></pre>

        <h3 class="card-title">Drain the Node</h3>
<pre><code class="bash"># replace &lt;node-to-drain&gt; with the name of your node you are draining
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets</code></pre>

        <h3 class="card-title">Upgrade kubelet and kubectl</h3>
<pre><code class="bash"># Ubuntu
# replace x in 1.22.x-00 with the latest patch version
apt-get update && \
apt-get install -y --allow-change-held-packages kubelet=1.22.x-00 kubectl=1.22.x-00

# RHEL
# replace x in 1.22.x-0 with the latest patch version
yum install -y kubelet-1.22.x-0 kubectl-1.22.x-0 --disableexcludes=kubernetes

# Restart the kubelet.
sudo systemctl daemon-reload
sudo systemctl restart kubelet</code></pre>

        <h3 class="card-title">Uncardon the Node</h3>
<pre><code class="bash"># replace &lt;node-to-drain&gt; with the name of your node you are draining
kubectl uncordon &lt;node-to-drain&gt; --ignore-daemonsets</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">Upgrading kubeadm clusters</a>
      </div>
  </div>

  <div class="card mb-4" id="kubernetes-">
      <div class="card-body">
        <h2 class="card-title">Operating etcd clusters.</h2>
        <p class="card-text">etcd is storage for all cluster data. A five member etcd cluster is recommended for production. Access to etcd is equivalent to root permission to the cluster and ideally only API server should have it. </p>
<pre><code class="bash"># To start API server with five member etcd cluster.
etcd --listen-client-urls=http://$IP1:2379,http://$IP2:2379,http://$IP3:2379,http://$IP4:2379,http://$IP5:2379 --advertise-client-urls=http://$IP1:2379,http://$IP2:2379,http://$IP3:2379,http://$IP4:2379,http://$IP5:2379</code></pre>

        <h3 class="card-title">Replace a failed etcd member</h3>
<pre><code class="bash"># Assume three members: member1=http://10.0.0.1, member2=http://10.0.0.2, and member3=http://10.0.0.3. When member1 fails, replace it with member4=http://10.0.0.4.

# Get the member ID of the failed member1.
etcdctl --endpoints=http://10.0.0.2,http://10.0.0.3 member list
# This outputs something like.
8211f1d0f64f3269, started, member1, http://10.0.0.1:2380, http://10.0.0.1:2379
91bc3c398fb3c146, started, member2, http://10.0.0.2:2380, http://10.0.0.2:2379
fd422379fda50e48, started, member3, http://10.0.0.3:2380, http://10.0.0.3:2379

# Remove the failed member.
etcdctl member remove 8211f1d0f64f3269

# Add a new member.
etcdctl member add member4 --peer-urls=http://10.0.0.4:2380

# Start the newly added member
export ETCD_NAME="member4"
export ETCD_INITIAL_CLUSTER="member2=http://10.0.0.2:2380,member3=http://10.0.0.3:2380,member4=http://10.0.0.4:2380"
export ETCD_INITIAL_CLUSTER_STATE=existing
etcd [flags]

# Update t--etcd-servers flag for the Kubernetes API servers.
# Restart the Kubernetes API servers.</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/">Operating etcd clusters for Kubernetes</a>
      </div>
    </div>


    <div class="card mb-4" id="kubernetes-1">
      <div class="card-body">
        <h2 class="card-title">1. Kubectl</h2>
<pre><code class="bash">kubectl config view
kubectl config get-contexts
kubectl config current-context
kubectl config use-context &lt;context_name&gt;

kubectl get ns

kubectl get pods -n &lt;namespace&gt;
kubectl get pods --all-namespaces
kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space:]]' '\n' | sort | uniq -c</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">kubectl Cheat Sheet</a>
      </div>
    </div>


    <!-- <div class="card mb-4" id="kubernetes-4">
        <div class="card-body">
            <h2 class="card-title">4. Setup Kubernetes Master</h2>

<pre><code class="groovy">sudo -i

hostnamectl set-hostname 'k8s-master'
exec bash
setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux

firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=2379-2380/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10251/tcp
firewall-cmd --permanent --add-port=10252/tcp
firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --reload
modprobe br_netfilter
echo '1' > /proc/sys/net/bridge/bridge-nf-call-iptables

cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kube*
EOF

yum install kubeadm docker -y
systemctl restart docker && systemctl enable docker
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl restart kubelet && systemctl enable kubelet
kubeadm init

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

export kubever=$(kubectl version | base64 | tr -d '\n')
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$kubever"

kubectl get nodes
kubectl get pods --all-namespaces</code></pre>

<pre><code class="groovy"># From /etc/hosts
[ip] k8s-master
[ip] k8s-node1
[ip] k8s-node2
[ip] k8s-node3</code></pre>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://www.linuxtechi.com/install-kubernetes-1-7-centos7-rhel7">How to Install Kubernetes (k8s) 1.7 on CentOS 7 / RHEL 7</a>
        </div>
    </div> -->

    <!-- <div class="card mb-4" id="kubernetes-5">
        <div class="card-body">
            <h2 class="card-title">5. Setup Kubernetes Node</h2>
            <p class="card-text">Do this on each node. Replace [k8s-node-name] with appropriate node name</p>

<pre><code class="groovy">sudo -i

hostnamectl set-hostname '[k8s-node-name]'
setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --permanent --add-port=30000-32767/tcp
firewall-cmd --permanent --add-port=6783/tcp
firewall-cmd  --reload
echo '1' > /proc/sys/net/bridge/bridge-nf-call-iptables

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kube*
EOF

yum  install kubeadm docker -y
systemctl restart docker && systemctl enable docker
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl restart kubelet && systemctl enable kubelet
systemctl enable docker.service && systemctl start docker.service</code></pre>

<pre><code class="groovy">kubeadm join --token [k8s-master-token] --discovery-token-unsafe-skip-ca-verification [k8s-master-ip]:6443</code></pre>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://www.linuxtechi.com/install-kubernetes-1-7-centos7-rhel7">How to Install Kubernetes (k8s) 1.7 on CentOS 7 / RHEL 7</a>
        </div>
    </div> -->

    <!-- <div class="card mb-4" id="kubernetes-6">
        <div class="card-body">
            <h2 class="card-title">6. Write Deployment for Jenkins</h2>
            <p class="card-text">"deployment.yaml". Replace [dockerhub_user] with appropriate username</p>

<pre><code class="groovy">apiVersion: extensions/v1beta1
kind: Deployment
metadata:
name: jenkins
spec:
replicas: 1
template:
metadata:
labels:
app: jenkins
spec:
containers:
- name: jenkins
image: [dockerhub_user]/jenkins-master
env:
- name: JAVA_OPTS
value: -Djenkins.install.runSetupWizard=false
ports:
- name: http-port
containerPort: 8080
- name: jnlp-port
containerPort: 50000
volumeMounts:
- name: jenkins-home
mountPath: /var/jenkins_home
volumes:
- name: jenkins-home
emptyDir: {}</code></pre>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://rancher.com/blog/2018/2018-11-27-scaling-jenkins/">Deploying and Scaling Jenkins on Kubernetes</a>
        </div>
    </div>

    <div class="card mb-4" id="kubernetes-7">
        <div class="card-body">
            <h2 class="card-title">7. Write Service for Jenkins</h2>
            <p class="card-text">"service.yaml"</p>

<pre><code class="groovy">apiVersion: v1
kind: Service
metadata:
=name: jenkins
spec:
type: LoadBalancer
ports:
- port: 80
targetPort: 8080
selector:
app: jenkins

---

apiVersion: v1
kind: Service
metadata:
name: jenkins-jnlp
spec:
type: ClusterIP
ports:
- port: 50000
targetPort: 50000
selector:
app: jenkins</code></pre>

        </div>
        <div class="card-footer text-muted">
            Reference: <a href="https://rancher.com/blog/2018/2018-11-27-scaling-jenkins/">Deploying and Scaling Jenkins on Kubernetes</a>
        </div>
    </div> -->

    <!-- <div class="card mb-4" id="kubernetes-8">
        <div class="card-body">
            <h2 class="card-title">8. Deploy Jenkins master</h2>
            <p class="card-text">Do this from Kubernetes master</p>

            <ul>
                <li>kubectl apply -f deployment.yaml</li>
                <li>kubectl create -f service.yaml</li>
                <li>kubectl get service</li>
            </ul>
        </div>
        <div class="card-footer text-muted"></div>
    </div>

    <div class="card mb-4" id="kubernetes-9">
        <div class="card-body">
            <h2 class="card-title">9. Deploy Jenkins agent</h2>
            <p class="card-text">Do this from Kubernetes master</p>

            <ul>
                <li>kubectl cluster-info | grep master</li>
                <li>kubectl get pods | grep jenkins</li>
                <li>kubectl describe pod</li>
            </ul>
        </div>
        <div class="card-footer text-muted"></div>
    </div>
 -->

    <!-- Kubernetes END -->


    <!-- Nexus BEGIN -->
    <div class="card mb-4" id="nexus">
      <div class="card-body">
        <h2 class="card-title">Nexus</h2>
        <ul class="list-unstyled mb-0">
          <li><a href="#nexus-1">1. Nexus Architecture</a></li>
            <!-- <li><a href="#nexus-2">Managing Permission</a></li>
            <li><a href="#nexus-3">LDAP Certificates</a></li> -->
        </ul>
      </div>
    </div>

    <div class="card mb-4" id="nexus-1">
      <div class="card-body">
        <h2 class="card-title">1. Nexus Architecture</h2>
        <p class="card-text">Nexus is a tool used to store Software artifacts. It allows uploading and downloading artifacts by GUI and REST endpoint. There are two types of artifacts</p>
        <ul>
          <li>SNAPSHOT - this type of artifact is for temporarily storage whose retention period is usually 1 day. SNAPSHOT artifacts should be allowed to be overwritten. This is useful when developement team frequently builds their artifact and upload it to nexus to allow QA testing to commmence immediately</li>
          <li>RELEASE - this type of artifact is for permanent storage and it should not be overwritten. RELEASE artifacts are used during Continuous Delievery phase where it will deployed to many different environments before landing the Production</li>
        </ul>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>
    <!-- Nexus END -->


    <!-- Linux BEGIN -->
    <div class="card mb-4" id="linux">
      <div class="card-body">
        <h2 class="card-title">Linux</h2>
        <p class="card-text"></p>
        <ul class="list-unstyled mb-0">
          <li><a href="#linux-1">1. Shell Scripting</a></li>
          <li><a href="#linux-2">2. CD Command</a></li>
          <li><a href="#linux-3">3. Date</a></li>
          <li><a href="#linux-4">4. SSH and SCP</a></li>
          <li><a href="#linux-5">5. PS</a></li>
          <li><a href="#linux-6">6. Archive</a></li>
          <li><a href="#linux-7">7. Administration</a></li>
          <li><a href="#linux-8">8. System</a></li>
          <li><a href="#linux-10">10. Color</a></li>
          <li><a href="#linux-11">11. Python Integration</a></li>
          <li><a href="#linux-12">12. Cron</a></li>
          <li><a href="#linux-13">13. File</a></li>
          <li><a href="#linux-14">14. Process and Thread</a></li>
        </ul>
      </div>
    </div>

    <div class="card mb-4" id="linux-1">
      <div class="card-body">

        <h2 class="card-title">1. Shell Scripting</h2>

        <h3 class="card-title">Script header</h3>
<pre><code class="bash">#!/bin/bash

# ------------------------------ #
# The script does blah blah blah #
# ------------------------------ #</code></pre>

        <h3 class="card-title">Formatting</h3>
        <ul>
          <li>Indent 2 spaces.</li>
          <li>Maximum line length is 80 characters.</li>
        </ul>

        <h3 class="card-title">Function</h3>
<pre><code class="bash">########################
# Function description #
########################
function &lt;function_name&gt;() {
  # $1, $2, $3, so on are used to read in arguments passed to shell script and functions.
  local &lt;argument1&gt;=$1 # Description about the first argument.
  local &lt;argument2&gt;=$2 # Description about the second argument.
  local &lt;argument3&gt;=$3 # Description about the thrid argument.
  ...

  echo &lt;ret_val&gt; # This is the return statement.

  exit 1 # This exits the script execution.
}

# When calling a function, wrapping a variable inside quotes will make sure that the entire content is passed.
# Example
my_function $arg1 $arg2 "$arg_large_string_with_spaces"</code></pre>

        <h3 class="card-title">Read user inputs</h3>
<pre><code class="bash">read USER_INPUT1 ; export USER_INPUT1
# Makes echoing user input unavailable.
read -s USER_INPUT1 ; export USER_INPUT1

read input
if [[ "${input}" == "y" ]]; then
  echo "${input}"
fi

# Provide user guide on how to run the script.
if [ -z "${ENV_VAR_SET_BY_USER_ACTION}" ]; then
  echo "Usage: $0 keyword1"
  echo "Usage: $0 keyword2"
  echo "Usage: $0 keyword3"
  exit 1
fi</code></pre>

        <h3 class="card-title">Suppress outputs</h3>
<pre><code class="bash"># Supress outputs of pushd and popd commands.
pushd () {
  command pushd "$@" > /dev/null
}

popd () {
  command popd "$@" > /dev/null
}

# Suppress output of bash command.
cat file.txt > /dev/null # suppress output

# Suppress error.
err() {
  echo "[$(date +'%Y-%m-%dT%H:%M:%S%z')]: $*" >&2
}</code></pre>

        <h3 class="card-title">curl</h3>
<pre><code class="bash"># Options
# v – verbose output
# s – suppress output
# u - to pass in credentials
# o – to write output to a destination
# w '%{http_code}' – to get the http status code
curl [options] [URL] -X [GET/POST/PUT/DELETE] -H [Headers] -d [Data]

# Posting a JSON data.
echo $JSON_DATA | curl [options] [URL] -X [GET/POST/PUT/DELETE] -H [Headers] -d @-
curl [options] [URL] -X [GET/POST/PUT/DELETE] -H [Headers] -d'{ "field": "value" }'

# Constructing JSON payload.
curl -u "${username}":"${password}" -X POST "${url}/${path}" \
--data-urlencode 'json={
  "": "0",
  "field": {
    "field1": "'${value1}'",
    "field2": "'${value2}'",
    "field3": "'${value3}'"
  }
}' -H "field: ${value}"

# Constructing XML payload.
cat &gt; data.xml &lt;&lt;EOF
&lt;element&gt;
  &lt;subelement1&gt;$value1&lt;/subelement1&gt;
  &lt;subelement2&gt;$value2&lt;/subelement2&gt;
  &lt;subelement3&gt;$value3&lt;/subelement3&gt;
&lt;/element&gt;
EOF

curl -u "${username}":"${password}" \
     -X POST \
     -H 'content-type:application.xml' \
     -d @data.xml \
     "${url}/${path}"
rm -f data.xml

# Example
http_status_code=$(curl -u "${username}":"${password}" -w "%{http_code}" -o "${log_output_location}" -s -H "Content-Type:application/json" -d '{"field1": "'${variable1}'", "field2": "'${variable2}'"}' "${url}/${path}")</code></pre>

        <h3 class="card-title">wget</h3>
<pre><code class="bash">wget --user &lt;username&gt; --password &lt;password&gt; &lt;url&gt;</code></pre>

        <h3 class="card-title">Conditional</h3>
<pre><code class="bash"># Variable equals to an integer 200.
if [ "${variable}" -eq 200 ]; then

fi

# Variable is null.
if [ -z "${variable}" ]; then

fi

# Variable is not null.
if [ -n "${variable}" ]; then

fi

# One of two variables is null.
if [ -z "${var1}" -o -z "${var1}" ]; then

fi

# Variable equals to a string.
if [ "${variable}" == "{string}" ]; then

fi

# Complex conditions.
if [[ -z "${variable1}" && "{variable2}" != "something" ]] && [[ "${variable3}" == "value1" || "${variable4}" == "value2" ]]; then

fi</code></pre>

        <h3 class="card-title">Current and parent directory</h3>
<pre><code class="bash"># Scripts can execute from different path, so absolute path is needed.
CURRENT_DIR=$( cd "$(dirname "${BASH_SOURCE[0]}")" ; pwd -P )
PARENT_DIR="$(dirname "${CURRENT_DIR}")"</code></pre>

        <h3 class="card-title">Loop</h3>
<pre><code class="bash"># Loop through array.
for i in "${array[@]}"; do
  echo "${i}"
done

# Loop through number.
for i in $(seq 1 "${END}"); do
  echo "${i}"
done

# Loop through a string separated by space.
string="a b c d e"
for i in $(echo "${string}"); do
  echo "${i}"
done

# Loop through directory.
for filename in path/*.txt; do
  [ -e "${filename}" ] || continue
done</code></pre>

        <h3 class="card-title">Array</h3>
<pre><code class="bash"># Declare an array.
array=("item1" "item2" "item3")
# Add to an array.
array+=("item4")

# Assessing array element.
element=${array[0]}</code></pre>

        <h3 class="card-title">File</h3>
<pre><code class="bash"> # Check if file exists.
if [ ! -f /path/file ]; then
  echo "File does not exist"
fi

# Check if a string exists in a file.
if grep -Fxq "${string}" "${file}"; then
  # String found
else
  # String not found
fi

# Read file line by line.
while IFS= read -r line; do
  echo "${line}"
done < "${file}"

# Write a block of texts to a file
cat &lt;&lt;EOF&gt;&gt; "${file}"
{
  "key": "value"
}
EOF</code></pre>

        <h3 class="card-title">sed</h3>
<pre><code class="bash"># Match pattern and update in place.
sed -i "s/string_to_match/string_to_replace_with/"

# Add a line after a match.
sed -i "/string_to_match.*/a ${string_to_insert}/"

# If adding 5 leading spaces to "string_to_insert".
sed -i "/string_to_match.*/a /    / ${string_to_insert}/"

# Remove a block of texts from a file.
sed -i "/begin/./end/d "${file}"</code></pre>

        <h3 class="card-title">Sting</h3>
<pre><code class="bash"># Remove two characters from the beginning for the string.
string=${string:2}

# Remove prefix from a string.
string=${string#"prefix_to_remove"}

# Remove path from a file.
string=${string##*/}

# Find and replace.
${string/$match/$replace}

# Find and replace for all occurance.
${string//$match/$replace}

# Split string by a delimiter.
array_of_split_string=(${string//\//})
first_element_after_split=${array_of_split_string[0]}
second_element_after_split=${array_of_split_string[1]}</code></pre>

        <h3 class="card-title">jq</h3>
<pre><code class="bash"># Make JSON output pretty
echo $json | jq -r '.'

# Sort the JSON fields by key
echo $json | jq --sort-keys

# Replace values of multiple fields
echo $json | jq .field1.field2.field3 = value1 | field4.field5.field6 = value2</code></pre>

        <h3 class="card-title">yq</h3>
<pre><code class="yaml"># Example
a:
  b:
    - c:
      d:
        e:
        f:
        g:
    - c:
      d:
        e:
        f:
        g:
    - c:
      d:
        e:
        f:
        g:
    - c:
      d:
        e:
        f:
        g:</code></pre>

<pre><code class="bash"># Assuming version greater or equal to 3.

# Get all values of 'e'.
yq r $yaml_file_name "a.b.*.d.e"

# Get 'f' that where 'e' equals to a particular value.
yq r $yaml_file_name "a.b.(d.e==$some_value).d.f"

# Add an elemnet under 'b'.
yq w -i $yaml_file_name a.b[+] $something_to_add

# Add under second element of 'b'.
yq w -i $yaml_file_name a.b[1].d.e[+] $something_to_add</code></pre>

        <h3 class="card-title">grep</h3>
<pre><code class="bash"># Options
Use option -v to # Find all except the match
Use option -c to # Get number of lines with match
Use option -i to # Ignore case
Use option -r to # Find matches recursively in files in directory
grep [options] pattern [files]

# Check if a string exists in a file.
if greq -q $string $file; then
    # Do something.
fi
</code></pre>

        <h3 class="card-title">find</h3>
<pre><code class="bash">find [pathnames] [conditions]

# Find files containing mail in "/etc".
find /etc -name "*mail*"

# Find files greater than 100M.
find / -type f -size +100M

# Find files modified in last two days.
find . –mtime -2

# List files greater than 100M.
find / -type f -name *.tar.gz -size +100M -exec ls -l {} \;

# Delete files greater than 100M.
find / -type f -name *.tar.gz -size +100M -exec rm -f {} \;

# Loop through results from "find".
find / type -f -name $filename 2> /dev/null | while read line; do
    # Do something with $line
done</code></pre>

        <h3 class="card-title">Uppercase and lowercase</h3>
<pre><code class="bash">tr a-z A-Z < file.txt # Convert to uppercase.
tr A-Z a-z < file.txt # Convert to lowercase.
lowercase=$(echo "$string" | tr '[:upper:]' '[:lower:]') # Convert a string to lowercase.

var="Test"

lowercase=${var,,}
echo $lowercase  # test

uppercase=${var^^}
echo $uppercase  # TEST</code></pre>

        <h3 class="card-title">Cut</h3>
<pre><code class="bash">cut -d: -f 1 file.txt # Display 1st field from colon delimited file
cut -d: -f 1,3 file.txt # Display 1st and 3rd field from colon delimited file
cut -d: -f1 /etc/passwd # Displays unix login names for all users in the system
free | tr -s ' ' | sed '/^Mem/!d' | cut -d" " -f2 # Displays total memory available on the system</code></pre>

        <h3 class="card-title">envsubst</h3>
<pre><code class="json"># Example json to be updated by envsubst.
{
    "field1": ${value1},
    "field2": ${value2},
    "field3": ${value3}
}</code></pre>

<pre><code class="bash">data=$(value1="some_value1" value2="some_value2" value3="some_value3" envsubst '${value1}, ${value2}, ${value3}' < $file_name)</code>
</pre>

        <h3 class="card-title">Environment variable</h3>
<pre><code class="bash"># Add to an environment variable.
export ENV_VAR=$ENV_VAR:/path/to/add</code></pre>
<pre><code class="bash"># Remove from an environment variable.
directory_to_remove=/path/to/remove
ENV_VAR=:$ENV_VAR:
ENV_VAR=${ENV_VAR//:$directory_to_remove:/:}
ENV_VAR=${ENV_VAR#:}; ENV_VAR=${ENV_VAR%:}</code></pre>

        <h3 class="card-title">Increment a snapshot version</h3>
<pre><code class="bash"># build.gradle
version=$(grep version\( build.gradle | cut -d- -f1 | cut -d\' -f2)
[[ -n $grep version\( build.gradle | grep SNAPSHOT) ]] && version=$(echo $version | awk -F\. '{print $1"."$2"."(#3-1)}')
echo $version</code></pre>
<pre><code class="bash"># maven-metadata.xml (in Nexus)
url=&lt;nexus_url&gt;/repository/&lt;repo_name&gt;/&lt;group_id&gt;/&lt;artifact_id&gt;/maven_metadata.xml
current_version=$(curl -k $url | grep -Po '(?&lt;=&lt;version&gt;)([0-9\.]+(-SNAPSHOT)?)' | sort --version-sort r | head -n 1)
incremented_version=$(echo $current_version | awk -F. -v OFS=. 'NF==1{pring ++$NF}; NF&gt;1{if(length($NF+1)&gt;length($NF))$(NF-1)++;$NF=sprintf("%0*d", length($NF), ($NF+1)%(10^length($NF))); print}')
echo $incremented_version</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="linux-2">
      <div class="card-body">
        <h2 class="card-title">2. CD Command</h2>
        <h3 class="card-title">CDPATH</h3>
<pre><code class="bash">export CDPATH=/etc
cd security
/etc/security</code></pre>
        <p class="card-text">To make this permanent, add "export CDPATH=/etc" to "~/.bash_profile" (also do "source ~/.bash_profile")</p>

        <h3 class="card-title">alias</h3>
<pre><code class="bash">alias ..5=../../../../../
cd one/two/three/four/five/six
cd ..5
pwd
one</code></pre>

        <h3 class="card-title">mkdircd</h3>
<pre><code class="bash">mkdircd /one/two/three
pwd
one/two/three</code></pre>

        <h3 class="card-title">"cd -" toogle between last two directories</h3>

        <h3 class="card-title">"dirs" - display directory stack. "pushd" - push directory into stack. "popd" - pop directory from stack and cd to it</h3>
<pre><code class="bash"># Example: create tmp, do the work, and remove tmp
mkdir tmp && pushd
# do some work
popd && rm -rf tmp</code></pre>

        <h3 class="card-title">shopt -s cdspell</h3>
<pre><code class="bash">shopt -s cdspell
cd /etc/mall
pwd
/etc/mail</code></pre>
      </div>
      <div class="card-footer text-muted">
          Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-3">
      <div class="card-body">
        <h2 class="card-title">3. Date</h2>
        <h3 class="card-title">System date and time</h3>
<pre><code class="bash">date -s "01/31/2009 22:19:53"</code></pre>

        <h3 class="card-title">Set hardware date and time based on system date and time</h3>
<pre><code class="bash">hwclock --systohc –utc</code></pre>

        <h3 class="card-title">Format date and time</h3>
<pre><code class="bash">date
date --date='1970-01-01 00:00:01 UTC +5 hours' +%s
date '+Current Date: %m/%d/%y%nCurrent Time:%H:%M:%S'
date +"%d/%m/%Y"
date +"%A,%B %d %Y"</code></pre>

        <h3 class="card-title">Past date and time</h3>
<pre><code class="bash">date --date="1 day ago"
date --date="1 year ago"
date --date="yesterday"</code></pre>

        <h3 class="card-title">Future date and time</h3>
<pre><code class="bash">date --date="1 day"
date --date="1 year"
date --date="tomorrow"</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-4">
      <div class="card-body">
        <h2 class="card-title">4. SSH and SCP</h2>
        <h3 class="card-title">Check ssh version</h3>
<pre><code class="bash">ssh -V</code></pre>

        <h3 class="card-title">Login to remote</h3>
<pre><code class="bash">ssh -l &lt;username&gt; &lt;ip&gt;</code></pre>

        <h3 class="card-title">Debug ssh client session</h3>
<pre><code class="bash">ssh -v l &lt;username&gt; &lt;ip&gt;</code></pre>

        <h3 class="card-title">Creating public and private key pair. First, have <strong>Git</strong> installed in your machine</h3>
<pre><code class="bash">ssh-keygen</code></pre>
        <img class="img-fluid" class="card-img-top" src="img/linux/linux-3-a.png" alt="Card image cap" style="max-width:500px">
        <p class="card-text">You can choose to have passphrase as well (which you need to remember when sshing into a remote machine)</p>
        <p class="card-text">Make sure to give 600 to id_rsa and 644 to id_rsa.pub and known_hosts</p>

        <h3 class="card-title">Refresh known_hosts</h3>
<pre><code class="bash">ssh-keyscan -H &lt;ip&gt; ~/.ssh/known_hosts</code></pre>

        <h3 class="card-title">Change SSH password</h3>
<pre><code class="bash">Login via SSH first. Type "passwd" and enter the existing and new passwords</code></pre>

        <h3 class="card-title">SCP</h3>
<pre><code class="bash"># Local to remote.
scp -r &lt;folder&gt; &lt;username&gt;@&lt;IP-or-hostname&gt;:&lt;directory&gt;

# Remote to local.
scp &lt;username&gt;@&lt;IP-or-hostname&gt;:&lt;file&gt; &lt;directory&gt;</code></pre>

        <h3 class="card-title">SSH tunnel via port-forwarding</h3>
<pre><code class="bash">ssh -i &lt;host-private-key&gt; -L &lt;host-port&gt;:&lt;vm-ip&gt;:&lt;vm-port&gt; &lt;vm-username&gt;@&lt;vm-ip&gt; -N</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-5">
      <div class="card-body">
        <h2 class="card-title">5. PS</h2>

        <h3 class="card-title">Change color of prompt</h3>
<pre><code class="bash">export PS1="\e[0;34m\u@\h \w> \e[m " # blue color (foreground), username, host and current directory</code></pre>
        <p class="card-text">For permanent change, in ~/.bash_profile</p>
<pre><code class="bash">STARTCOLOR='\e[0;34m';
ENDCOLOR="\e[0m"
export PS1="$STARTCOLOR\u@\h \w> $ENDCOLOR"</code></pre>
<pre><code class="bash">export PS1="\e[47m\u@\h \w> \e[m " # blue color (background), username, host and current directory</code></pre>
        <p class="card-text">For permanent change, in ~/.bash_profile</p>
<pre><code class="bash">STARTFGCOLOR='\e[0;34m';
STARTBGCOLOR="\e[47m"
ENDCOLOR="\e[0m"
export PS1="$STARTFGCOLOR$STARTBGCOLOR\u@\h \w> $ENDCOLOR"</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-6">
      <div class="card-body">
        <h2 class="card-title">6. Archive</h2>

        <h3 class="card-title">zip {.zip file-name} {file-names}</h3>
<pre><code class="bash">zip var-log-files.zip /var/log/* # zip all files in /var/log/* into var-log-files.zip</code></pre>

        <h3 class="card-title">unzip var-log.zip</h3>

        <h3 class="card-title">Compression</h3>
<pre><code class="bash">zip var-log-files-default.zip /var/log/* # level 6 - default high compression
zip -0 var-log-files-0.zip /var/log/* # level 0 - no compression
zip -9 var-log-files-9.zip /var/log/* # level 9 - highest compression</code></pre>

        <h3 class="card-title">Password protect</h3>
<pre><code class="bash">zip -P mysecurepwd var-log-protected.zip /var/log/*</code></pre>

        <h3 class="card-title">tar</h3>
<pre><code class="bash">tar [options] [tar-archive-name] [other-file-names]
# Options
# c - create an archive
# v - verbose mode
# f - archive file name
# x - extract files from tar archive
# z - when dealing with tar.gz compressed file
# j - when dealing with tar.bz2 compressed file
tar cvf /tmp/file.tar /home/rieh # create tar
tar xvf /tmp/file.tar # extract tar</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-7">
      <div class="card-body">
        <h2 class="card-title">7. Administration</h2>
        <p class="card-text">7.1. Disk</p>
        <p class="card-text">n – new partition creation</p>
        <p class="card-text">d – delete existing partition</p>
        <p class="card-text">p - print partition table</p>
        <p class="card-text">w – write changes to the partition table</p>
        <p class="card-text">q – quit fdisk utility</p>
<pre><code class="bash">fdisk /dev/sda # invoke fdisk (first step to create /dev/sda1 primary partition)</code></pre>
<pre><code class="bash">mke2fs /dev/sda1 # format disk so it can be used</code></pre>
<pre><code class="bash">mount /dev/sda1 /home/database # mount partition to directory</code></pre>
<pre><code class="bash">tune2fs -l /dev/sda1 # view the filesystem</code></pre>

        <p class="card-text">7.2. User and group</p>
<pre><code class="bash">useradd rieh # add a user</code></pre>
<pre><code class="bash">passwd rieh # change user password</code></pre>
<pre><code class="bash">groupadd developers # add a group</code></pre>
<pre><code class="bash">usermod -g developers jsmith # add user to group</code></pre>

        <p class="card-text">7.3. Owndership and permission</p>
<pre><code class="bash">chmod -fR [permission] [directory/file] # change permission on file/directory</code></pre>
<pre><code class="bash">chown -fR [user/group]:[user/group] [directory/file] # change ownership of file/directory</code></pre>

        <p class="card-text">7.4. Access control</p>
<pre><code class="bash">/etc/security/access.conf # Add user(s) or groups(s) to this file to grant access to the machine</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-8">
      <div class="card-body">
        <h2 class="card-title">8. System</h2>

        <p class="card-text">8.1. free [options]</p>
        <p class="card-text">m - displays values in MB</p>
        <p class="card-text">t - displays sum of physical and swap memory</p>
        <p class="card-text">o - hide buffers/cache line</p>

        <p class="card-text">8.2. top [options]</p>

        <p class="card-text">8.3. ps [options]</p>
<pre><code class="bash">ps aux | more # display all processes running in system</code></pre>

        <p class="card-text">8.4. df [options] [name]</p>
<pre><code class="bash">df –h # human readable format</code></pre>

        <p class="card-text">8.5. kill [options] [pids|commands]</p>

        <p class="card-text">8.6. Disk usage</p>
<pre><code class="bash">du -sh ~</code></pre>
<pre><code class="bash">du --max-depth=1 /[folder] | sort -n -r # find size of folders</code></pre>

        <p class="card-text">8.7. lsof</p>
<pre><code class="bash">lsof | more # view all open files in system</code></pre>
<pre><code class="bash">lsof -i -P -n | grep LISTEN # find pid and kill them
kill -9 [pid]</code></pre>

        <p class="card-text">8.8. sar</p>
<pre><code class="bash">sar –u # Display CPU statistics</code></pre>
<pre><code class="bash">sar –d # Display disk IO statistics</code></pre>

        <p class="card-text">8.9. stat</p>
<pre><code class="bash">netstat -tulnp | grep 8443 # find processes running on port 8443</code></pre>
<pre><code class="bash">stat -c "%a &n" * # display stats of files</code></pre>

        <p class="card-text">1.18. Diff</p>
<pre><code class="bash">diff -w file_old.txt file_new.txt</code></pre>

        <p class="card-text">1.19. Reboot the machine</p>
<pre><code class="bash">sudo reboot</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: Linux 101 Hacks, Remesh Natarajan, www.thegeekstuff.com
      </div>
    </div>

    <div class="card mb-4" id="linux-10">
      <div class="card-body">
        <h2 class="card-title">10. Color</h2>

        <p class="card-text">10.1. Types of colors in bash</p>
<pre><code class="bash">printf "Foreground Regular\n"
printf "\033[31mI am Red\033[0m\n"
printf "\033[32mI am Green\033[0m\n"
printf "\033[33mI am Yellow\033[0m\n"
printf "\033[34mI am Blue\033[0m\n"
printf "\033[35mI am Magenta\033[0m\n"
printf "\033[36mI am Cyan\033[0m\n"
printf "\033[37mI am Light Gray\033[0m\n"
printf "Foreground Bright\n"
printf "\033[90mI am Dark Gray\033[0m\n"
printf "\033[91mI am Light Red\033[0m\n"
printf "\033[92mI am Light Green\033[0m\n"
printf "\033[93mI am Light Yellow\033[0m\n"
printf "\033[94mI am Light Blue\033[0m\n"
printf "\033[95mI am Light Magenta\033[0m\n"
printf "\033[96mI am Light Cyan\033[0m\n"
printf "Background Regular\n"
printf "\033[41mI am Red\033[0m\n"
printf "\033[42mI am Green\033[0m\n"
printf "\033[43mI am Yellow\033[0m\n"
printf "\033[44mI am Blue\033[0m\n"
printf "\033[45mI am Magenta\033[0m\n"
printf "\033[46mI am Cyan\033[0m\n"
printf "\033[47mI am Light Gray\033[0m\n"
printf "Background Bright\n"
printf "\033[100mI am Dark Gray\033[0m\n"
printf "\033[101mI am Light Red\033[0m\n"
printf "\033[102mI am Light Green\033[0m\n"
printf "\033[103mI am Light Yellow\033[0m\n"
printf "\033[104mI am Light Blue\033[0m\n"
printf "\033[105mI am Light Magenta\033[0m\n"
printf "\033[106mI am Light Cyan\033[0m\n"</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="linux-11">
      <div class="card-body">
        <h2 class="card-title">11. Python Integration</h2>

        <p class="card-text">11.1. Virtual python environment</p>
<pre><code class="bash">virtualenv -p python3 .env # create python3 virtual environment at .env directory
source .env/bin/activate
pip3 install -r requirements.txt # Assuming python dependencies are under "requirements.txt"</code></pre>

        <p class="card-text">11.2. Execute python</p>
<pre><code class="bash">python [your_script.py] [--options] [arguments]</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="linux-12">
      <div class="card-body">
        <h2 class="card-title">12. Cron</h2>

        <p class="card-text">minute (0 - 59) | hour (0 - 23) | day of the month (1 - 31) | month (1 - 12) | day of the week (0 - 6) [Sunday to Saturday]</p>
<pre><code class="bash">22 5 * * 6 # 5:22AM every Saturday
*/5 * * * * # Every 5 minutes
0 0 1 1 * # Yearly
0 0 1 * * # Monthly
0 0 * * 0 # Weekly
0 0 * * * # Daily
0 * * * * # Hourly</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="linux-13">
      <div class="card-body">
        <h2 class="card-title">13. File</h2>

        <h3 class="card-title">Ownership and permission</h3>
<pre><code class="bash"># owner / grouup / all users
# read(4) / write (2) / execute (1)
# For example, "chmod 640" gives read and write permission to the owner, read permission to the group, no permission to all others
chmod 640 $file</code></pre>

        <h3 class="card-title">Softlink</h3>
<pre><code class="bash"># To have "link1 -> file1"
ln -s file1 link1
ls -l file1 link1</code></pre>

        <h3 class="card-title">Remove a file starting with dash.</h3>
<pre><code class="bash">rm ./ -file</code></pre>

        <h3 class="card-title">Split and merge files.</h3>
<pre><code class="bash"># Split file.tar.gz by 1000000000 (this produces xaa, xab, xac, ...)
split -b 1000000000 file.tar.gz

# Merge splitted files.
cat x* > file.tar.gz</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="linux-14">
      <div class="card-body">
        <h2 class="card-title">14. Process and Thread</h2>

        <p class="card-text">Thread is an execution unit, which is a part of process. It is a unit of execution in concurrent programming. It can be managed by a scheduler</p>

        <p class="card-text">Process is an isolated execution entity, which does not share data. Creating process requires a separate system call. It has its own heap memory</p>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

      <!-- div class="card mb-4" id="linux-3">
      <div class="card-body">
          <h2 class="card-title">JBoss</h2>
          <p class="card-text"><strong>standalone.xml</strong> - this file located at /etc/jbossas/standalone/standalone.xml contains deployment configuration including certificates and passwords for web access</p>
          <p class="card-text"><strong>logs</strong> - the Jboss server logs are located at /var/log/jbossas/[ServerName]
          <p class="card-text"><strong>deployment info</strong> - to view the deployment info sudo /usr/share/jbossas/bin/jboss-cli.sh --connect deployment-info</p>
      </div>
      <div class="card-footer text-muted"></div>
    </div> -->
    <!-- Linux END -->


    <!-- Ubuntu BEGIN -->
    <div class="card mb-4" id="ubuntu">
      <div class="card-body">
        <h2 class="card-title">Ubuntu</h2>
        <p class="card-text"></p>
        <ul class="list-unstyled mb-0">
          <li><a href="#ubuntu-1">1. Proxing</a></li>
          <li><a href="#ubuntu-2">2. Kubectl</a></li>
          <li><a href="#ubuntu-3">3. Gomplate</a></li>
          <li><a href="#ubuntu-4">4. Helm</a></li>
          <li><a href="#ubuntu-5">5. Vault</a></li>
          <li><a href="#ubuntu-6">6. Java</a></li>
        </ul>
      </div>
    </div>

    <div class="card mb-4" id="ubuntu-1">
      <div class="card-body">
        <h2 class="card-title">1. Proxing</h2>

<pre><code class="bash"># Update /etc/profile such that
export http_proxy=&lt;PROXY_URL_AND_PORT&gt;
export https_proxy=&lt;PROXY_URL_AND_PORT&gt;</code></pre>

<pre><code class="bash"># The source the updated file
source /etc/profile</code></pre>

<pre><code class="bash"># To disable proxy
unset `env | grep proxy | cut -d= -f1`</code></pre>

<pre><code class="bash"># To enable proxy for apt package manager, create /etc/apt/apt/conf.d/proxy.conf and add
Acquire {
  HTTP::proxy "&lt;PROXY_URL_AND_PORT&gt;"
  HTTPS::proxy "&lt;PROXY_URL_AND_PORT&gt;"
}

# Then run
sudo apt-get update</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="ubuntu-2">
      <div class="card-body">
        <h2 class="card-title">2. Kubectl</h2>
<pre><code class="bash">curl -k -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="ubuntu-3">
      <div class="card-body">
        <h2 class="card-title">3. Gomplate</h2>
<pre><code class="bash">curl -k -o /usr/local/bin/gomplate -sSL https://github.com/hairyhenderson/gomplate/releases/download/&lt;version&gt;/gomplate_&lt;os&gt;-&lt;arch&gt;
# For example
curl -k -o /usr/local/bin/gomplate -sSL https://github.com/hairyhenderson/gomplate/releases/download/v3.10.0/gomplate_linux-amd64
chmod 755 /usr/local/bin/gomplate
which gomplate</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="ubuntu-4">
      <div class="card-body">
        <h2 class="card-title">4. Helm</h2>
<pre><code class="bash">curl -k -o helm-v3.7.1-linux-amd64.tar.gz https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz
tar -zxvf helm-v3.7.1-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="ubuntu-5">
      <div class="card-body">
        <h2 class="card-title">5. Vault</h2>

<pre><code class="bash"># Install Vault.
curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
sudo apt-get update && sudo apt-get install vault

# Setup Vault URL.
export VAULT_ADDR=https://&lt;YOUR_VAULT_URL&gt;

# Login to Vault (Need to enter token you can get by logging into Vault UI)
vault login

# Read password.
vault kv get -field &lt;CREDENTIAL_NAME&gt; &lt;PATH/TO/CREDENTIAL&gt;</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>

    <div class="card mb-4" id="ubuntu-6">
      <div class="card-body">
        <h2 class="card-title">6. Java</h2>

<pre><code class="bash">sudo apt install default-jre
java -version

# Assuming ubuntu 18.04
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
echo $JAVA_HOME
export PATH=$PATH:$JAVA_HOME/bin
echo $PATH</code></pre>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>
    <!-- Ubuntu END -->


    <!-- vi BEGIN -->
    <div class="card mb-4" id="vi">
      <div class="card-body">
        <h2 class="card-title">vi</h2>
        <p class="card-text"></p>
        <ul class="list-unstyled mb-0">
          <li><a href="#vi-1"></a></li>
<pre><code class="bash"># Search
:/your_search_string # Then, type "n" to go the next

# Line number
:set number</code></pre>
        </ul>
      </div>
    </div>
    <!-- vi END -->


    <!-- Sonarqube BEGIN -->
    <!-- <div class="card mb-4" id="sonarqube">
        <div class="card-body">
            <h2 class="card-title">SonarQube</h2>
            <p class="card-text">SonarQube is a code scanning tool which checks for <strong>maintenance and reliability</strong>. Although it also looks for potential security issues, its not in depth compared to Sonatype and Veracode</p>
            <ul class="list-unstyled mb-0">
                <li><a href="#sonarqube-1">Permission Templates</a></li>
            </ul>
        </div>
        <div class="card-footer text-muted">
            Posted on September 9, 2018 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div> -->
    <!-- Sonarqube END -->


    <!-- Sonatype BEGIN -->
    <!-- <div class="card mb-4" id="sonatype">
        <div class="card-body">
            <h2 class="card-title">SonaType</h2>
            <p class="card-text">SonaType is a code scanning tool which checks for potential <strong>security issues in thrid part libraries</strong>.</p>
            <ul class="list-unstyled mb-0">
                <li><a href="#sonatype-1">sonatype</a></li>
            </ul>
        </div>
        <div class="card-footer text-muted">
            Posted on September 9, 2018 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div> -->
    <!-- Sonatype END -->


    <!-- Veracode BEGIN -->
    <!-- <div class="card mb-4" id="veracode">
        <div class="card-body">
            <h2 class="card-title">Veracode</h2>
            <p class="card-text">Veracode is a code scanning tool which checks for potential <strong>security issues in the code</strong>.</p>
            <ul class="list-unstyled mb-0">
                <li><a href="#veracode-1">veracode</a></li>
            </ul>
        </div>
        <div class="card-footer text-muted">
            Posted on September 9, 2018 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div> -->
    <!-- Veracode END -->


    <!-- Windows BEGIN -->
    <!-- <div class="card mb-4" id="windows">
        <div class="card-body">
            <h2 class="card-title">Windows</h2>
            <p class="card-text"></p>
            <ul class="list-unstyled mb-0">
                <li><a href="#windows-1">Access Control</a></li>
            </ul>
        </div>
        <div class="card-footer text-muted">
            Posted on September 9, 2018 by
            <a href="#">Seungmoon Rieh</a>
        </div>
    </div> -->
    <!-- Windows END -->


    <!-- GCP BEGIN -->
    <div class="card mb-4" id="gcp-1">
      <div class="card-body">
        <h2 class="card-title">Google Cloud Platform</h2>
        <p class="card-text">How to provision GKE using Redhat7</p>

<pre><code class="bash"># Update YUM with Cloud SDK repo information:
sudo tee -a /etc/yum.repos.d/google-cloud-sdk.repo << EOM
[google-cloud-sdk]
name=Google Cloud SDK
baseurl=https://packages.cloud.google.com/yum/repos/cloud-sdk-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOM

# Install the Cloud SDK
sudo yum install google-cloud-sdk

# Choose the project and region
gcloud init

sudo yum install kubectl

# You may get errors. Wait until Kubernetes API is enabled for the project. Then try this command again
gcloud container clusters create [CLUSTER_NAME]

gcloud container clusters get-credentials [CLUSTER_NAME]

# Delete the cluster after
gcloud container clusters delete [CLUSTER_NAME]</code></pre>

        <p class="card-text">From this point on, you can just do the following to provision/delete cluster</p>

<pre><code class="bash">gcloud container clusters create [CLUSTER_NAME]

gcloud container clusters delete [CLUSTER_NAME]</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://cloud.google.com/sdk/docs/quickstart-redhat-centos">Quickstart for Red Hat and Centos</a> | <a href="https://cloud.google.com/kubernetes-engine/docs/quickstart">Quickstart</a>
      </div>
    </div>

    <div class="card mb-4" id="gcp-1">
      <div class="card-body">
        <h2 class="card-title">Load Balancer and Static IP</h2>
        <p class="card-text">Provisioning GKE, Load balancer, Static IP, and Jenkins application</p>

<pre><code class="bash"># Load balancer and static IP

gcloud container clusters create [CLUSTER_NAME]

# Reverve static IP for "jenkins-master" application
gcloud compute addresses create [INGRESS_GLOBLA_STATIC_IP_NAME] --global

kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
kubectl apply -f ingress.yaml

# Wait about 10 mins until application comes up

# To delete ingress, IP, and cluster
kubectl delete ingress [INGRESS_NAME]

gcloud compute addresses delete [INGRESS_GLOBLA_STATIC_IP_NAME] --global

gcloud container clusters delete [CLUSTER_NAME]</code></pre>
      </div>
      <div class="card-footer text-muted">
        Reference: <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer">Setting up HTTP Load Balancing with Ingress</a>
      </div>
    </div>
    <!-- GCP END -->


    <!-- F5 BEGIN -->
    <div class="card mb-4" id="f5">
      <div class="card-body">
        <h2 class="card-title">F5</h2>
        <p class="card-text"></p>
        <ul class="list-unstyled mb-0">
            <li><a href="#f5-1">1. Network Basics</a></li>
        </ul>
      </div>
    </div>

    <div class="card mb-4" id="f5-1">
      <div class="card-body">
        <h2 class="card-title">Network Basics</h2>
        <ul>
          <li>Computers can connect to themselves via 127.0.0.1 (localhost)</li>
          <li>"ipconfig" file provides very useful information</li>
          <li>TCP allows multiple services to share the same physical computer via port
            <ul>
              <li>21 - file transfer (FTP)</li>
              <li>22 - secure shell (SSH)</li>
              <li>25, 110 - email (SMTP, POP3)</li>
              <li>80 - web (HTTP)</li>
              <li>443 - secure web (HTTPS)</li>
              <li>993, 995 - secure email</li>
            </ul>
          </li>
          <li>UDP is better suited for streaming media and online games</li>
        </ul>
      </div>
      <div class="card-footer text-muted">

      </div>
    </div>
    <!-- F5 END -->


    <!-- Aboutme BEGIN -->
    <div class="card mb-4" id="aboutme">
      <div class="card-body">
        <h2 class="card-title">About me</h2>
        <p class="card-text"><a href="https://www.linkedin.com/in/seungmoon">Linkedin</a> | <a href="https://github.com/riehseun">Github</a> | <a href="https://www.facebook.com/seungmoon.rieh">Facebook</a></p>
      </div>
    </div>
    <!-- Aboutme END -->


</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->


<footer class="py-5 bg-dark">
  <div class="container">
    <p class="m-0 text-center text-white">Copyright &copy; Seungmoon Rieh 2020</p>
  </div>
</footer>


</body>

</html>