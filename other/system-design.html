<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Other</h1>

<!-- System design BEGIN -->
<div class="card mb-4" id="system-design">
  <div class="card-body">
    <h2 class="card-title">System design</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#system-design-1">System design</a></li>
      <li><a href="#system-design-2">ML Platform</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="system-design-1">
  <div class="card-body">
    <h2 class="card-title">System design</h2>

    <h3 class="card-title">System design</h3>
    <ul>
      <li>Problem</li>
      <li>Functional</li>
      <li>Non-functional</li>
      <li>Extended</li>
      <li>Capacity</li>
      <li>API</li>
      <li>DB</li>
      <li>Design</li>
      <li>Architecture</li>
      <li>Data partitioning</li>
      <li>Load balancing</li>
      <li>Caching</li>
      <li>Design</li>
    </ul>

    <h3 class="card-title">Machine learning system design</h3>
    <ul>
      <li>Problem</li>
      <li>Metric</li>
      <li>Training</li>
      <li>Inference</li>
      <li>Capacity</li>
      <li>Architecture</li>
      <li>Feature engineering</li>
      <li>Training data generation</li>
      <li>Design</li>
    </ul>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>

<div class="card mb-4" id="system-design-2">
  <div class="card-body">
    <h2 class="card-title">ML Platform</h2>
    <ul>
      <li>Performce for out-of-sample and out-of-time.</li>
      <li>Features should be mostly unchanged when input data is slighly perturbed. (Could be challgenging when data contains similar/duplicate features)</li>
      <li>Interpretation should not be depending on training sample choices.</li>
    </ul>

    <h3 class="card-title">Problem definition</h3>
    <ul>
      <li>Construct ground truth.</li>
      <li>Metrics.</li>
    </ul>

    <h3 class="card-title">Data prep</h3>
    <ul>
      <li>Proportion of null/zero values across columns.</li>
      <li>Columns that should be rejected due to zero or null values.</li>
      <li>Categorical columns with high cardinality.</li>
      <li>Columns with high sparcity.</li>
      <li>Duplicate columns.</li>
      <li>Compute per-month count of rows and selected attribute to see if they make sense.</li>
      <li>Verify that join keys are consistent across tables.</li>
      <li>Verify that labels/values to apply exclusions are available in the tables.</li>
      <li>Verify that labels/values to apply ground truth are available in the tables.</li>
      <li>Rectify missing values in columns.</li>
      <ul>
      <li>Random missing value - value is missing for unexplained reason.</li>
      <li>Structural missing value - value is missing for a reason. (For example, the fact that it is missing means something)</li>
      <li>Engineered missing value - feature engineering introduced the missing values. (For example, divide by zero)</li>
      <li>Table join mismatch - IDs in one table were missing in another table, so missing values are created after join.</li>
    </ul>
    </ul>

    <h3 class="card-title">Data profiling</h3>
    <ul>
      <li>General statistics.</li>
      <li>Columns with large portion of missing values. (For example, > 10%)</li>
      <ul>
        <li>These columns should generally be retained for they may turn out to be quite predictive.</li>
        <li>XGBoost has build-in capability to handle missing values.</li>
      </ul>
      <li>Similar/duplicate columns. (For example, prefer one feature over another? Can use univariate analysis)</li>
      <li>Columns with consistant values should be removed because they provide no signal.</li>
      <li>Remove sensitive features from model inputs. (For example, age / gender)</li>
      <li>Data imputation (For example, NULL to 0) should rarely happens when feature is critical and will undergo feature engineering and treatment is known.</li>
    </ul>

    <h3 class="card-title">Exclusion</h3>
    <ul>
      <li>Exclude rows based on certain attributes. (This is driven by business reasons)</li>
    </ul>

    <h3 class="card-title">Ground truth construction</h3>

    <h3 class="card-title">Data split</h3>
    <ul>
      <li>Training: In-Time and In-Sample. Split into 5-folds for cross-validation.</li>
      <li>Testing: Out-of-Time test and In-Time & Out-of-Sample test.</li>
      <li>If a data about person is seen at many different dates, all data about that person must be assigned to the same split. (either Out-of-Sample or one of the folds) Otherwise, there is information leak bwetween training and validation.</li>
      <li>Final model is retrained with all 5 folds combined.</li>
    </ul>

    <h3 class="card-title">Data representativeness</h3>
    <ul>
      <li>Separate datasets by ground truth labels.</li>
      <li>Perform univariate analysis. For example, look at the distribution of samples of a key feature for both the entire dataset and the partitioned dataset. Repeat for all key features.</li>
      <li>All paritioned datasets must include sufficient volume of each ground truth labels across key features.</li>
      <li>Bin size may be increased or bins could be combined as a result of above analysis.</li>
    </ul>

    <h3 class="card-title">Model development</h3>
    <ul>
      <li>Define metric to evaluate the model.</li>
      <li>Score the model by the desired metric.</li>
      <li>Check model performace by month to check seasonality.</li>
    </ul>

    <h3 class="card-title">Feature selection</h3>
    <ul>
      <li>Start with initial set of feature ~ 1500</li>
      <li>First gate</li>
      <ul>
        <li>Data preparation</li>
        <li>Feature engineering</li>
      </ul>
      <li>After exclusions ~ 1000</li>
      <li>First stage</li>
      <ul>
        <li>Assess each feature individually.</li>
        <li>Select a metric.</li>
        <li>Use 4-folds for training and 1 fold for validation.</li>
        <li>Train a shallow model with a single feature as input and compute performance in validation set.</li>
        <li>Rank individual features.</li>
        <li>Then, train a model wtih all features.</li>
        <li>Then again, rank the features.</li>
      </ul>
      <ul>
        <li>Perform recursive feature search.</li>
        <li>Use 4-folds for training and 1 fold for validation. (Validation fold must be different from previous step)</li>
        <li>For each feature in top N features, train a model and score performance on validation set.</li>
        <li>Add the best scoring features to the candidate features.</li>
      </ul>
      <li>Candidate features ~ 100</li>
      <li>Second gate</li>
      <ul>
        <li>Highly correlated features should be justified or redundant features should be removed.</li>
        <li>Future retraining starts from the candidate features.</li>
      </ul>
      <li>Second stage</li>
      <ul>
        <li>Perform 5-fold cross validation with each candidate feature.</li>
        <li>Compute shapley values on the validation set.</li>
        <li>Select stable features via union of top features across the folds.</li>
      </ul>
      <li>Stable features ~ 40</li>
    </ul>

    <h3 class="card-title">Hyperparameter tuning</h3>
    <ul>
      <li>Ex. grid search, random search, bayesian optimization.</li>
    </ul>

    <h3 class="card-title">Final model training</h3>
    <ul>
      <li>Train the model using stable features and tuned hyperparameters.</li>
      <li>Evaluate on OOS (seasonality) and OOT (final evaluation) test sets.</li>
    </ul>

    <h3 class="card-title">Monitoring</h3>
    <ul>
      <li>Partial dependency plot (PDP) assesses marginal effect of a feature to the model output.</li>
      <li>Indvidual conditional expectation (ICDE) is equivalent to PDP but for an individual data point.</li>
      <li>Feature contribution is assessed via shapley values.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>
<!-- System design END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>