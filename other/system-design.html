<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Other</h1>

<!-- System design BEGIN -->
<div class="card mb-4" id="system-design">
  <div class="card-body">
    <h2 class="card-title">System design</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#system-design-1">System design</a></li>
      <li><a href="#system-design-2">Machine learning system design</a></li>
      <br>
      <li><a href="#system-design-10">Key-value store</a></li>
      <li><a href="#system-design-11">CDN</a></li>
      <li><a href="#system-design-12">Sequencer</a></li>
      <li><a href="#system-design-13">Distributed cache</a></li>
      <li><a href="#system-design-14">Distributed message queue</a></li>
      <li><a href="#system-design-15">Pub-sub</a></li>
      <li><a href="#system-design-16">Rate limiter</a></li>
      <li><a href="#system-design-17">Blob store</a></li>
      <li><a href="#system-design-18">Distributed search</a></li>
      <li><a href="#system-design-19">Distributed task scheduler</a></li>
      <li><a href="#system-design-20">Sharded counter</a></li>
      <br>
      <li><a href="#system-design-100">Google search</a></li>
      <li><a href="#system-design-101">Twitter feed</a></li>
      <li><a href="#system-design-102">Netflix</a></li>
      <li><a href="#system-design-103">Tesla</a></li>
      <li><a href="#system-design-104">Entity linking</a></li>
      <li><a href="#system-design-105">Ad prediction</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="system-design-1">
  <div class="card-body">
    <h2 class="card-title">System design</h2>

    <h3 class="card-title">High level design</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/sd-cicd.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">Component design</h3>

  </div>
  <div class="card-footer text-muted">

  </div>
</div>

<div class="card mb-4" id="system-design-2">
  <div class="card-body">
    <h2 class="card-title">Machine learning system design</h2>

    <h3 class="card-title">High level design</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-highlevel.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">Component design</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-development-v1.png" alt="Card image cap">
    <br>
    <br>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-training-v1.png" alt="Card image cap">
    <br>
    <br>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ml-inference-batch-v1.png" alt="Card image cap">
    <br>
    <br>
    <ul>
      <li>Performce for out-of-sample and out-of-time.</li>
      <li>Features should be mostly unchanged when input data is slighly perturbed. (Could be challgenging when data contains similar/duplicate features)</li>
      <li>Interpretation should not be depending on training sample choices.</li>
    </ul>

    <h3 class="card-title">Problem definition</h3>
    <ul>
      <li>Construct ground truth.</li>
      <li>Metrics.</li>
    </ul>

    <h3 class="card-title">Data prep</h3>
    <ul>
      <li>Proportion of null/zero values across columns.</li>
      <li>Columns that should be rejected due to zero or null values.</li>
      <li>Categorical columns with high cardinality.</li>
      <li>Columns with high sparcity.</li>
      <li>Duplicate columns.</li>
      <li>Compute per-month count of rows and selected attribute to see if they make sense.</li>
      <li>Verify that join keys are consistent across tables.</li>
      <li>Verify that labels/values to apply exclusions are available in the tables.</li>
      <li>Verify that labels/values to apply ground truth are available in the tables.</li>
      <li>Rectify missing values in columns.</li>
      <ul>
      <li>Random missing value - value is missing for unexplained reason.</li>
      <li>Structural missing value - value is missing for a reason. (For example, the fact that it is missing means something)</li>
      <li>Engineered missing value - feature engineering introduced the missing values. (For example, divide by zero)</li>
      <li>Table join mismatch - IDs in one table were missing in another table, so missing values are created after join.</li>
    </ul>
    </ul>

    <h3 class="card-title">Data profiling</h3>
    <ul>
      <li>General statistics.</li>
      <li>Columns with large portion of missing values. (For example, > 10%)</li>
      <ul>
        <li>These columns should generally be retained for they may turn out to be quite predictive.</li>
        <li>XGBoost has build-in capability to handle missing values.</li>
      </ul>
      <li>Similar/duplicate columns. (For example, prefer one feature over another? Can use univariate analysis)</li>
      <li>Columns with consistant values should be removed because they provide no signal.</li>
      <li>Remove sensitive features from model inputs. (For example, age / gender)</li>
      <li>Data imputation (For example, NULL to 0) should rarely happens when feature is critical and will undergo feature engineering and treatment is known.</li>
    </ul>

    <h3 class="card-title">Exclusion</h3>
    <ul>
      <li>Exclude rows based on certain attributes. (This is driven by business reasons)</li>
    </ul>

    <h3 class="card-title">Ground truth construction</h3>

    <h3 class="card-title">Data split</h3>
    <ul>
      <li>Training: In-Time and In-Sample. Split into 5-folds for cross-validation.</li>
      <li>Testing: Out-of-Time test and In-Time & Out-of-Sample test.</li>
      <li>If a data about person is seen at many different dates, all data about that person must be assigned to the same split. (either Out-of-Sample or one of the folds) Otherwise, there is information leak bwetween training and validation.</li>
      <li>Final model is retrained with all 5 folds combined.</li>
    </ul>

    <h3 class="card-title">Data representativeness</h3>
    <ul>
      <li>Separate datasets by ground truth labels.</li>
      <li>Perform univariate analysis. For example, look at the distribution of samples of a key feature for both the entire dataset and the partitioned dataset. Repeat for all key features.</li>
      <li>All paritioned datasets must include sufficient volume of each ground truth labels across key features.</li>
      <li>Bin size may be increased or bins could be combined as a result of above analysis.</li>
    </ul>

    <h3 class="card-title">Model development</h3>
    <ul>
      <li>Define metric to evaluate the model.</li>
      <li>Score the model by the desired metric.</li>
      <li>Check model performace by month to check seasonality.</li>
      <li>Kubernetes based</li>
      <ul>
        <li>Make changes to code.</li>
        <li>Build, test, package the code.</li>
        <li>Build an image which includes the code package.</li>
        <li>Deploy the image to Kubenetes using tools like Skaffold / Helm.</li>
        <li>Run commands inside the image to execute the code.</li>
      </ul>
      <li>Databricks based</li>
      <ul>
        <li>Make changes to code.</li>
        <li>Build, test, package, publish the code.</li>
        <li>Import the code from the notebook.</li>
        <li>Write additional code on the notebook as needed.</li>
        <li>Run commands on the notebook execute the code.</li>
      </ul>
    </ul>

    <h3 class="card-title">Feature selection</h3>
    <ul>
      <li>Start with initial set of feature ~ 1500</li>
      <li>First gate</li>
      <ul>
        <li>Data preparation</li>
        <li>Feature engineering</li>
      </ul>
      <li>After exclusions ~ 1000</li>
      <li>First stage</li>
      <ul>
        <li>Assess each feature individually.</li>
        <li>Select a metric.</li>
        <li>Use 4-folds for training and 1 fold for validation.</li>
        <li>Train a shallow model with a single feature as input and compute performance in validation set.</li>
        <li>Rank individual features.</li>
        <li>Then, train a model wtih all features.</li>
        <li>Then again, rank the features.</li>
      </ul>
      <ul>
        <li>Perform recursive feature search.</li>
        <li>Use 4-folds for training and 1 fold for validation. (Validation fold must be different from previous step)</li>
        <li>For each feature in top N features, train a model and score performance on validation set.</li>
        <li>Add the best scoring features to the candidate features.</li>
      </ul>
      <li>Candidate features ~ 100</li>
      <li>Second gate</li>
      <ul>
        <li>Highly correlated features should be justified or redundant features should be removed.</li>
        <li>Future retraining starts from the candidate features.</li>
      </ul>
      <li>Second stage</li>
      <ul>
        <li>Perform 5-fold cross validation with each candidate feature.</li>
        <li>Compute shapley values on the validation set.</li>
        <li>Select stable features via union of top features across the folds.</li>
      </ul>
      <li>Stable features ~ 40</li>
    </ul>

    <h3 class="card-title">Hyperparameter tuning</h3>
    <ul>
      <li>Ex. grid search, random search, bayesian optimization.</li>
    </ul>

    <h3 class="card-title">Final model training</h3>
    <ul>
      <li>Train the model using stable features and tuned hyperparameters.</li>
      <li>Evaluate on OOS (seasonality) and OOT (final evaluation) test sets.</li>
    </ul>

    <h3 class="card-title">Monitoring</h3>
    <ul>
      <li>Partial dependency plot (PDP) assesses marginal effect of a feature to the model output.</li>
      <li>Indvidual conditional expectation (ICDE) is equivalent to PDP but for an individual data point.</li>
      <li>Feature contribution is assessed via shapley values.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>

<div class="card mb-4" id="system-design-10">
  <div class="card-body">
    <h2 class="card-title">Key-value store</h2>
    <ul>
      <li>Distributed hash table.</li>
      <li>Key is generated by a hash function.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Users can configure availability vs consistency.</li>
      <li>Users can write into key-value store.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
    </ul>

    <h3 class="card-title">API</h3>
    <ul>
      <li>get(key)</li>
      <li>put(key, value)</li>
    </ul>

    <h3 class="card-title">Component design</h3>

    <h4 class="card-title">Vector clock</h4>
    <ul>
      <li>A list of (node, counter) pairs.</li>
      <li>If two objects have different vector clocks, we’re able to tell whether they’re causally related or not.</li>
    </ul>

    <h4 class="card-title">Merkle tree</h4>
    <ul>
      <li>Keys are hashed and used as the leaves of the tree.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-11">
  <div class="card-body">
    <h2 class="card-title">CDN</h2>
    <ul>
      <li>Geographically distributed proxy servers.d</li>
      <li>Proxy servers are placed on the network edge.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>CDN can retrieve content from the origin servers.</li>
      <li>CDN can respond to each user’s request.</li>
      <li>If push model, origin servers can send the content to the CDN.</li>
      <li>CDN can search against a user query.</li>
      <li>CDN can update the content within peer CDN proxy servers.</li>
      <li>CDN can delete contents from cache.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <ul>
        <li>No single point of failure.</li>
      </ul>
      <li>Scalability.</li>
      <li>Performance.</li>
      <ul>
        <li>Minimize latency.</li>
      </ul>
    </ul>

    <h3 class="card-title">High level design</h3>
    <ul>
      <li>The origin server provides the URI namespace to request routing system.</li>
      <li>The origin server publishes the content to the distribution system.</li>
      <li>The distribution system distributes the content to the proxy servers and provides feedback to the request routing system.</li>
      <li>User requests the routing system for a suitable proxy server.</li>
      <li>The request routing system returns IP address of a proxy server.</li>
      <li>User requests routes through the scrubber servers for security reasons.</li>
      <li>The scrubber server forwards good traffic to the edge proxy server.</li>
      <li>The edge proxy server serves the client reques.</li>
    </ul>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/cdn1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">API</h3>
    <ul>
      <li>retrieve_content(proxyserver_id, content_type, description)</li>
      <li>deliver_content(originserver_id, server_list, content_type, description)</li>
      <li>request_content(user_id, content_type, description)</li>
      <li>search_content(proxyserver_id, content_type, description)</li>
      <li>update_content(proxyserver_id, content_type, description)</li>
    </ul>

    <h3 class="card-title">Component design</h3>

    <h4 class="card-title">Push CDN</h4>
    <ul>
      <li>Content gets sent automatically to the CDN proxy servers from the origin server.</li>
      <li>Appropriate for static content delivery.</li>
    </ul>

    <h4 class="card-title">Pull CDN</h4>
    <ul>
      <li>A CDN pulls the unavailable data from origin servers when requested by a user.</li>
      <li>Appropriate for dynamic content delivery.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-12">
  <div class="card-body">
    <h2 class="card-title">Sequencer</h2>
    <ul>
      <li>Geographically distributed proxy servers.d</li>
      <li>Proxy servers are placed on the network edge.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Generate unqiue identifier.</li>
      <li>Length is limited to 64 bits.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
    </ul>

    <h3 class="card-title">Component design</h3>

    <h4 class="card-title">UUID</h4>
    <ul>
      <li>128-bit number, which makes the primary-key indexing slower</li>
      <li>There is a chance of duplication.</li>
    </ul>

    <h4 class="card-title">Database</h4>
    <ul>
      <li>Difficult to scale for multiple data centers.</li>
    </ul>

    <h4 class="card-title">Range handler</h4>

    <h4 class="card-title">Unix timestamp</h4>

    <h4 class="card-title">Twitter Snowflake</h4>

    <h4 class="card-title">Vector clock</h4>

    <h4 class="card-title">Google TrueTime</h4>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-13">
  <div class="card-body">
    <h2 class="card-title">Distributed cache</h2>
    <ul>
      <li>Multiple cache servers coordinate to store frequently accessed data.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Insert data.</li>
      <li>Retrieve data.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
    </ul>

    <h3 class="card-title">High level design</h3>
    <ul>
      <li>Cache client: holds all the information regarding cache servers.</li>
      <li>Cache server: maintain the cache of the data.</li>
    </ul>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/distributed-cache1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">API</h3>
    <ul>
      <li>insert(key, value)</li>
      <li>retrieve(key)</li>
    </ul>

    <h3 class="card-title">Component design</h3>
    <ul>
      <li>Each cache client uses consistent hashing to identify the cache server.</li>
      <li>Each cache server has primary and replica servers.</li>
      <li>Configuration service ensures all users see consistent view of cache servers.</li>
      <li>Monitoring services log and report metrics of cache service.</li>
    </ul>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/distributed-cache2.png" alt="Card image cap">
    <br>
    <br>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-14">
  <div class="card-body">
    <h2 class="card-title">Distributed message queue</h2>
    <ul>
      <li>Component between producers and consumers.</li>
      <li>Enables asynchronous communication</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Create and delete queue.</li>
      <li>Send, retrieve, delete message.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
    </ul>

    <h3 class="card-title">High level design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/distributed-message-queue1.png" alt="Card image cap">
    <br>
    <br>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-15">
  <div class="card-body">
    <h2 class="card-title">Pub-sub</h2>
    <ul>
      <li>Asynchronous service-to-service communication.</li>
      <li>Producers and consumers are disconnected and operate independently.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Create and subscribe topic.</li>
      <li>Read, write, and delete message.</li>
      <li>Specify retention time.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
    </ul>

    <h3 class="card-title">High level design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/pub-sub1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">API</h3>
    <ul>
      <li>create(topic_id, topic_name)</li>
      <li>write(topic_id, message)</li>
      <li>read(topic_id)</li>
      <li>subscribe(topic_id)</li>
      <li>unsubscribe(topic_id)</li>
      <li>delete_topic(topic_id)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-16">
  <div class="card-body">
    <h2 class="card-title">Rate limiter</h2>
    <ul>
      <li>Prevents DDOS attack.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Limit number of requests a client can send within time window.</li>
      <li>Make the number of requests within time window configurable.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
    </ul>

    <h3 class="card-title">High level design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/rate-limiter1.png" alt="Card image cap">
    <br>
    <br>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-17">
  <div class="card-body">
    <h2 class="card-title">Blob store</h2>
    <ul>
      <li>For write once, read many.</li>
      <li>Huge amount of unstructured data.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>Create, list, and delete container to group blobs.</li>
      <li>Create, list, update, and delete data.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
      <ul>
        <li>High data throughput.</li>
      </ul>
    </ul>

    <h3 class="card-title">Estimation</h3>

    <h4 class="card-title">Server</h4>
    <ul>
      <li>Assume</li>
      <ul>
        <li>5M active users.</li>
        <li>A single server can handle 500 connections.</li>
      </ul>
      <li>5M / 500 = 10,000 servers are needed.</li>
    </ul>

    <h4 class="card-title">Storage</h4>
    <ul>
      <li>Assume</li>
      <ul>
        <li>250,000 videos per day.</li>
        <li>Each video is 50 MB.</li>
      </ul>
      <li>250,000 * 50 MB = 12.5TB per day.</li>
    </ul>

    <h4 class="card-title">Bandwidth</h4>
    <ul>
      <li>Assume</li>
      <ul>
        <li>Each user makes 20 requests.</li>
      </ul>
      <li>12.5 TB * 8 / 86400 = 1.16 Gbps</li>
      <li>5M * 20 * 50MB * 8 = 462.96 Gbps.</li>
    </ul>

    <h3 class="card-title">High level design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/blob-store1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">API</h3>
    <ul>
      <li>create_container(container_name)</li>
      <li>put_blob(container_path, blob_bame, data)</li>
      <li>get_blob(blob_path)</li>
      <li>delete_blob(blob_path)</li>
      <li>list_blob(container_path)</li>
      <li>delete_container(container_path)</li>
      <li>list_containers(account_id)</li>
    </ul>

    <h3 class="card-title">Component design</h3>
    <ul>
      <li>Data nodes: hold the actual blob data.</li>
      <li>Master node: manages storage paths and access privileges of blobs.</li>
      <li>Monitoring service: monitors the data nodes and the master node.</li>
    </ul>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/blob-store2.png" alt="Card image cap">
    <br>
    <br>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-18">
  <div class="card-body">
    <h2 class="card-title">Distributed search</h2>
    <ul>
      <li>Crawler: fetches content and creates documents.</li>
      <li>Indexer: builds a searchable index.</li>
      <li>Searcher: responds to search queries by running the search query on the index created by the indexer..</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>User can search via queries.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
      <ul>
        <li>Users should get result quickly.</li>
      </ul>
    </ul>

    <h3 class="card-title">Estimation</h3>

    <h4 class="card-title">Server</h4>
    <ul>
      <li>Assume</li>
      <ul>
        <li>3M daily active users.</li>
        <li>A single server can handle 1000 connections.</li>
      </ul>
      <li>3M / 1,000 = 3,000 servers are needed.</li>
    </ul>

    <h4 class="card-title">Storage</h4>
    <ul>
      <li>Assume</li>
      <ul>
        <li>Single JSON is 200 KB.</li>
        <li>The number of unique terms from each document is 1000.</li>
        <li>Each term is 100 bytes.</li>
        <li>6000 videos per day.</li>
      </ul>
      <li>One video: 200 KB * 1000 * 100 bytes = 300 KB.</li>
      <li>6000 * 300 KB = 1.8 GB per day.</li>
    </ul>

    <h4 class="card-title">Bandwidth</h4>
    <ul>
      <li>Assume</li>
      <ul>
        <li>150 M queries per day.</li>
        <li>Each query is 100 bytes.</li>
        <li>Response is 4000 bytes.</li>
      </ul>
      <li>Incoming: 150 M * 100 * 8 / 86400 = 1.39 Mbps</li>
      <li>Outgoing: 150 M * 4000 * 8 / 86400 = 55.56 Mbps</li>
    </ul>

    <h3 class="card-title">High level design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/distributed-search1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">API</h3>
    <ul>
      <li>search(query)</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-19">
  <div class="card-body">
    <h2 class="card-title">Distributed task scheduler</h2>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Functional</h4>
    <ul>
      <li>User can submit tasks.</li>
      <li>User can cancel submitted tasks.</li>
      <li>User can see task status.</li>
      <li>CPU and memory must be allocated efficiently.</li>
    </ul>

    <h4 class="card-title">Non-functional</h4>
    <ul>
      <li>Availability.</li>
      <li>Reliability.</li>
      <li>Scalability.</li>
      <li>Performance.</li>
    </ul>

    <h3 class="card-title">High level design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/distributed-task-scheduler1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">Component design</h3>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/distributed-task-scheduler2.png" alt="Card image cap">
    <br>
    <br>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>

<div class="card mb-4" id="system-design-20">
  <div class="card-body">
    <h2 class="card-title">Shared counter</h2>

  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>



























<div class="card mb-4" id="system-design-100">
  <div class="card-body">
    <h2 class="card-title">Google search</h2>
    <ul>
      <li>A general search engine like Google.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Training</h4>
    <ul>
      <li>Split training data and validation data by time.</li>
    </ul>

    <h4 class="card-title">Inference</h4>
    <ul>
      <li>Serving: low latency (50ms - 100ms) for search ranking.</li>
    </ul>

    <h3 class="card-title">Estimation</h3>
    <ul>
      <li>How many websites to search from? Billions of documents.</li>
      <li>How many requests per second? 10K queries per second.</li>
      <li>Assume user is logged in and historical search data of user is available.</li>
    </ul>

    <h3 class="card-title">Metric</h3>

    <h4 class="card-title">Online</h4>
    <ul>
      <li>Click through rate</li>
      <ul>
        <li>(number of clicks / number of impressions or views)</li>
        <li>Unsuccessful clicks would also be part of this metric.</li>
      </ul>
      <li>Session success rate</li>
      <ul>
        <li>Dwell time: time user spent viewing a page after clicking a link.</li>
        <li>(number of sucessful sessions (dwell time &gt; 10s) / number of total sessions)</li>
        <li>Does not capture zero-click searches.</li>
      </ul>
      <li>Time to success</li>
      <ul>
        <li>Number of queries per session.</li>
        <li>Low number of queries means the system was good at guessing what user wanted.</li>
      </ul>
    </ul>

    <h4 class="card-title">Offline</h4>
    <ul>
      <li>Ground truth: actual outputs desired by the system. In this case, it is the rating provided by humans.</li>
      <li>Assume the search engine returns documents \( D1, D2, D3, D4 \) in the order of relevance.</li>
      <li>Assume human rates the documents on scale of 0-3 (3 is highly relevant, 0 is merely relevant) such that</li>
      <ul>
        <li>\( D1=3, D2=2, D3=3, D4=0 \)</li>
      </ul>
      <li>Cumulative gain simply adds</li>
      <ul>
        <li>\( 3 + 2 + 3 + 0 = 8 \)</li>
      </ul>
      <li>Discounted cumulative gain (DCG) penalizes if highly relevant document appears lower in the result.</li>
      <ul>
        <li>\( \frac{3}{log(1+1)} + \frac{2}{log(2+1)} + \frac{3}{log(3+1)} + \frac{0}{log(4+1)} = 3 + 1.262 + 1.5 + 0 = 5.762 \)</li>
      </ul>
      <li>Discounted cumulative gain for a query with long result will be higher due to its length rather than its quality.</li>
      <li>Normalized discounted cumulative gain (NDCG) is computed by (DCG / IDCG) where IDCG is DCG of ideal ordering.</li>
      <ul>
        <li>Near 1 means good result. Near 0 means bad result.</li>
        <li>Caveat: NDCG does not penalize irrelevant search result.</li>
      </ul>
    </ul>

    <h3 class="card-title">Architecture</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/google-search1.png" alt="Card image cap">
    <br>
    <br>

    <h4 class="card-title">Query rewriting</h4>
    <ul>
      <li>Spell checker: fix basic spelling mistakes.</li>
      <li>Query expansion: add terms to user query. For example, "restaurant" is expaneded to "food" or "recipe".</li>
    </ul>

    <h4 class="card-title">Query understanding</h4>
    <ul>
      <li>Query "gas stations" most likely has local intent.</li>
      <li>Query "earthquake" may have newsy intent.</li>
    </ul>

    <h4 class="card-title">Document selection</h4>
    <ul>
      <li>Focuses on recall.</li>
      <li>Select set of documents that are relevant to query.</li>
    </ul>

    <h4 class="card-title">Ranker</h4>
    <ul>
      <li>Find the best order of documents.</li>
    </ul>

    <h4 class="card-title">Blender</h4>
    <ul>
      <li>Provides various results like posts, images, news, videos.</li>
      <li>Avoid displaying results from a single or few sources.</li>
      <li>Outputs final result page to users.</li>
    </ul>

    <h4 class="card-title">Training data generation</h4>
    <ul>
      <li>Generate positive and negative example from online data.</li>
    </ul>

    <h4 class="card-title">Feature pipeline</h4>
    <ul>
      <li>Process online features.</li>
    </ul>

    <h4 class="card-title">Feature store</h4>
    <ul>
      <li>Need low latency (<10ms) to access features before scoring. (MySQL, Redis, DynamoDB)</li>
    </ul>

    <h4 class="card-title">Model Store</h4>
    <ul>
      <li>Distributed storage like S3</li>
    </ul>

    <h3 class="card-title">Feature engineering</h3>

    <h4 class="card-title">Searcher (Assume the user is logged in)</h4>
    <ul>
      <li>Age</li>
      <li>Gender</li>
      <li>Interest</li>
    </ul>

    <h4 class="card-title">Query</h4>
    <ul>
      <li>History</li>
      <ul>
        <li>For example, query "earthquake" historically was related to recent news.</li>
      </ul>
      <li>Intent</li>
      <ul>
        <li>For example, query "Pizza places" has "local" intent, thus should give higher rank to pizza places located nearby the searcher.</li>
      </ul>
    </ul>

    <h4 class="card-title">Document</h4>
    <ul>
      <li>Page rank</li>
      <ul>
        <li>For example, the number of quality documents that link to it.</li>
      </ul>
      <li>Radius</li>
      <ul>
        <li>For example, coffee shop in Toronto is relevant to people in 10km radicus but Eiffel tower has global scope.</li>
      </ul>
    </ul>

    <h4 class="card-title">Context</h4>
    <ul>
      <li>Time of day</li>
      <ul>
        <li>For example, query "restaurant" should consider restaurant open at the time of query.</li>
      </ul>
      <li>Recent query</li>
      <ul>
        <li>Take a look at previous quries. For example, "python" -> "python list"</li>
      </ul>
    </ul>

    <h4 class="card-title">Searcher-document</h4>
    <ul>
      <li>Distance</li>
      <ul>
        <li>For queries regarding locations, consider distance between searcher and matching location.</li>
      </ul>
      <li>History</li>
      <ul>
        <li>For example, if searcher looked for video document in the past, then vidoe document would be more relevant to the searcher.</li>
      </ul>
    </ul>

    <h4 class="card-title">Query-document</h4>
    <ul>
      <li>Text match</li>
      <ul>
        <li>Matches in the title, metadata, content of document.</li>
      </ul>
      <li>N-gram match</li>
      <ul>
        <li>For example, "Seattle tourism guide". Find text match for the combinations of three words.</li>
        <li>TF-IDF</li>
        <ul>
          <li>TF: (Term Frequency) importance of each term in the document.</li>
          <li>IDF: (Inverse Document Frequency) how much information a particular term provides.</li>
        </ul>
      </ul>
      <li>Click rate</li>
      <ul>
        <li>User's historical engagement with document.</li>
      </ul>
      <li>Embeddings</li>
      <ul>
        <li>Find relationship between query and document.</li>
        <li>Similarity score is computed between query vector and each document vector.</li>
      </ul>
    </ul>

    <h3 class="card-title">Training data generation</h3>

    <h4 class="card-title">Binary classification (pointwise approach)</h4>
    <ul>
      <li>Document is either relevant or irrevant.</li>
      <ul>
        <li>If user spent some time in the document, mark it relevant.</li>
        <li>If user immediate backed after clicking the document, mark it irrelevant.</li>
      </ul>
      <li>We may never get enough negative examples.</li>
      <ul>
        <li>Maybe treat all document displayed in 50th page in Google as negative.</li>
      </ul>
    </ul>

    <h4 class="card-title">Train / test split</h4>
    <ul>
      <li>Use the first two weeks of data for training.</li>
      <li>Use the third week of data for validation and test.</li>
    </ul>

    <h4 class="card-title">Document ordering (pairwise approach)</h4>
    <ul>
      <li>The goal is to minimize inversion. (number of wrong orders compared to ground truth)</li>
      <li>Rank the document based on user activity on each document and use that as training data.</li>
    </ul>

    <h3 class="card-title">Document selection</h3>
    <ul>
      <li>Inverted index</li>
      <ul>
        <li>Map words to documents.</li>
      </ul>
      <li>Selection criteria</li>
      <ul>
        <li>Go to index and retrive all documents based on this criteria.</li>
      </ul>
      <li>Scoring scheme</li>
      <ul>
        <li>Personalization measures searcher's profile such as age, gender, interest, location.</li>
      </ul>
    </ul>

    <h3 class="card-title">Ranker</h3>
    <ul>
      <li>Stage1</li>
      <ul>
        <li>Find subset of document that should be passed to stage 2.</li>
        <li>Use simpler algorithm like logistic regression to do binary classification.</li>
        <li>Objective function takes pointwise approach.</li>
      </ul>
      <li>Stage2</li>
      <ul>
        <li>Perform complex algorithm like LambdaMART (If using offline NDCG, which is based on human-rated data) or LambdaRank (If using online training data) to do document ordering.</li>
        <li>Objective function takes pairwise approach.</li>
        <ul>
          <li>Get as many pairs of document in the right order as possible.</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Filter</h3>
    <ul>
      <li>Filter inappropriate result despite good user engagement.</li>
      <li>Training data can come from human raters and/or online feedback.</li>
      <li>Extra features could be considered such as</li>
      <ul>
        <li>Website historical report rate</li>
        <li>Sexually explicit terms used</li>
        <li>Domain name</li>
        <li>Website description</li>
        <li>Images used on the website</li>
      </ul>
      <li>Use classification to determine if result inappropriate or not.</li>
    </ul>

  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="system-design-101">
  <div class="card-body">
    <h2 class="card-title">Twitter feed</h2>
    <ul>
      <li>Design a Twitter feed system.</li>
      <li>Reverse chronological order fails to catch most engaging tweets due to the sheer large number of tweets.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Training</h4>
    <ul>
      <li>Retrain the models (incrementally) multiple times per day.</li>
      <li>Personalization.</li>
      <li>Avoid showing repetitive feed.</li>
    </ul>

    <h4 class="card-title">Inference</h4>
    <ul>
      <li>Feed Ranking needs to return within 50ms.</li>
      <li>Data pipelines need to run really fast.</li>
    </ul>

    <h3 class="card-title">Estimation</h3>
    <ul>
      <li>500M daily active users.</li>
      <li>1 user is connected to 100 users.</li>
      <li>User fetches the feed 10 times a day.</li>
      <ul>
        <li>We run Tweet ranking algorithm 5B times per day.</li>
      </ul>
    </ul>

    <h4 class="card-title">Storage</h4>
    <ul>
      <li>1B positive labels and 100B negative labels.</li>
      <li>Hundreds of features per data point and each row takes 500 bytes.</li>
      <li>120B rows per month.</li>
      <li>Total: 500 * 120 * 10^9 = 60 * 10^12 bytes = 60TB. Move data past 6 months to cold storage to save cost.</li>
    </ul>

    <h3 class="card-title">Metric</h3>

    <h4 class="card-title">Positive user actions</h4>
    <ul>
      <li>Time spent viewing Tweets.</li>
      <li>Liking Tweets.</li>
      <li>Re-Tweeting.</li>
      <li>Commenting on Tweets.</li>
    </ul>

    <h4 class="card-title">Negative user actions</h4>
    <ul>
      <li>Hiding Tweets.</li>
      <li>Reporting Tweets as inappropriate.</li>
    </ul>

    <h4 class="card-title">Weighted user actions</h4>
    <ul>
      <li>Not all actions are equal value.</li>
    </ul>

    <h3 class="card-title">Architecture</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/twitter-feed1.png" alt="Card image cap">
    <br>
    <br>

    <h4 class="card-title">Tweet selection</h4>
    <ul>
      <li>Fetches a pool of Tweets from the user network since the last login.</li>
    </ul>

    <h4 class="card-title">Ranker</h4>
    <ul>
      <li>Predict Tweets probability of engagement.</li>
    </ul>

    <h4 class="card-title">Training data generation</h4>
    <ul>
      <li>Each user engagement action results in positive and negative examples.</li>
    </ul>

    <h3 class="card-title">Feature engineering</h3>

    <h4 class="card-title">User-author historical relations</h4>
    <ul>
      <li>author_liked_posts_3months</li>
      <ul>
        <li>Percentage of author Tweets user liked in the last 3 months.</li>
      </ul>
      <li>author_liked_posts_count_1year</li>
      <ul>
        <li>Number of author Tweets user liked in the past one year.</li>
      </ul>
    </ul>

    <h4 class="card-title">User-author similarity</h4>
    <ul>
      <li>common_followees</li>
      <ul>
        <li>Numbers of users and hash tags followed by bothN</li>
      </ul>
      <li>topic_similarity</li>
      <ul>
        <li>Similarity between hash tags in the posts that both interacted.</li>
      </ul>
      <li>tweet_content_embedding_similarity</li>
      <ul>
        <li>Generate embedding (bag-of-words) for every user and take dot product between them.</li>
      </ul>
      <li>social_embedding_similarity</li>
      <ul>
        <li>Every user is represented by bag-of-ids (rather than bag-of-words)</li>
      </ul>
    </ul>

    <h4 class="card-title">Author influence</h4>
    <ul>
      <li>is_verified</li>
      <ul>
        <li>If author is verifiedI</li>
      </ul>
      <li>author_social_rank</li>
      <ul>
        <li>Similar to Google page rank.</li>
      </ul>
      <li>author_num_followers</li>
      <ul>
        <li>Nubmer of followers that author has.</li>
      </ul>
      <li>follower_to_following_ratio</li>
    </ul>

    <h4 class="card-title">Author Tweets historical trend</h4>
    <ul>
      <li>author_engagement_rate_3months</li>
      <ul>
        <li>(Tweets-interactions) / (Tweets-views)</li>
      </ul>
      <li>author_topic_engagement_rate_3months</li>
      <ul>
        <li>Compute similar feature above but per topic.</li>
      </ul>
    </ul>

    <h4 class="card-title">User-tweet</h4>
    <ul>
      <li>topic_similarity</li>
      <ul>
        <li>Similarity between hashtags and contents that user tweeted in the past and the Tweet itself.</li>
      </ul>
      <li>embedding_similarity</li>
      <ul>
        <li>Dot product between user and Tweet vector.</li>
      </ul>
    </ul>

    <h4 class="card-title">Tweet content</h4>
    <ul>
      <li>Tweet_length</li>
      <ul>
        <li>Concise Tweet has higher chance of getting likes.</li>
      </ul>
      <li>Tweet_recency</li>
      <ul>
        <li>People are interested in latest Tweets.</li>
      </ul>
      <li>is_image_video</li>
      <ul>
        <li>Tweets with image or video are more catchy.</li>
      </ul>
      <li>is_URL</li>
      <ul>
        <li>Tweets with URL have higher probability of engagement.</li>
      </ul>
    </ul>

    <h4 class="card-title">Tweet interaction</h4>
    <ul>
      <li>num_total_interactions</li>
      <ul>
        <li>Need to use time decay model to give proper attention to trending Tweets.</li>
      </ul>
      <li>likes_in_last_3_days</li>
      <li>comments_in_last_1_day</li>
      <li>reshares_in_last_2_hours</li>
      <li>likes_in_last_3_days_user’s_network_only</li>
      <li>comments_in_last_1_day_user’s_network_only</li>
      <li>reshares_in_last_2_hours_user’s_network_only</li>
    </ul>

    <h4 class="card-title">Context based features</h4>
    <ul>
      <li>day_of_week</li>
      <li>time_of_day</li>
      <li>current_user_location</li>
      <li>season</li>
      <li>lastest_k_tag_interactions</li>
      <li>approaching_holiday</li>
    </ul>

    <h4 class="card-title">Sparse features</h4>
    <ul>
      <li>unigrams/bigrams of a Tweet</li>
      <li>user_id</li>
      <li>tweets_id</li>
    </ul>

    <h3 class="card-title">Training data generation</h3>

    <h4 class="card-title">If single model</h4>
    <ul>
      <li>All Tweets with user interation will be postive examples.</li>
      <li>All Tweeks with only impressions will be negative examples.</li>
    </ul>

    <h4 class="card-title">If many models</h4>
    <ul>
      <li>Tweets with "likes" will be positive and Tweets without "likes" will be negative.</li>
      <li>Tweets with "comments" will be positive and Tweets without "comments" will be negative.</li>
      <li>And so on.</li>
    </ul>

    <h4 class="card-title">Balancing positive and negative examples</h4>
    <ul>
      <li>Randomly downsample to match the number of positive and negative examples.</li>
    </ul>

    <h4 class="card-title">Train/dev/test</h4>
    <ul>
      <li>Train data on one time interval and validate data on next time interval.</li>
    </ul>

    <h3 class="card-title">Tweet selection</h3>

    <h4 class="card-title">Consider new Tweets</h4>
    <ul>
      <li>Tweets generated between user's log out and log in.</li>
      <li>Previous Tweets viewed by user, which was not popular but now is popular.</li>
      <li>Previous Tweets not viewed by user while user was logged in.</li>
    </ul>

    <h4 class="card-title">User comes back after a while</h4>
    <ul>
      <li>There will be limits of Tweet data to fetch.</li>
      <li>Need to fetch certain numbers of Tweets from a pool.</li>
    </ul>

    <h4 class="card-title">Tweets outside the user network</h4>
    <ul>
      <li>Aligns with user interests.</li>
      <li>Locally/globally trending.</li>
      <li>Tweet is relevant to user's network.</li>
    </ul>

    <h3 class="card-title">Ranking</h3>
    <ul>
      <li>Given Tweets, predict probabilities of likes, comments, and re-Tweets.</li>
      <li>This is classification problem.</li>
    </ul>

    <h4 class="card-title">Logistic regression</h4>
    <ul>
      <li>Must create feature in training data manually. (Tree and NN are able to learn features)</li>
      <li>Single model to predict overall engagement or separate models to predict different types of engagement.</li>
    </ul>

    <h4 class="card-title">Deep learning</h4>
    <ul>
      <li>Hyperparameters</li>
      <ul>
        <li>Learning rate</li>
        <li>Number of hidden layers</li>
        <li>Batch size</li>
        <li>Number of epochs</li>
        <li>Dropout rate</li>
      </ul>
      <li>Multi task NN where total_loss = like_loss + comment_loss + retweet_loss</li>
      <li>Better than training sepearate network for each task because shared layers make training faster.</li>
    </ul>

    <h4 class="card-title">Stacking models</h4>
    <ul>
      <li>Use Tree and NN to generate features to use in logistic regression.</li>
      <ul>
        <li>For example, use outputs of last hidden layer as input of logistic regression.</li>
        <li>Online learning: update model based on user action.</li>
      </ul>
    </ul>

    <h3 class="card-title">Diversity</h3>
    <ul>
      <li>Introduce penalty for same authors and similar content.</li>
      <ul>
        <li>For example, add negative score for repeated author and contents.</li>
      </ul>
    </ul>

    <h3 class="card-title">Online experimentation</h3>
    <ul>
      <li>Use training and validation data to train 15 different models.</li>
      <li>Use test data to select the best model offline.</li>
      <li>Do A/B testing between the best offline model and online model.</li>
      <ul>
        <li>Before testing, retrain the best offline model with the latest data.</li>
        <li>Select 1% of users. Use existing model to one half of 1% of users. Use the best offline model to the other half of 1% of users.</li>
        <li>Compare user engagement</li>
        <ul>
          <li>Use statistical significance. (Ex. p-value)</li>
          <li>Also, consider if new model causes the system to be more complex.</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="system-design-102">
  <div class="card-body">
    <h2 class="card-title">Netflix</h2>
    <ul>
      <li>Give a user and context (time, location, etc) predict probability of engagement for each movie, and order movies.</li>
      <li>Will use implicit feedback (user watched the movie or not) rathen explicit feedback (user rated the movie) to gather large training data.</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Training</h4>
    <ul>
      <li>Train many times during the day to capture temporal changes.</li>
    </ul>

    <h4 class="card-title">Inference</h4>
    <ul>
      <li>Latency needs to be under 200ms.</li>
      <li>Balance between exploitation (relevancy) and exploration (fresh new content)</li>
    </ul>

    <h3 class="card-title">Estimation</h3>
    <ul>
      <li>1B total users.</li>
      <li>150M video views per month.</li>
      <li>10% of videos are watched from 15M recommendations.</li>
      <li>User sees 100 videos on homepage.</li>
      <li>User watches 2 out of 100 recommendations.</li>
      <li>If user does not click video in 10 minutes, it is missed recommendation.</li>
    </ul>

    <h4 class="card-title">Storage</h4>
    <ul>
      <li>15B positive labels and 750B negative labels per month.</li>
      <li>Hundreds of features per data point, costing 500 bytes.</li>
      <li>800B row of data point per month.</li>
      <li>Total: 500 * 800 * 10^9 = 4 * 10^14 bytes = 0.4PB per month. Keep old data past 6 months to cold storage to save cost.</li>
    </ul>

    <h4 class="card-title">Bandwidth</h4>
    <ul>
      <li>Generate recommendation for 10M users per second.</li>
      <li>Each request will generate ranks for 1k-10k videos.</li>
    </ul>

    <h3 class="card-title">Metric</h3>

    <h4 class="card-title">Online</h4>
    <ul>
      <li>Engagement rate: (sessions with clicks / total number of sessions)</li>
      <ul>
        <li>User may click the movie but not watch it.</li>
      </ul>
      <li>Videos watched: count videos user watched at least for some time.</li>
      <ul>
        <li>User may not finishing watching the movie because movie is uninteresting.</li>
      </ul>
      <li>Session watch time: overall time that user spent watching movies based on recommendation in a session.</li>
      <li>Use A/B testing to compare.</li>
    </ul>

    <h4 class="card-title">Offline</h4>
    <ul>
      <li>Assume 5 movies were recommended. Total movies that Netflix has are 10. And user watches 3 out of 5 movies.</li>
      <li>Mean Average Precision (mAP @ N)</li>
      <ul>
        <li>Precision = number of relevant recommendations / total number of recommendations</li>
        <li>Measures how system performs overall.</li>
        <li>\( AP@N = \frac{1}{m} \sum_{k=1}^N P(k) \cdot rel(k)  = \frac{1}{10} \cdot (1*\frac{1}{1} + 1*\frac{2}{2} + 0*\frac{2}{3} + 1*\frac{3}{4} + 0*\frac{3}{5}) = 0.275 \)</li>
      </ul>
      <li>Mean Average Recall (mAR @ N)</li>
      <ul>
        <li>Recall = number of relevant recommendations / number of all movies.</li>
        <li>Measures how many top recommendation (based on historical data) that system can put in the recommendation list.</li>
        <li>\( AR@N = \frac{1}{m} \sum_{k=1}^N R(k) \cdot rel(k)  = \frac{1}{10} \cdot (1*\frac{1}{10} + 1*\frac{2}{10} + 0*\frac{2}{10} + 1*\frac{3}{10} + 0*\frac{3}{10}) = 0.06 \)</li>
      </ul>
      <li>F1 score = \( 2 * \frac{mAP*mAR}{mAP+mAR} \)</li>
    </ul>

    <h3 class="card-title">Architecture</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/netflix1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">Feature engineering</h3>

    <h4 class="card-title">User</h4>
    <ul>
      <li>age</li>
      <li>gender</li>
      <li>language</li>
      <li>country</li>
      <li>average_session_time</li>
      <li>last_genre_watched</li>
      <li>user_actor_histogram</li>
      <ul>
        <li>Histogram showing historical interaction between users and actors in movies.</li>
      </ul>
      <li>user_genre_histogram</li>
      <li>user_language_histogram</li>
    </ul>

    <h4 class="card-title">Context</h4>
    <ul>
      <li>season_of_the_year</li>
      <li>upcoming_holiday</li>
      <li>days_to_upcoming_holiday</li>
      <li>time_of_day</li>
      <li>day_of_week</li>
      <li>device</li>
    </ul>

    <h4 class="card-title">Media</h4>
    <ul>
      <li>public-platform-rating</li>
      <li>revenue</li>
      <li>time_passed_since_release_date</li>
      <li>time_on_platform</li>
      <li>media_watch_history</li>
      <li>genre</li>
      <li>movie_duration</li>
      <li>content_set_time_period</li>
      <li>content_tags</li>
      <li>show_season_number</li>
      <li>country_of_origin</li>
      <li>release_country</li>
      <li>release_year</li>
      <li>release_type</li>
      <li>maturity_rating</li>
    </ul>

    <h4 class="card-title">User-media</h4>
    <ul>
      <li>user_genre_historical_interaction_3months</li>
      <li>user_genre_historical_interaction_1year</li>
      <li>user_and_movie_embedding_similarity</li>
      <li>user_actor</li>
      <li>user_director</li>
      <li>user_language_match</li>
      <li>user_age_match</li>
    </ul>

    <h4 class="card-title">Sparse feature</h4>
    <ul>
      <li>movie_id</li>
      <li>title_of_media</li>
      <li>synopsis</li>
      <li>original_title</li>
      <li>distributor</li>
      <li>creator</li>
      <li>original_language</li>
      <li>director</li>
      <li>first_release_year</li>
      <li>music_composer</li>
      <li>actors</li>
    </ul>

    <h3 class="card-title">Training data generation</h3>
    <ul>
      <li>User watched 80% or more of the movie? positive example.</li>
      <li>User watched 10% or less of the movie? negative example.</li>
      <li>Between 10% and 80%? uncertain example.</li>
      <li>Make sure to downsample over-represented class.</li>
    </ul>

    <h3 class="card-title">Candidate generation</h3>
    <ul>
      <li>Select top K movies to recommend to user.</li>
      <li>Focuses on recall.</li>
    </ul>

    <h4 class="card-title">Collaborative filtering</h4>
    <ul>
      <li>Find similar users to active user based on historical watches.</li>
      <li>User and media profiles do not require domain knowledge.</li>
      <li>Has cold start problem</li>
      <ul>
        <li>It is hard to find similar users to current user who had historical interactions.</li>
        <li>Cannot recommend new movies because they do not have user feedback yet.</li>
      </ul>
    </ul>

    <h4 class="card-title">Nearest neighborhood</h4>
    <ul>
      <li>Computationally expensive.</li>
      <li>Task is to predict the feedback for movies that users haven't watched.</li>
    </ul>

    <h4 class="card-title">Content-based filtering</h4>
    <ul>
      <li>Make recommendations based on content of media that user had already interacted with.</li>
      <li>User and media profiles require some domain knowledge. (Can get this by asking user preference when they sign up)</li>
      <li>Does not have cold start problem.</li>
    </ul>

    <h4 class="card-title">Two options for recommending media to user (Given TD-IDF representation for each movie)</h4>
    <ul>
      <li>Similarity with historical interactions.</li>
      <ul>
        <li>Recommend movies similar to movies that user watched in the past.</li>
        <li>Compute by taking dot product between movies.</li>
      </ul>
      <li>Similarity between media and user profiles.</li>
    </ul>

    <h4 class="card-title">Embedding-based similarity</h4>
    <ul>
      <li>Use deep learning to generate latent vectors/embeddings to represent both movies and users.</li>
      <li>Then, use KNN to find movies to recommend.</li>
      <li>Has cold start problem</li>
      <ul>
        <li>If any one of user or movie is new, then fewer feedbacks are available.</li>
        <li>In other words, there is lack of training example to update user and movie embedding vectors.</li>
      </ul>
    </ul>

    <h3 class="card-title">Ranking</h3>
    <ul>
      <li>Probability of user watching a media.</li>
      <li>Focuses on precision.</li>
    </ul>

    <h4 class="card-title">Logistic regression</h4>
    <ul>
      <li>When training data is limited.</li>
    </ul>

    <h4 class="card-title">Deep learning</h4>
    <ul>
      <li>When 100M data is available.</li>
    </ul>

    <h4 class="card-title">Two sparse features to consider</h4>
    <ul>
      <li>Videos user watched in the past.</li>
      <li>User's search terms.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="system-design-103">
  <div class="card-body">
    <h2 class="card-title">Tesla</h2>
    <ul>
      <li>Design a self-driving car system focusing on semantic image segmentation.</li>
    </ul>

    <h4 class="card-title">Scope</h4>
    <ul>
      <li>Object detection</li>
      <ul>
        <li>Identify objects by drawing bounding boxes.</li>
      </ul>
      <li>Semantic segmentation</li>
      <ul>
        <li>Pixel-wise classification of image.</li>
      </ul>
    </ul>

    <h4 class="card-title">Not in scope</h4>
    <ul>
      <li>Instance segementation</li>
      <ul>
        <li>Semantic segmentation does not differentiate instance of the same class.</li>
        <li>Combines object detection and semantic segmentation.</li>
        <li>Detects object and then classifies its pixels.</li>
      </ul>
      <li>Scene understanding</li>
      <li>Movement plan</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Training</h4>

    <h4 class="card-title">Inference</h4>

    <h3 class="card-title">Estimation</h3>

    <h3 class="card-title">Metric</h3>

    <h4 class="card-title">Online</h4>
    <ul>
      <li>Driver's manual intervention would be negative example.</li>
    </ul>

    <h4 class="card-title">Offline</h4>
    <ul>
      <li>Intersection over union (IoU) = (area of overlap / area of union)</li>
      <li>IoU is computed for each class, then averaged.</li>
    </ul>

    <h4 class="card-title">Historical example</h4>
    <ul>
      <li>Use expert drivers scene recording at ground truth.</li>
    </ul>

    <h3 class="card-title">Architecture</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/tesla1.png" alt="Card image cap">
    <br>
    <br>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/tesla2.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">Training data generation</h3>
    <ul>
      <li>Human labeled data.</li>
      <li>Open source dataset.</li>
      <li>GAN</li>
      <ul>
        <li>Generate new training images.</li>
      </ul>
      <li>cGAN</li>
      <ul>
        <li>Ensure generated images have different weather conditions.</li>
      </ul>
    </ul>

    <h3 class="card-title">Modeling</h3>

    <h4 class="card-title">Fully convolutional network</h4>
    <ul>
      <li>Used for semantic segmentation.</li>
      <li>Fine-tune an image classification CNN and apply pixel-wise training.</li>
      <li>First, compress information via convolutions and poolings.</li>
      <li>Then, up-sample these feature maps to predict each pixel class.</li>
    </ul>

    <h4 class="card-title">U-Net</h4>
    <ul>
      <li>Built upon FCN with modifications.</li>
      <li>Require less training examples.</li>
      <li>First, down-sample convolutional features via pooling.</li>
      <li>Then, up-sample feature maps to generate segmentation maps.</li>
    </ul>

    <h4 class="card-title">Mask R-CNN</h4>
    <ul>
      <li>Combines</li>
      <ul>
        <li>Faster R-CNN: object detectection and localization.</li>
        <li>FCN: pixel-wise instance segmentation of objects.</li>
      </ul>
    </ul>

    <h4 class="card-title">Action predictor makes movement decision based on</h4>
    <ul>
      <li>Outputs of all visual understanding subtasks.</li>
      <li>Vehicle movements based on previous scene understanding.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="system-design-104">
  <div class="card-body">
    <h2 class="card-title">Entity linking</h2>

    <h3 class="card-title">Problem</h3>
    <ul>
      <li>Named entity recognition</li>
      <ul>
        <li>Detect person, organization, location, etc.</li>
      </ul>
      <li>Disambiguation</li>
      <ul>
        <li>Map each detected entity to corresponding entity in knowledge base.</li>
        <li>For example, "Michael Jordan is a machine learning professor at UC Berkeley."</li>
        <ul>
          <li>Michael Jordan linked to the professor at the University of California, Berkeley entity in the knowledge base.</li>
          <li>UC Berkeley is linked to the University of California entity in the knowledge base.</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Training</h4>

    <h4 class="card-title">Inference</h4>

    <h3 class="card-title">Estimation</h3>

    <h3 class="card-title">Metric</h3>
    <ul>
      <li>There will be separate metric for each of three components</li>
      <ul>
        <li>Named entity recognition</li>
        <li>Disambiguation</li>
        <li>Entity linking as a whole</li>
      </ul>
    </ul>

    <h4 class="card-title">Named entity recognition (Offline)</h4>
    <ul>
      <li>Precision = number of correctly recognized named entities / number of total recognized named entitied</li>
      <li>Recall = number of correctly recognized named entities / number of named entities in corpus</li>
      <li>F1 score = \( 2 * \frac{PR}{P+R} \)</li>
    </ul>

    <h4 class="card-title">Disambiguation (Offline)</h4>
    <ul>
      <li>Recall doesn't make sense.</li>
      <li>Precision = number of mentions correctly linked / number of total mentions</li>
    </ul>

    <h4 class="card-title">Micro average (Offline)</h4>
    <ul>
      <li>Aggregates contributions of all documents to compute average.</li>
      <li>Precision = sum of TP / (sum of TP + sum of FP)</li>
      <li>Recall = sum of TP / (sum of TP + sum of FN)</li>
      <li>Micro-averaged F1-score = \( 2 * \frac{PR}{P+R} \)</li>
    </ul>

    <h4 class="card-title">Macro average (Offline)</h4>
    <ul>
      <li>Computes metrics independently for each document and takes the average.</li>
      <li>Precision = sum of Precision over documents / n</li>
      <li>Recall = sum of Recall over documents / n</li>
      <li>Macro-averaged F1-score = \( 2 * \frac{PR}{P+R} \)</li>
    </ul>

    <h3 class="card-title">Architecture</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/entity-linking1.png" alt="Card image cap">
    <br>
    <br>

    <h3 class="card-title">Training data generation</h3>
    <ul>
      <li>Named entity recognition</li>
      <ul>
        <li>CoNLL-2003</li>
      </ul>
      <li>Disambiguation</li>
      <ul>
        <li>AIDA CoNLL-YAGO Dataset</li>
      </ul>
    </ul>

    <h3 class="card-title">Modeling</h3>
    <ul>
      <li>Traditional word embedding like Word2vec does not understand the context.</li>
    </ul>

    <h4 class="card-title">ELMo (Embeddings from Language Models)</h4>
    <ul>
      <li>Starts with something like Word2vec.</li>
      <li>Raw vectors are fed into bidirectional LSTM layer.</li>
      <li>Forward and backward LSTMs are trained independently.</li>
      <li>Word representations cannot take advantage of left and right context simultaneously.</li>
    </ul>

    <h4 class="card-title">BERT (Bidirectional encoder representations from transformers)</h4>
    <ul>
      <li>Take input sentenses, which can be multiple sentences separated by SEP tag.</li>
      <li>Each word is converted to embedding and fed into transformer encoder layer.</li>
      <li>All words are processed simultaneously in the layer.</li>
      <li>Final transformer layer outputs the contextualized representation of each word.</li>
    </ul>

    <h4 class="card-title">NER modelling</h4>
    <ul>
      <li>Option 1. Use embeddings generated by BERT as features in NER modelling.</li>
      <li>Option 2. Take pre-trained models and fine-tune them based on NER dataset.</li>
    </ul>

    <h4 class="card-title">Disambiguation modeling</h4>

    <h5 class="card-title">Candidate generation</h5>
    <ul>
      <li>Build an index where terms are mapped to knowledge base entities.</li>
      <li>Index should include all terms that could possibly refer to an entity.</li>
    </ul>

    <h5 class="card-title">Linking</h5>
    <ul>
      <li>Build a model that gives the probability of a candidate being true match for a recognized entity.</li>
      <li>Inputs to this model should be represented by BERT/ELMo embeddings.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="system-design-105">
  <div class="card-body">
    <h2 class="card-title">Ad prediction</h2>
    <ul>
      <li>Predict the probability of user engagement with an AD given context (query, device, etc)</li>
    </ul>

    <h3 class="card-title">Requirement</h3>

    <h4 class="card-title">Training</h4>
    <ul>
      <li>Handle highly imbalanced data.</li>
      <li>Retrain models many times within one day.</li>
      <li>Training data and validation data is partitioned by time.</li>
    </ul>

    <h4 class="card-title">Inference</h4>
    <ul>
      <li>Low latency (50ms - 100ms) for ad prediction.</li>
      <li>Recommendation latency for ML model needs to be fast.</li>
    </ul>

    <h3 class="card-title">Estimation</h3>
    <ul>
      <li>100B ad requests per month.</li>
    </ul>

    <h4 class="card-title">Storage</h4>
    <ul>
      <li>Hundreds of features per data point and each row is 500 bytes.</li>
      <li>1B clicked ads.</li>
      <li>100 * 10^12 * 500 = 5 * 10^16 = 50PB.</li>
      <li>Use 1 week of data for training and use the next day for validation.</li>
    </ul>

    <h3 class="card-title">Metric</h3>

    <h4 class="card-title">Offline</h4>
    <ul>
      <li>AUC (Area under curve)</li>
      <ul>
        <li>Common metric for binary classification.</li>
        <li>Does not penalize how far off predicted score is from the actual label.</li>
        <li>Insensitive to well-calibrated probabilities.</li>
      </ul>
      <li>Log loss (Cross-entropy loss)</li>
      <ul>
        <li>Calibration sensitive metric.</li>
        <li>Captures what degree expected probabilities diverge from class label.</li>
        <li>Sensitive to background CTR.</li>
      </ul>
      <li>Normalized Cross-Entropy</li>
      <ul>
        <li>Predictive logloss divided by the cross-entropy of the background CTR.</li>
        <li>This way NCE is insensitive to background CTR.</li>
      </ul>
    </ul>

    <h4 class="card-title">Online</h4>
    <ul>
      <li>Revenue, which is the sum of winning bid value.</li>
      <ul>
        <li>If bid is 1 and user clicks the Ad, advertisement is charged 1.</li>
        <li>Advertiser is not charged unless users click the AD.</li>
      </ul>
      <li>Engagement.</li>
      <ul>
        <li>Click rate: ratio of user clicks to ads.</li>
        <li>Rate of particular action such as add to cart, purchase, etc.</li>
      </ul>
      <li>Counter metric</li>
      <ul>
        <li>Hide the AD.</li>
        <li>Never see the AD.</li>
        <li>Report AD as inappropriate.</li>
      </ul>
    </ul>

    <h3 class="card-title">Architecture</h3>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ad-prediction1.png" alt="Card image cap">
    <br>
    <br>
    <img class="img-fluid" class="card-img-top" src="/img/system-design/ad-prediction2.png" alt="Card image cap">
    <br>
    <br>

    <h4 class="card-title">Auction</h4>
    <ul>
      <li>AD rank score = (AD predicted score * bid)</li>
      <li>Cost per engagement = (AD rank of AD below / AD rank score) + 0.01</li>
      <li>AD will cost the minimum price that wins the auction.</li>
    </ul>

    <h4 class="card-title">When user issues a query</h4>
    <ul>
      <li>AD selection selects all ADs matching the targeting criteria and predict AD relevance score using simple model.</li>
      <li>AD selection also ranks the ADs and sends top ADs to AD prediction.</li>
      <li>AD prediction uses ML model to predict precisely calibrated score.</li>
      <li>AD auction uses bid and predicted score to pick the top most relevant ADs shown to users.</li>
    </ul>

    <h3 class="card-title">Feature engineering</h3>

    <h4 class="card-title">Ad</h4>
    <ul>
      <li>ad_id</li>
      <li>ad_content_raw_terms</li>
      <li>historical_engagement_rate</li>
      <ul>
        <li>ad_engagement_history_last_24_hrs</li>
        <li>ad_engagement_history_last_7_days</li>
      </ul>
      <li>ad_impression</li>
      <li>ad_negative_engagement_rate</li>
      <li>ad_embedding</li>
      <li>ad_age</li>
      <li>ad_bid</li>
    </ul>

    <h4 class="card-title">Advertiser</h4>
    <ul>
      <li>advertiser_domain</li>
      <li>historical_engagement_rate</li>
      <li>region_wise_engagement</li>
    </ul>

    <h4 class="card-title">User</h4>
    <ul>
      <li>user_previous_search_terms</li>
      <li>user_search_terms</li>
      <li>age</li>
      <li>gender</li>
      <li>language</li>
      <li>embedding_last_k_ads</li>
      <li>engagement_content_type</li>
      <li>engagement_days</li>
      <li>platform_time_spent</li>
      <li>region</li>
    </ul>

    <h4 class="card-title">Context</h4>
    <ul>
      <li>current_region</li>
      <li>time</li>
      <li>device</li>
      <ul>
        <li>screen_size</li>
      </ul>
    </ul>

    <h4 class="card-title">User-ad</h4>
    <ul>
      <li>embedding_similarity</li>
      <li>region_wise_engagement</li>
      <li>user_ad_category_histogram</li>
      <li>user_ad_subcategory_histogram</li>
      <li>user_gender_ad_histogram</li>
      <li>user_age_ad_histogram</li>
    </ul>

    <h4 class="card-title">User-advertiser</h4>
    <ul>
      <li>embedding_similarity</li>
      <li>user_gender_advertiser_histogram</li>
      <li>user_age_advertiser_histogram</li>
    </ul>

    <h3 class="card-title">Training data generation</h3>

    <h4 class="card-title">Positive</h4>
    <ul>
      <li>Clicks the AD.</li>
      <li>Add item to cart.</li>
    </ul>

    <h4 class="card-title">Negative</h4>
    <ul>
      <li>Ignore the AD.</li>
      <li>Negative feedback on AD.</li>
    </ul>

    <h4 class="card-title">Model recalibration</h4>
    <ul>
      <li>Downsample negative examples because it is likely that 98% of data would be negative.</li>
      <li>Recalibration is needed such that</li>
      <ul>
        <li>\( q = \frac{p}{p+\frac{1-p}{w}} \)</li>
        <li>q is re-calibrated prediction score.</li>
        <li>p is prediction in downsampling space.</li>
        <li>w is downsampling rate.</li>
      </ul>
    </ul>

    <h4 class="card-title">Train/test</h4>
    <ul>
      <li>Train on first two weeks of data and test on third week of data.</li>
    </ul>

    <h3 class="card-title">Ad selection</h3>

    <h4 class="card-title">1. Selection</h4>
    <ul>
      <li>Build an in-memory index.</li>
      <li>Issue a query to fetch all Ads that are targeted for the current user.</li>
      <ul>
        <li>Ex. Use search term, age, location, gender, etc to fetch the result.</li>
      </ul>
    </ul>

    <h4 class="card-title">2. Narrow down selection</h4>
    <ul>
      <li>Use (bid * prior cost per engagement score) to pick the top selections.</li>
      <ul>
        <li>If no prior score due to being new AD, give slightly higher score.</li>
      </ul>
    </ul>

    <h4 class="card-title">3. Rank using simple model</h4>
    <ul>
      <li>Select top K Ads from the result of the previous step.</li>
      <li>Use logistic regression or additive trees.</li>
      <li>At evaluation, Ads will be ranked basd on (bid * cost per engagement score)</li>
    </ul>

    <h3 class="card-title">Ad prediction</h3>

    <h4 class="card-title">Online learning</h4>
    <ul>
      <li>Refresh model with the latest impression and engagement at regular interval (15min, 30min, etc)</li>
      <ul>
        <li>Train base model and add new examples on top of it.</li>
        <li>Stochastic gradient descent is used.</li>
      </ul>
      <li>Generates the latest training examples using an online joiner.</li>
      <li>Training data generater takes those examples and generates right feature sets.</li>
      <li>Model trainer runs SGD with those examples.</li>
    </ul>

    <h4 class="card-title">Non-linear feature generation</h4>
    <ul>
      <li>Use additive trees and neural network to generate features.</li>
      <li>Use features from above in logistic regression.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- System design END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>