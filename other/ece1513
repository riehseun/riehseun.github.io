[L1]
Review of probability
Review of linear algebra
Introduction to TensorFlow

[L2]
K Nearest Neighbours Optimization
Maximum likelihood estimation Optimization and regularization
Tricks to improve SGD
“Tuning/debugging” optimizer
Multivariate Gaussian
Underfitting vs. overfitting

[L3]
Probabilistic interpretation of linear regression
MLE vs. MAP
Optimal regressor
Feature expansion
Decision theory

[L4]
Logistic regression
Neural networks
Backpropagation

[L5]
Multi-class classification
Learning feedforward neural networks
Bag-of-tricks for deep neural networks
Types of neural networks: convolutional neural networks, recurrent neural networks

[L6]
k-means clustering
dimensionality reduction

[L7]
PCA continued, Bayesian methods
Bayesian learning continued

[L8]
Mixture models, EM algorithm
Mixture of Gaussians, Naive Bayes and Bayesian Networks

[L9]
Bayesian networks continued
Markov Random Fields, factor graphs
Review of graphical models
Conversion between BN, MRF and FG
Inference in graphical models

[L10]
Sequence models
Hidden Markov Models (HMMs)
Review of Markov models
Examples of inference in graphical models

[L11]
HMM inference/learning
Message-passing algorithms (updated notation)

[L12]
Max-sum algorithm
Junction-tree algorithm, Loopy belief propagation

[L13]
Supervised Learning using Graphical Models
Discriminative Approach
Conditional Random Fields (CRFs)
Combining Deep Learning with Graphical Models