<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- Scikit-learn BEGIN -->
<div class="card mb-4" id="scikit-learn">
  <div class="card-body">
    <h2 class="card-title">Scikit-learn</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#scikit-learn-1">Scikit-learn</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="scikit-learn-1">
  <div class="card-body">
    <h2 class="card-title">Scikit-learn</h2>

    <h3 class="card-title">Standard data format</h3>

<pre><code class="python">from sklearn.preprocessing import scale

# Standardizing each column of pizza_data
col_standardized = scale(pizza_data)

# Column means (rounded to nearest thousandth)
col_means = col_standardized.mean(axis=0).round(decimals=3)

# Column standard deviations
col_stds = col_standardized.std(axis=0)</code></pre>

    <h3 class="card-title">Range scaling</h3>

<pre><code class="python">from sklearn.preprocessing import MinMaxScaler

default_scaler = MinMaxScaler() # the default range is [0,1]
transformed = default_scaler.fit_transform(data)

custom_scaler = MinMaxScaler(feature_range=(-2, 3))
transformed = custom_scaler.fit_transform(data)</code></pre>

    <h3 class="card-title">Robust scaling</h3>
    <ul>
      <li>Avoid being affected by outliers by using the data's median and Interquartile Range. (IQR)</li>
    </ul>

<pre><code class="python">from sklearn.preprocessing import RobustScaler

robust_scaler = RobustScaler()
transformed = robust_scaler.fit_transform(data)</code></pre>

    <h3 class="card-title">L2 normalization</h3>

<pre><code class="python">from sklearn.preprocessing import Normalizer

normalizer = Normalizer()
transformed = normalizer.fit_transform(data)</code></pre>

    <h3 class="card-title">Data imputation</h3>
    <ul>
      <li>Handles missing value.</li>
    </ul>

<pre><code class="python">from sklearn.impute import SimpleImputer

imp_mean = SimpleImputer()
transformed = imp_mean.fit_transform(data)

imp_median = SimpleImputer(strategy='median')
transformed = imp_median.fit_transform(data)

imp_frequent = SimpleImputer(strategy='most_frequent')
transformed = imp_frequent.fit_transform(data)

imp_constant = SimpleImputer(strategy='constant',
                             fill_value=-1)
transformed = imp_constant.fit_transform(data)</code></pre>

    <h3 class="card-title">PCA</h3>

<pre><code class="python">from sklearn.decomposition import PCA

pca_obj = PCA() # The value of n_component will be by default m-1
pc = pca_obj.fit_transform(data).round(3)

pca_obj = PCA(n_components=3)
pc = pca_obj.fit_transform(data).round(3)</code></pre>

    <h3 class="card-title">Class labels</h3>

<pre><code class="python">from sklearn.datasets import load_breast_cancer

bc = load_breast_cancer()
bc.data  # All the dataset values.
bc.target  # Class ID labels for each row in bc.data.
malignant = bc.data[bc.target == 0]
benign = bc.data[bc.target == 1]</code></pre>

    <h3 class="card-title">Linear regression</h3>

<pre><code class="python">from sklearn import linear_model

pizza_data  # 5x2 vector
pizza_prices  # 5x1 vector
new_pizzas  # 2x2 vector

reg = linear_model.LinearRegression()
reg.fit(pizza_data, pizza_prices)
reg.predict(new_pizzas)
reg.coef_
reg.intercept_
reg.score(pizza_data, pizza_prices)  # R2 score.</code></pre>

    <h3 class="card-title">Ridge regression</h3>

<pre><code class="python">from sklearn import linear_model

reg = linear_model.Ridge(alpha=0.1)
reg.fit(pizza_data, pizza_prices)
reg.score(pizza_data, pizza_prices)

alphas = [0.1, 0.2, 0.3]
reg = linear_model.RidgeCV(alphas=alphas)
reg.fit(pizza_data, pizza_prices)</code></pre>

    <h3 class="card-title">LASSO regression</h3>

<pre><code class="python">from sklearn import linear_model

reg = linear_model.Lasso(alpha=0.1)
reg.fit(data, labels)</code></pre>

    <h3 class="card-title">Bayesian regression</h3>

<pre><code class="python">from sklearn import linear_model

# data.shape: (150, 4)
# labels.shape: (150,)

reg = linear_model.BayesianRidge()
reg.fit(data, labels)
reg.coef_
reg.intercept_
reg.score(data, labels)
reg.alpha_
reg.lambda_</code></pre>

    <h3 class="card-title">Logistic regression</h3>

<pre><code class="python">from sklearn import linear_model

# data.shape: (569, 4)
# labels.shape: (569,)
# new_data.shape: (2, 4)

reg = linear_model.LogisticRegression()
reg.fit(data, labels)
reg.predict(new_data)

# Multiclass
reg = linear_model.LogisticRegression(
    solver='lbfgs',
    multi_class='multinomial',
    max_iter=200)
reg.fit(data, labels)
reg.predict(new_data)

# Cross-validated model
reg = linear_model.LogisticRegressionCV(
    solver='multinomial', max_iter=1000)</code></pre>

    <h3 class="card-title">Decision tree</h3>

<pre><code class="python">from sklearn import tree

clf_tree1 = tree.DecisionTreeClassifier()
reg_tree1 = tree.DecisionTreeRegressor()
clf_tree2 = tree.DecisionTreeClassifier(max_depth=8)  # max depth of 8.
reg_tree2 = tree.DecisionTreeRegressor(max_depth=5)  # max depth of 5.

# data.shape: (569, 4)
# labels.shape: (569,)
clf_tree1.fit(data, labels)</code></pre>

    <h3 class="card-title">Data split</h3>

<pre><code class="python">from sklearn.model_selection import train_test_split

# data.shape: (8, 2)
# labels.shape: (2,)

split_dataset = train_test_split(data, labels, test_size=0.375)
train_data = split_dataset[0]
test_data = split_dataset[1]
train_labels = split_dataset[2]
test_labels = split_dataset[3]

# train_data.shape: (5, 2)
# train_labels.shape: (5,)
# test_data.shape: (3, 2)
# test_labels.shape: (3,)</code></pre>

    <h3 class="card-title">Cross validation</h3>

<pre><code class="python">from sklearn import linear_model
from sklearn.model_selection import cross_val_score

clf = linear_model.LogisticRegression(max_iter=3000)
cv_score = cross_val_score(clf, data, labels, cv=3)  # k = 3.

reg = linear_model.LinearRegression()
cv_score = cross_val_score(reg, data, labels, cv=4)  # k = 4.

# Apply K-Fold CV to tune a decision tree's maximum depth.
is_clf = True  # for classification
for depth in range(3, 8):
    # Predefined data and labels
    scores = cv_decision_tree(is_clf, data, labels, depth, 5)  # k = 5.
    mean = scores.mean()  # Mean acc across folds.
    std_2 = 2 * scores.std()  # 2 std devs.</code></pre>

    <h3 class="card-title">Model evaluation</h3>

<pre><code class="python">from sklearn import metrics

reg = tree.DecisionTreeRegressor()
reg.fit(train_data, train_labels)
predictions = reg.predict(test_data)

r2 = metrics.r2_score(test_labels, predictions)
mse = metrics.mean_squared_error(test_labels, predictions)
mae = metrics.mean_absolute_error(test_labels, predictions)

clf = tree.DecisionTreeClassifier()
clf.fit(train_data, train_labels)
predictions = clf.predict(test_data)

acc = metrics.accuracy_score(test_labels, predictions)</code></pre>

    <h3 class="card-title">Grid search</h3>
    <ul>
      <li>It can be incredibly slow for larger datasets.</li>
    </ul>

<pre><code class="python">reg = linear_model.BayesianRidge()
params = {
  'alpha_1':[0.1,0.2,0.3],
  'alpha_2':[0.1,0.2,0.3]
}
reg_cv = GridSearchCV(reg, params, cv=5)
reg_cv.fit(train_data, train_labels)</code></pre>

  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- Scikit-learn END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>