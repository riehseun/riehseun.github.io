<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- Data processing BEGIN -->
<div class="card mb-4" id="data-processing">
  <div class="card-body">
    <h2 class="card-title">Data processing</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#data-processing-1">Data processing</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="data-processing-1">
  <div class="card-body">
    <h2 class="card-title">Data processing</h2>
    <ul>
      <li>DataFrame is not the most efficient data storage for the input pipeline.</li>
      <li>Randomly shuffle data before splitting it.</li>
      <li>Convert each DataFrame row into a TensorFlow Example object to optimize the input pipeline.</li>
      <li>Use TFRecords files (Which hold serialized Example objects) for efficient input pipeline storage for both the training and evaluation sets.</li>
      <li>Use Example spec to parse the serialized Examples in the input pipeline.</li>
    </ul>

<pre><code class="python">import tensorflow as tf

def add_int_features(dataset_row, feature_dict):
    int_vals = ['Store', 'Dept', 'IsHoliday', 'Size']
    for feature_name in int_vals:
        list_val = tf.train.Int64List(value=[dataset_row[feature_name]])
        feature_dict[feature_name] = tf.train.Feature(int64_list=list_val)

def add_float_features(dataset_row, feature_dict, has_labels):
    float_vals = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']
    if has_labels:
        float_vals.append('Weekly_Sales')
    for feature_name in float_vals:
        list_val = tf.train.FloatList(value=[dataset_row[feature_name]])
        feature_dict[feature_name] = tf.train.Feature(float_list=list_val)

def create_example(dataset_row, has_labels):
    feature_dict = {}
    add_int_features(dataset_row, feature_dict)
    add_float_features(dataset_row, feature_dict, has_labels)
    byte_type = dataset_row['Type'].encode()
    list_val = tf.train.BytesList(value=[byte_type])
    feature_dict['Type'] = tf.train.Feature(bytes_list=list_val)
    features_obj = tf.train.Features(feature=feature_dict)
    return tf.train.Example(features=features_obj)

# Write serialized Example objects to a TFRecords file
def write_tfrecords(dataset, has_labels, tfrecords_file):
    writer = tf.python_io.TFRecordWriter(tfrecords_file)
    for i in range(len(dataset)):
        example = create_example(dataset.iloc[i], has_labels)
        writer.write(example.SerializeToString())
    writer.close()

# train_set is the training DataFrame
write_tfrecords(train_set, 'train.tfrecords')

# eval_set is the evaluation DataFrame
write_tfrecords(eval_set, 'eval.tfrecords')

def create_example_spec(has_labels):
    example_spec = {}
    int_vals = ['Store', 'Dept', 'IsHoliday', 'Size']
    float_vals = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']
    if has_labels:
        float_vals.append('Weekly_Sales')
    for feature_name in int_vals:
        example_spec[feature_name] = tf.io.FixedLenFeature((), tf.int64)
    for feature_name in float_vals:
        example_spec[feature_name] = tf.io.FixedLenFeature((), tf.float32)
    example_spec['Type'] = tf.io.FixedLenFeature((), tf.string)
    return example_spec

def parse_features(ser_ex, example_spec, has_labels):
    parsed_features = tf.io.parse_single_example(ser_ex, example_spec)
    features = {k: parsed_features[k] for k in parsed_features if k != 'Weekly_Sales'}
    if not has_labels:
        return features
    label = parsed_features['Weekly_Sales']
    return features, label

train_file = 'train.tfrecords'
eval_file = 'eval.tfrecords'
train_dataset = tf.data.TFRecordDataset(train_file)
eval_dataset = tf.data.TFRecordDataset(eval_file)

example_spec = create_example_spec(True)
parse_fn = lambda ser_ex: parse_features(ser_ex, example_spec, True)
train_dataset = train_dataset.map(parse_fn)
eval_dataset = eval_dataset.map(parse_fn)

train_dataset = train_dataset.shuffle(421570)
eval_dataset = eval_dataset.shuffle(421570)

train_dataset = train_dataset.repeat()

train_dataset = train_dataset.batch(100)
eval_dataset = eval_dataset.batch(20)

def add_numeric_columns(feature_columns):
    numeric_features = ['Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']
    for feature_name in numeric_features:
        feature_col = tf.feature_column.numeric_column(feature_name, shape=())
        feature_columns.append(feature_col)

# Add the numeric feature columns to the list of dataset feature columns
dataset_feature_columns = []
add_numeric_columns(dataset_feature_columns)

def add_indicator_columns(final_dataset, feature_columns):
    indicator_features = ['IsHoliday', 'Type']
    for feature_name in indicator_features:
        dtype = tf.string if feature_name == 'Type' else tf.int64
        vocab_list = list(final_dataset[feature_name].unique())
        vocab_col = tf.feature_column.categorical_column_with_vocabulary_list(
                feature_name, vocab_list, dtype=dtype)
        feature_col = tf.feature_column.indicator_column(vocab_col)
        feature_columns.append(feature_col)

def add_embedding_columns(final_dataset, feature_columns):
    embedding_features = ['Store', 'Dept']
    for feature_name in embedding_features:
        vocab_list = list(final_dataset[feature_name].unique())
        vocab_feature_col = tf.feature_column.categorical_column_with_vocabulary_list(
                feature_name, vocab_list, dtype=tf.int64)
        embedding_dim = int(len(vocab_list)**0.25)
        feature_col = tf.feature_column.embedding_column(vocab_feature_col, embedding_dim)
        feature_columns.append(feature_col)

def create_feature_columns(final_dataset):
    feature_columns = []
    add_numeric_columns(feature_columns)
    add_indicator_columns(final_dataset, feature_columns)
    add_embedding_columns(final_dataset, feature_columns)
    return feature_columns

feature_columns = create_feature_columns(final_dataset)</code></pre>

  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- Data processing END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>