<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- Big data BEGIN -->
<div class="card mb-4" id="bigdata">
  <div class="card-body">
    <h2 class="card-title">Big data</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#bigdata-1">Big data basic</a></li>
      <li><a href="#bigdata-2">Big data system</a></li>
      <li><a href="#bigdata-3">YARN</a></li>
      <li><a href="#bigdata-4">Map reduce</a></li>
      <li><a href="#bigdata-5">HDFS</a></li>
      <li><a href="#bigdata-6">Parquet</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="bigdata-1">
  <div class="card-body">
    <h2 class="card-title">Big data basic</h2>

    <h3 class="card-title">Characteristics of big data</h3>
    <ul>
      <li>Volumn: sheer size of data.</li>
      <li>Variety: complexity. structural (Ex. formats), media (Ex. how data is delivered), semantic (Ex. units), availability (Ex. real-time)</li>
      <li>Velocity: speed at creating, storing, and analyzing data.</li>
      <li>Veracity: quality.</li>
      <li>Valence: connectedness.</li>
      <li>Value: benefits to business.</li>
    </ul>

    <h3 class="card-title">Why DBMS rather than file system</h3>
    <ul>
      <li>Declaritive query language.</li>
      <li>Data independence. (Applications not worrying about data formats and locations)</li>
      <li>Efficient access through optimization.</li>
      <li>Data integrity and security.</li>
      <li>Concurrent access.</li>
    </ul>

    <h3 class="card-title">BDMS</h3>
    <ul>
      <li>Flexible, semi-structure data model.</li>
      <li>Support for common big data types.</li>
      <li>A full query language.</li>
      <li>Efficient parallel query runtime.</li>
      <li>Wide range of query sizes.</li>
      <li>Continuous data ingestion.</li>
      <li>ACID is hard to maintain in BDMS, so we aim BASE (Basic Availability, Soft State, Eventual Consistency)</li>
      <li>CAP theorem: distributed system cannot simultaneously achieve consistency, availability, partition tolerance.</li>
      <li>May not guarantee consistency. (Most likely supports eventual consistency)</li>
    </ul>

    <h3 class="card-title">Semijoin (used in distributed settings)</h3>
    <ul>
      <li>A semijoin from R to S reduce data transmission cost.</li>
      <li>1. <strong>Project</strong> R on attribute A (call it R[A]).</li>
      <li>2. <strong>Step</strong> this projection from the site of R to the site of S.</li>
      <li>3. <strong>Reduce</strong> S by eliminating tuples where attribute A are not matching any value in R[A].</li>
    </ul>

  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/big-data">Big data</a>
  </div>
</div>

<div class="card mb-4" id="bigdata-2">
  <div class="card-body">
    <h2 class="card-title">Big data system</h2>

    <h3 class="card-title">Vector space model</h3>
    <ul>
      <li>Ex. document vector using inverse document frequency.</li>
      <li>Similarity function (cosine distance)</li>
      <li>Query term weighting.</li>
    </ul>

    <h3 class="card-title">Graph data model</h3>
    <ul>
      <li>Find the shortest path between two nodes.</li>
      <li>Find optimal round-trip path that must include some specific nodes.</li>
      <li>Find best "compromisable" path while cannot meet all the requirements simultaneously. (Pareto optimality)</li>
      <li>Communities: clusters within the graph with lots of edges connecting nodes within.</li>
    </ul>

    <h3 class="card-title">Data stream</h3>
    <ul>
      <li>Sequence of data records.</li>
      <li>Small window of data elements.</li>
      <li>Fast and simple computations.</li>
      <li>No interation with data source.</li>
      <li>Independent computations.</li>
      <li>Near real-time.</li>
      <li>Static: size determins time and space.</li>
      <li>Streaming: unbounded size, but finite time and space.</li>
      <li>Challenges: size and frequency of streaming data can be unpredictable, sporadic.</li>
    </ul>

    <h3 class="card-title">Lambda architecture</h3>
    <ul>
      <li>Real-time data is pushed to batch.</li>
    </ul>

    <h3 class="card-title">Data lake</h3>
    <ul>
      <li>Stores raw data.</li>
      <li>Add data model on read. (schema on read)</li>
    </ul>

    <h3 class="card-title">Data warehouse</h3>
    <ul>
      <li>Well-defined structure.</li>
      <li>Schema on write.</li>
      <li>databases are optimized for reading/writing, whereas a data warehouse is optimized for aggregation and retrieval of large data sets.</li>
      <li>In a data warehouse, data is massaged into a format and possibly combined with other data sources allowing for faster processing of complex queries.</li>
      <li>Data Mart, subset of data warehouse, serves the needs of a particular department within an organization.</li>
    </ul>

    <h3 class="card-title">Redis</h3>
    <ul>
      <li>In-memory data structure store. (string, hash, list, set, sorted set)</li>
      <li>ziplist: compresses list</li>
    </ul>

    <h3 class="card-title">Aerospike</h3>
    <ul>
      <li>Distributed NoSQL DB and key-value store.</li>
      <li>Data types: scalar, list, map, geospatial, large object.</li>
      <li>Ensures ACID.</li>
    </ul>

    <h3 class="card-title">AsterixDB</h3>
    <ul>
      <li>Designed for semi-structured data.</li>
      <li>Supports multiple query languages.</li>
    </ul>

    <h3 class="card-title">Solr</h3>
    <ul>
      <li>Large scale text data search.</li>
    </ul>

    <h3 class="card-title">Vertica</h3>
    <ul>
      <li>Relational DBMS.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/big-data">Big data</a> | <a href="https://www.educative.io/courses/introduction-to-big-data-and-hadoop">Introduction to Big Data and Hadoop</a>
  </div>
</div>

<div class="card mb-4" id="bigdata-3">
  <div class="card-body">
    <h2 class="card-title">YARN</h2>
    <ul>
      <li>Operating system of HDFS and HBase.</li>
    </ul>

    <h3 class="card-title">Resource manager</h3>
    <ul>
      <li>Applications Manager: accepts job submissions. Starts a container for ApplicationMaster. (Client job/application)</li>
      <li>Scheduler: allocates resources such as disk, CPU, and network running applications.</li>
      <ul>
        <li>FIFO scheduler: large jobs can deny small jobs from running.</li>
        <li>Capacity scheduler: each queue gets fraction of cluster resource. A queue can use other queue's capacitiy if under-utilized.</li>
        <li>Fair scheduler: allocate resources fairly to each queue with running applications.</li>
      </ul>
    </ul>

    <h3 class="card-title">Node Manager</h3>
    <ul>
      <li>Runs on every machine in the cluster.</li>
      <li>Launches containers on that machine.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/courses/introduction-to-big-data-and-hadoop">Introduction to Big Data and Hadoop</a>
  </div>
</div>

<div class="card mb-4" id="bigdata-4">
  <div class="card-body">
    <h2 class="card-title">Map reduce</h2>
    <ul>
      <li>Batch processing system.</li>
      <li>Spark should be used for interactive requirement.</li>
      <li>Distributed, parallel, fault tolerant, and scalable.</li>
      <li>Works exclusively with key-value pairs.</li>
      <li>Map</li>
      <ul>
        <li>Transforms input set of key value pairs into intermediate set of key value pairs.</li>
        <li>Performs parsing, projection, filtering.</li>
        <li>Partitions output so that one partition can be assigned to one reduce task.</li>
      </ul>
      <li>Reduce</li>
      <ul>
        <li>Transforms intermediate set of key value pairs into smaller set of key value pairs.</li>
      </ul>
    </ul>

    <h3 class="card-title">End-to-end flow</h3>
    <ol>
      <li>Resource manager creates application ID and checks such as verifying if output path exists and input splits can be successfully computed are performed</li>
      <li>Resources for running the job are copied over to HDFS in a staging directory.</li>
      <li>Job is submitted for execution.</li>
      <li>Resource manager hands the request to the YARN scheduler.</li>
      <li>ApplicationMaster is launched in a container.</li>
      <li>ApplicationMaster initializes a number of book-keeping objects.</li>
      <li>ApplicationMaster decides whether to run MapReduce in the same JVM or request containers.</li>
      <ol>
        <li>ApplicationMaster requests containers from the resource manager.</li>
        <li>ApplicationMaster contacts the node manager to start the container.</li>
      </ol>
      <li>MapReduce reports their progress to the ApplicationMaster.</li>
      <li>Once ApplicationMaster is notified of the last task completing, it marks the job status as successful.</li>
    </ol>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/courses/introduction-to-big-data-and-hadoop">Introduction to Big Data and Hadoop</a>
  </div>
</div>

<div class="card mb-4" id="bigdata-5">
  <div class="card-body">
    <h2 class="card-title">HDFS</h2>

    <h3 class="card-title">File system</h3>
    <ul>
      <li>Disk blocks is the smallest unit writable by a file system.</li>
      <li>Usually disk blocks are 512 bytes in size.</li>
      <li>File system reads/writes a couple of blocks together for efficiency.</li>
      <li>i-node has mapping between logical position in a file and a physical position on disk.</li>
    </ul>

    <h3 class="card-title">HDFS</h3>
    <ul>
      <li>Namenode: stores metadata. This is a single point of failure in HDFS.</li>
      <li>Datanode: stores actual data.</li>
      <li>Clients talk to Namenode to read/write a file.</li>
      <li>Namenode responds with the location of the right Datanodes.</li>
      <li>Clients then contact Datanodes.</li>
    </ul>

    <h3 class="card-title">HDFS weakness</h3>
    <ul>
      <li>Cannot provide low latency data access.</li>
      <li>Not suitable for numerous small files.</li>
    </ul>

    <h3 class="card-title">HDFS block</h3>
    <ul>
      <li>HDFS has a default block size of 128MB. (It is the smallest unit that Namenode can reference in its memory)</li>
      <li>The underlying physical file system isn’t divided into HDFS block-sized chunks.</li>
    </ul>

    <h3 class="card-title">Write path</h3>
    <ul>
      <li>Client buffers data on local disk, waiting for one HDFS-block worth of data to accumulate.</li>
      <li>Namenode checks for permissions and gives client the list of DataNodes to write to.</li>
      <li>Client writes to first Datanode.</li>
      <li>First Datanode writes the first portion to local repo and transport this portion to the second Datanode.</li>
      <li>Second Datanode performs the same thing, and so on.</li>
    </ul>

    <h3 class="card-title">Read path</h3>
    <ul>
      <li>Client makes an RPC call to Namenode.</li>
      <li>Namenode responds with a list of Datanode addresses for each requested block. (The list of Datanodes is sorted by proximity to the client)</li>
      <li>If a local copy of the data block is available, it is returned.</li>
      <li>Else, client connects to the nearest Datanode to retrieve the first block.</li>
      <li>Client requests the Namenode for the next batch of data blocks.</li>
    </ul>

    <h3 class="card-title">Distcp</h3>
    <ul>
      <li>Implemented as a map reduce job with no reduce phase.</li>
      <li>The mappers run in parallel across the cluster to perform the copy.</li>
      <li>Each file is copied by one map task.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.coursera.org/specializations/big-data">Big data</a>
  </div>
</div>

<div class="card mb-4" id="bigdata-6">
  <div class="card-body">
    <h2 class="card-title">Parquet</h2>
    <ul>
      <li>A columnar storage format.</li>
      <li>Deeply nested fields are stored in a truly columnar fashion.</li>
      <li>Data model is defined in schema stored within the Parquet file.</li>
    </ul>

    <h3 class="card-title">Example</h3>
    <ul>
      <li><code>required</code> - exactly one occurrence</li>
      <li><code>optional</code> - 0 or 1 occurrence</li>
      <li><code>repeated</code> - 0 or more occurrences</li>
    </ul>

<pre><code class="bash">message Car {
  required string make;
  required int year;

  repeated group part {
     required string name;
     optional int life;
     repeated string oem;
  }
}</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/courses/introduction-to-big-data-and-hadoop">Introduction to Big Data and Hadoop</a>
  </div>
</div>
<!-- Big data END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>