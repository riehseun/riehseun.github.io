<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- Spark BEGIN -->
<div class="card mb-4" id="spark">
  <div class="card-body">
    <h2 class="card-title">Spark</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#spark-1">Start basic</a></li>
      <li><a href="#spark-2">Start with Spark</a></li>
      <li><a href="#spark-3">Spark read</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="spark-1">
  <div class="card-body">
    <h2 class="card-title">Start basic</h2>
    <p class="card-text"></p>
    <h3 class="card-title">Spark</h3>
    <ul>
      <li>Resilent distributed datasets (RDD)</li>
      <li>Driver program creates RDD.</li>
      <li>Create RDD -> apply transformation -> lazily evaluated and action performed.</li>
      <ul>
        <li>Transformations will wait until actions are performed.</li>
        <li>Errors may show up in action stage, not in transformation stage.</li>
      </ul>
    </ul>

    <h3 class="card-title">Narrow transformations</h3>
    <ul>
      <li>Take place in worker nodes locally.</li>
      <li>map: apply function to each element of RDD.</li>
      <li>flatMap: map then flatten output.</li>
      <li>filter: keep only elements where function is true.</li>
      <li>coalesce: reduce number of partitions.</li>
    </ul>

    <h3 class="card-title">Wide transformations</h3>
    <ul>
      <li>Processing depends on data residing in multiple partitions distributed across worker nodes,</li>
      <li>groupByKey: (K, V) pairs => (K, list of all V)</li>
    </ul>

    <h3 class="card-title">Actions</h3>
    <ul>
      <li>collect: copy all elements to the driver.</li>
      <li>take(n): copy first n elements.</li>
      <li>reduce(func): aggregate elements with func.</li>
      <li>saveAsTextFile(filename): save to local file or HDFS.</li>
    </ul>

    <h3 class="card-title">Spark SQL</h3>
    <ul>
      <li>Enables querying structured and unstructured data through Spark.</li>
      <li>APIs for Scala, Java, Python to convert result into RDDs.</li>
      <li>Deploy business intelligence tools over Spark.</li>
    </ul>

    <h3 class="card-title">Data frames</h3>
    <ul>
      <li>Looks just like tables in relational databases.</li>
      <li>RDDs can be converted to data frames.</li>
    </ul>

    <h3 class="card-title">Spark streaming</h3>
    <ul>
      <li>sources: Kafka, Flume, HDFS, S3, etc.</li>
    </ul>

    <h3 class="card-title">Spark MLLib</h3>
    <ul>
      <li>machine learning library for Spark</li>
    </ul>

    <h3 class="card-title">Spark GraphX</h3>
    <ul>
      <li>API for graph computation.</li>
      <li>triplets: views that logically join vertex and edge properties.</li>
    </ul>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>

<div class="card mb-4" id="spark-2">
  <div class="card-body">
    <h2 class="card-title">Start with Spark</h2>
<pre><code class="bash">bin/spark-shell
# Read a file from local file system.
val data = sc.textFile("tmp/test/file")
val num = Array(1,2,3,4,5,6,7,8,9)
val NewData = sc.parallelize(num)
NewData.count()
# Type Ctrl-D to exit.</code></pre>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>

<div class="card mb-4" id="spark-3">
  <div class="card-body">
    <h2 class="card-title">Start read</h2>
<pre><code class="bash">val file = spark.read.parquet("path_to_parquet_file")
val file = spark.read.load("path_to_source_file")</code></pre>
  </div>
  <div class="card-footer text-muted">

  </div>
</div>
<!-- Spark END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>