<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- PyCaret BEGIN -->
<div class="card mb-4" id="scikit-learn">
  <div class="card-body">
    <h2 class="card-title">PyCaret</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#pycaret-1">Regression</a></li>
      <li><a href="#pycaret-2">Classification</a></li>
      <li><a href="#pycaret-3">Clustering</a></li>
      <li><a href="#pycaret-4">Anomaly detection</a></li>
      <li><a href="#pycaret-5">Natural language processing</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="pycaret-1">
  <div class="card-body">
    <h2 class="card-title">Regression</h2>

<pre><code class="python"># Importing necessary libraries

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from pycaret.datasets import get_data
from pycaret.regression import *
mpl.rcParams['figure.dpi'] = 300</code></pre>

<pre><code class="python"># Loading/Importing dataset

data = get_data('insurance')</code></pre>

<pre><code class="python"># Getting dataset info

data.info()</code></pre>

    <h3 class="card-title">Exploratory data analysis</h3>

<pre><code class="python"># Histogram of numeric variables

numeric = ['age', 'bmi', 'children', 'charges']
data[numeric].hist(bins=20, figsize = (10,5))
plt.show()</code></pre>

<pre><code class="python"># Bar charts of categorical variables

categorical = ['smoker', 'sex', 'region']
color = ['C0', 'C1', 'C2', 'C3']
fig, axes = plt.subplots(2, 2, figsize = (9,7))
axes[1,1].set_axis_off()
for ax, col in zip(axes.flatten(), categorical) :
    data[col].value_counts().plot(kind = 'bar', ax = ax, color = color)
    ax.set_xlabel(col)</code></pre>

<pre><code class="python"># Histogram of numeric&categorical features

fig, axes = plt.subplots(2, 2, figsize=(10,7))
axes[1,1].set_axis_off()
for ax, col in zip(axes.flatten(), categorical):
   sns.histplot(data, x='charges', hue=col, multiple='stack', ax=ax)</code></pre>

<pre><code class="python"># Scatter plots

cols = ['age', 'bmi', 'charges', 'smoker']
sns.pairplot(data[cols], hue='smoker')
plt.show()</code></pre>

    <h3 class="card-title">PyCaret environment</h3>

<pre><code class="python"># PyCaret environment setup.Setting different parameters in setup() function
# to prepare model training and deployment data.

reg = setup(data=data, target='charges', train_size = 0.8, session_id = 7402,
numeric_features = numeric[:-1], categorical_features = categorical,
transformation = True,silent=True, normalize = True, transform_target = True)</code></pre>

<pre><code class="python"># Printing preprocessed features

get_config('X').head()</code></pre>

<pre><code class="python">import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from pycaret.datasets import get_data
from pycaret.regression import *
mpl.rcParams['figure.dpi'] = 300
numeric = ['age', 'bmi', 'children', 'charges']
categorical = ['smoker', 'sex', 'region']
data = get_data('insurance')
reg = setup(data=data, target='charges', train_size = 0.8, session_id = 7402, numeric_features = numeric[:-1], categorical_features = categorical, transformation = True,silent=True, normalize = True, transform_target = True)
# Comparing regression models
best=compare_models(sort='RMSE')</code></pre>

    <h3 class="card-title">Building the model</h3>

<pre><code class="python"># Create the model

model = create_model('gbr', fold = 10)</code></pre>

<pre><code class="python"># Tuning the model

params = {'learning_rate': [0.01, 0.02, 0.05],
          'max_depth': [1,2, 3, 4, 5, 6, 7, 8],
          'subsample': [0.4, 0.5, 0.6, 0.7, 0.8],
          'n_estimators' : [100, 200, 300, 400, 500, 600]}
tuned_model = tune_model(model, optimize = 'RMSE',tuner_verbose=False, fold = 10,
                  custom_grid = params, n_iter = 20)</code></pre>

<pre><code class="python"># Making predictions

cols = ['age', 'bmi', 'children', 'sex_female', 'smoker_no','charges','Label']
predictions = predict_model(tuned_model)
predictions[cols].head()</code></pre>

<pre><code class="python"># Plotting model

plot_model(tuned_model, 'feature', scale = 4)
plot_model(tuned_model, 'error')</code></pre>

<pre><code class="python"># Finalizing model

final_model = finalize_model(tuned_model)

# Saving model

save_model(final_model, 'regression_model')</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pycaret-2">
  <div class="card-body">
    <h2 class="card-title">Classification</h2>

    <h3 class="card-title">Import libraries</h3>

<pre><code class="python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from pycaret.datasets import get_data
from pycaret.classification import *
mpl.rcParams['figure.dpi'] = 300</code></pre>

    <h3 class="card-title">Import dataset</h3>

<pre><code class="python">data = get_data('iris')

data.info()</code></pre>

    <h3 class="card-title">Exploratory data analysis</h3>

<pre><code class="python"># Plotting pie chart

data['species'].value_counts().plot(kind='pie')
plt.ylabel('')
plt.show()

# Plotting box plot

fig, axes = plt.subplots(2, 2, figsize = (9, 7))
for ax, col in zip(axes.flatten(), data.columns) :
  sns.boxplot(data = data, x = 'species', y = col, ax = ax)
  ax.set_xlabel('')

# Drawing color-encoded matrix

plt.figure(figsize=(8, 6))
sns.heatmap(data.corr().round(decimals=2), annot=True)
plt.show()

# Drawing scatter plots

sns.pairplot(data, hue='species')
plt.show()</code></pre>

    <h3 class="card-title">Initializing PyCaret environment</h3>

<pre><code class="python">classf = setup(data = data, target = 'species', train_size = 0.8,
normalize = True,silent=True, session_id = 3934)</code></pre>

    <h3 class="card-title">Comparing classification models</h3>

<pre><code class="python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from pycaret.datasets import get_data
from pycaret.classification import *
mpl.rcParams['figure.dpi'] = 300
data = get_data('iris')
classf = setup(data = data, target = 'species', train_size = 0.8, normalize = True,silent=True, session_id = 3934)
# Comparing classification models
compare_models(sort = 'Accuracy')</code></pre>

    <h3 class="card-title">Creating the model</h3>

<pre><code class="python">model = create_model('lda')</code></pre>

    <h3 class="card-title">Tuning the model</h3>

<pre><code class="python">model_cat = create_model('catboost', verbose = False)
params = {'iterations': np.arange(100, 1000, 100),
       'max_depth': np.arange(1, 10),
       'learning_rate': np.arange(0.01, 1, 0.01),
       'random_strength': np.arange(0.1, 1.0, 0.1),
       'l2_leaf_reg': np.arange(1, 100),
       'border_count': np.arange(1, 256)}
tuned_model = tune_model(model_cat, optimize = 'Accuracy', fold = 4, tuner_verbose = False, search_library = 'scikit-optimize', custom_grid = params, n_iter = 15)</code></pre>

    <h3 class="card-title">Making predictions</h3>

<pre><code class="python">predictions = predict_model(model)
predictions.head(10)</code></pre>

    <h3 class="card-title">Plotting the model</h3>

<pre><code class="python">plot_model(model, 'confusion_matrix')</code></pre>

    <h3 class="card-title">Finalizing and saving the model</h3>

<pre><code class="python">final_model = finalize_model(model)
save_model(final_model, 'classification_model')</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pycaret-3">
  <div class="card-body">
    <h2 class="card-title">Clustering</h2>

    <h3 class="card-title">Import libraries</h3>

<pre><code class="python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from pycaret.clustering import *
from sklearn.datasets import make_blobs
mpl.rcParams['figure.dpi'] = 300</code></pre>

    <h3 class="card-title">Generating a synthetic dataset</h3>

<pre><code class="python">cols = ['column1', 'column2', 'column3',
        'column4', 'column5']
arr = make_blobs(n_samples = 1000, n_features = 5, random_state = 20,
                 centers = 3, cluster_std = 1)
data = pd.DataFrame(data = arr[0], columns = cols)
data.head()</code></pre>

    <h3 class="card-title">Exploratory data analysis</h3>

<pre><code class="python"># Histogram

data.hist(bins = 30, figsize = (10,7), grid = False)
plt.show()

# Color-encoded matrix

plt.figure(figsize=(8, 6))
sns.heatmap(data.corr().round(decimals=2), annot=True)
plt.show()

# Scatter plot

plt.figure(figsize=(8, 6))
sns.heatmap(data.corr().round(decimals=2), annot=True)
plt.show()</code></pre>

    <h3 class="card-title">Initializing PyCaret environment</h3>

<pre><code class="python">cluster = setup(data,silent=True, session_id = 7652)</code></pre>

    <h3 class="card-title">Creating the model</h3>

<pre><code class="python">model = create_model('kmeans')

plot_model(model, 'elbow')

# After using the elbow method to find the optimal number of clusters, we train the K-means model again.
model = create_model('kmeans', num_clusters = 3)

# PCA plot

plot_model(model, 'cluster')</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pycaret-4">
  <div class="card-body">
    <h2 class="card-title">Anomaly detection</h2>

    <h3 class="card-title">Import libraries</h3>

<pre><code class="python">import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from pycaret.datasets import get_data
from pycaret.anomaly import *
mpl.rcParams['figure.dpi'] = 300</code></pre>

    <h3 class="card-title">Loading the dataset</h3>

<pre><code class="python">numeric = ['Fresh','Milk','Grocery','Frozen','Detergents_Paper','Delicassen']
categorical = ['Channel','Region']
replace_dict = { "Channel": {1: "Horeca", 2: "Retail"},
                 "Region":  {1: "Lisbon", 2: "Oporto", 3: "Other"} }
data = get_data('wholesale', verbose = False)
data.replace(replace_dict, inplace = True)
data.head(10)</code></pre>

    <h3 class="card-title">Exploratory data analysis</h3>

<pre><code class="python"># Histogram

data[numeric].hist(bins=30, figsize=(9,8), grid=False)
plt.show()

# Numeric and categorical features

fig, axes = plt.subplots(1, 2, figsize = (9,4))
for ax, col in zip(axes.flatten(), categorical):
  sns.histplot(data=data, x ='Grocery', hue=col,
                 multiple='stack', ax=ax)
plt.show()

# Box plot

fig, ax = plt.subplots(figsize = (9,7))
sns.boxplot(data=data[numeric], orient='h', ax = ax)
ax.set_xlim(0, 60000)
plt.show()

# Bar plot

fig, ax = plt.subplots(figsize = (9,7))
sns.boxplot(data=data[numeric], orient='h', ax = ax)
ax.set_xlim(0, 60000)
plt.show()

# Heatmap plot

plt.figure(figsize=(9, 7))
sns.heatmap(data.corr().round(decimals=2), annot=True)
plt.show()

# Scatter plot

cols = ['Milk', 'Grocery', 'Frozen', 'Detergents_Paper']
sns.pairplot(data, vars=cols, hue='Channel')
plt.show()</code></pre>

    <h3 class="card-title">Initializing PyCaret environment</h3>

<pre><code class="python">anomaly = setup(data, silent=True, session_id = 8477)</code></pre>

    <h3 class="card-title">Creating the model</h3>

<pre><code class="python">model = create_model('lof', fraction = 0.05)
data_assigned = assign_model(model)
data_assigned.head(10)</code></pre>

    <h3 class="card-title">Inliers and outliers</h3>

<pre><code class="python">data_inliers = data_assigned.query('Anomaly == 0')
data_outliers = data_assigned.query('Anomaly == 1')
data_outliers.head(10)</code></pre>

    <h3 class="card-title">Evaluating the model</h3>

<pre><code class="python">data_skew = data[numeric].skew()
inliers_skew = data_inliers[numeric].skew()
print("Skewness of original dataset")
print(data_skew.round(decimals=2).to_string())
print("Mean skewness %0.2f" %data_skew.mean())
print("\nSkewness of inlier dataset")
print(inliers_skew.round(decimals=2).to_string())
print("Mean skewness %0.2f" %inliers_skew.mean())</code></pre>

    <h3 class="card-title">Plotting the model</h3>

<pre><code class="python">cols = ['Milk', 'Grocery', 'Frozen', 'Detergents_Paper']
sns.pairplot(data_assigned, vars=cols, hue='Anomaly', diag_kind = 'hist')
plt.show()

plot_model(model, 'umap')</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pycaret-5">
  <div class="card-body">
    <h2 class="card-title">Natural language processing</h2>

    <h3 class="card-title">Import libraries</h3>

<pre><code class="python">import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
from wordcloud import WordCloud
from spacy.lang.en.stop_words import STOP_WORDS
from pycaret import nlp
from pycaret import classification
mpl.rcParams['figure.dpi'] = 300</code></pre>

    <h3 class="card-title">Loading the dataset</h3>

<pre><code class="python">data = pd.read_csv('bbc-text.csv')
data.head(10)

# Getting dataset info

data.info()</code></pre>

    <h3 class="card-title">Exploratory data analysis</h3>

<pre><code class="python"># Plotting the bar chart

color = ['C0', 'C1', 'C2', 'C3', 'C4']
categories = data['category'].value_counts()
categories.plot(kind = 'bar', figsize = (12,8), color = color)
plt.show()

# Plotting word cloud

wc = WordCloud(width = 1800, height = 1200, stopwords = STOP_WORDS,
     background_color = 'white', min_word_length = 3, max_words = 100)

data_tech = data.query(" category == 'tech' ")['text']
text_tech = ' '.join(data_tech.to_list())
wc_img = wc.generate(text_tech)

plt.figure(figsize = (12,8))
plt.imshow(wc_img, interpolation = 'bilinear')
plt.axis("off")
plt.show()

# Visualize word frequencies in bar chart

text = ' '.join(data['text'].to_list())
freq = wc.process_text(text)
df_freq = pd.DataFrame.from_dict(freq, orient='index', columns=['frequency'])
df_freq = df_freq.sort_values('frequency')
df_freq[-20:].plot(kind = 'barh', figsize = (10,8))

plt.show()</code></pre>

    <h3 class="card-title">Initializing NLP environment</h3>

<pre><code class="python">nlp_ = nlp.setup(data = data, target='text', session_id = 6842)
data_ = nlp.get_config('data_')
data_.head(10)</code></pre>

    <h3 class="card-title">Creating the topic model</h3>

<pre><code class="python">cols = ['Topic_0','Topic_1','Topic_2',
        'Topic_3','Topic_4','category']

lda = nlp.create_model('lda', num_topics = 5)
data_assigned = nlp.assign_model(lda)
data_assigned_ = data_assigned[cols]

data_assigned_.head(10)</code></pre>

    <h3 class="card-title">Plotting the model</h3>

<pre><code class="python">nlp.plot_model(model = lda, plot = 'topic_model')</code></pre>

    <h3 class="card-title">Classification environment setup</h3>

<pre><code class="python">classf = classification.setup(data_assigned_, target = 'category',
    fix_imbalance = True, silent=True, train_size = 0.8, session_id = 3100)</code></pre>

    <h3 class="card-title">Creating the model</h3>

<pre><code class="python">catboost = classification.create_model('catboost')</code></pre>

    <h3 class="card-title">Finalizing and saving the models</h3>

<pre><code class="python">catboost_final = classification.finalize_model(catboost)
nlp.save_model(lda, 'lda_model')
save=classification.save_model(catboost_final, 'catboost_model')</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- PyCaret END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>