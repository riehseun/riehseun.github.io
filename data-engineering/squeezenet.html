<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- SqueezeNet BEGIN -->
<div class="card mb-4" id="squeezenet">
  <div class="card-body">
    <h2 class="card-title">SqueezeNet</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#squeezenet-1">SqueezeNet</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="squeezenet-1">
  <div class="card-body">
    <h2 class="card-title">SqueezeNet</h2>
    <ul>
      <li>Memory efficient and as accurate as AlexNet.</li>
      <li>Number of parameters: P = W x H x F x C + F</li>
      <ul>
        <li>W and H are width and height of kernal.</li>
        <li>F is filters.</li>
        <li>C is input channels.</li>
      </ul>
      <li>CIFAR-10 (Canadian Institute for Advanced Research) dataset contains 60,000 color images with dimensions 32x32.</li>
      <li>Transform images to generate more data. For example, random crop followed (potentially) by a horizontal flip.</li>
      <li>To make model smaller, decrease parameters by decreasing kernel size and number of input channels.</li>
      <ul>
        <li>Uses an intermediate convolution layer, referred to as a squeeze layer.</li>
      </ul>
    </ul>

<pre><code class="python">import tensorflow as tf

class SqueezeNetModel(object):
    # Model Initialization
    def __init__(self, original_dim, resize_dim, output_size):
        self.original_dim = original_dim
        self.resize_dim = resize_dim
        self.output_size = output_size

    # Random crop and flip
    def random_crop_and_flip(self, float_image):
        crop_image = tf.compat.v1.random_crop(float_image, [self.resize_dim, self.resize_dim, 3])
        updated_image = tf.image.random_flip_left_right(crop_image)
        return updated_image

    # Data Augmentation
    def image_preprocessing(self, data, is_training):
        reshaped_image = tf.reshape(data, [3, self.original_dim, self.original_dim])
        transposed_image = tf.transpose(reshaped_image, [1, 2, 0])
        float_image = tf.cast(transposed_image, tf.float32)
        if is_training:
            updated_image = self.random_crop_and_flip(float_image)
        else:
            updated_image = tf.image.resize_image_with_crop_or_pad(float_image, self.resize_dim, self.resize_dim)
        standardized_image = tf.image.per_image_standardization(updated_image)
        return standardized_image

    # Convolution layer wrapper
    def custom_conv2d(self, inputs, filters, kernel_size, name):
        return tf.keras.layers.Conv2D(
        filters=filters,
        kernel_size=kernel_size,
        padding='same',
        activation='relu',
        name=name)(inputs)

    # SqueezeNet fire module
    def fire_module(self, inputs, squeeze_depth, expand_depth, name):
        with tf.compat.v1.variable_scope(name):
            squeezed_inputs = self.custom_conv2d(
                inputs,
                squeeze_depth,
                [1, 1],
                'squeeze')
            expand1x1 = self.custom_conv2d(
                squeezed_inputs,
                expand_depth,
                [1, 1],
                'expand1x1')
            expand3x3 = self.custom_conv2d(
                squeezed_inputs,
                expand_depth,
                [3, 3],
                'expand3x3')
            return tf.concat([expand1x1, expand3x3], axis=-1)

    # Stacked fire modules
    def multi_fire_module(self, layer, params_list):
        for params in params_list:
            layer = self.fire_module(layer, params[0], params[1], params[2])
        return layer

    # Max pooling layer wrapper
    def custom_max_pooling2d(self, inputs, name):
        return tf.keras.layers.MaxPool2D(
        pool_size=[2, 2],
        strides=2,
        name=name)(inputs)

    # Model Layers
    # inputs: [batch_size, resize_dim, resize_dim, 3]
    def model_layers(self, inputs, is_training):
        conv1 = self.custom_conv2d(inputs, 64, [3, 3], name='conv1')
        pool1 = self.custom_max_pooling2d(conv1, name='pool1')

        fire_params1 = [(32, 64, 'fire1'), (32, 64, 'fire2')]
        multi_fire1 = self.multi_fire_module(pool1, fire_params1)
        pool2 = self.custom_max_pooling2d(multi_fire1, 'pool2')

        fire_params2 = [(32, 128, 'fire3'), (32, 128, 'fire4')]
        multi_fire2 = self.multi_fire_module(pool2, fire_params2)
        dropout1 = tf.keras.layers.Dropout(rate=0.5)(multi_fire2, training=is_training)

        conv_layer = self.custom_conv2d(dropout1, self.output_size, [1, 1], 'final_conv')
        return self.get_logits(conv_layer)

    # Set up and run model training
    def run_model_setup(self, inputs, labels):
        logits = self.model_layers(inputs, is_training)
        self.probs = tf.nn.softmax(logits, name='probs')
        self.predictions = tf.math.argmax(
        self.probs, axis=-1, name='predictions')
        is_correct = tf.math.equal(tf.cast(self.predictions, tf.int32), labels)
        is_correct_float = tf.cast(is_correct, tf.float32)
        self.accuracy = tf.math.reduce_mean(is_correct_float)
        # calculate cross entropy
        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)
        self.loss = tf.math.reduce_mean(cross_entropy)
        adam = tf.compat.v1.train.AdamOptimizer()
        self.train_op = adam.minimize(self.loss, global_step=self.global_step)</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- SqueezeNet END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>