<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- Pandas BEGIN -->
<div class="card mb-4" id="pandas">
  <div class="card-body">
    <h2 class="card-title">Pandas</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#pandas-1">Pandas</a></li>
      <li><a href="#pandas-2">Exploratory data analysis</a></li>
      <li><a href="#pandas-3">Data scrubbing</a></li>
      <li><a href="#pandas-4">Pre-model algorithm</a></li>
      <li><a href="#pandas-5">Split validation</a></li>
      <li><a href="#pandas-6">Data analysis</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="pandas-1">
  <div class="card-body">
    <h2 class="card-title">Pandas</h2>

<pre><code class="python">import pandas as pd</code></pre>

    <h3 class="card-title">Series</h3>
    <ul>
      <li>Use <code>pd.Series</code> for 1-D data.</li>
    </ul>

<pre><code class="python">series = pd.Series(5)
# 0    5
# dtype: int64

series = pd.Series([1, 2, 3])
# 0    1
# 1    2
# 2    3
# dtype: int64

series = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
# a    1
# b    2
# c    3
# dtype: int64

series = pd.Series({'a':1, 'b':2, 'c':3})
# a    1
# b    2
# c    3
# dtype: int64</code></pre>

    <h3 class="card-title">DataFrame</h3>
    <ul>
      <li>Use <code>pd.DataFrame</code> for 2-D data.</li>
    </ul>

<pre><code class="python">df = pd.DataFrame([[5, 6], [1, 3]],
                  index=['r1', 'r2'],
                  columns=['c1', 'c2'])
#     c1  c2
# r1   5   6
# r2   1   3

df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4]},
                  index=['r1', 'r2'])
#     c1  c2
# r1   1   3
# r2   2   4</code></pre>

<pre><code class="python">df = pd.DataFrame([[5, 6], [1.2, 3]])
ser = pd.Series([0, 0], name='r3')

df_app = df.append(ser)
#       0  1
# 0   5.0  6
# 1   1.2  3
# r3  0.0  0

df_app = df.append(ser, ignore_index=True)
#      0  1
# 0  5.0  6
# 1  1.2  3
# 2  0.0  0</code></pre>

<pre><code class="python">df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4],
                   'c3': [5, 6]},
                  index=['r1', 'r2'])

# Drop row r1
df_drop = df.drop(labels='r1')
#     c1  c2  c3
# r2   2   4   6

# Drop columns c1, c3
df_drop = df.drop(labels=['c1', 'c3'], axis=1)
#     c2
# r1   3
# r2   4</code></pre>

    <h3 class="card-title">Combining</h3>

<pre><code class="python">df1 = pd.DataFrame({'c1':[1,2], 'c2':[3,4]},
                   index=['r1','r2'])
df2 = pd.DataFrame({'c1':[5,6], 'c2':[7,8]},
                   index=['r1','r2'])
df3 = pd.DataFrame({'c1':[5,6], 'c2':[7,8]})

concat = pd.concat([df1, df2], axis=1)
#     c1  c2  c1  c2
# r1   1   3   5   7
# r2   2   4   6   8

concat = pd.concat([df2, df1, df3])
#     c1  c2
# r1   5   7
# r2   6   8
# r1   1   3
# r2   2   4
# 0    5   7
# 1    6   8

concat = pd.concat([df1, df3], axis=1)
#      c1   c2   c1   c2
# r1  1.0  3.0  NaN  NaN
# r2  2.0  4.0  NaN  NaN
# 0   NaN  NaN  5.0  7.0
# 1   NaN  NaN  6.0  8.0</code></pre>

    <h3 class="card-title">Merging</h3>

<pre><code class="python">mlb_df1 = pd.DataFrame({'name': ['john doe', 'al smith', 'sam black', 'john doe'],
                        'pos': ['1B', 'C', 'P', '2B'],
                        'year': [2000, 2004, 2008, 2003]})
#         name pos  year
# 0   john doe  1B  2000
# 1   al smith   C  2004
# 2  sam black   P  2008
# 3   john doe  2B  2003

mlb_df2 = pd.DataFrame({'name': ['john doe', 'al smith', 'jack lee'],
                        'year': [2000, 2004, 2012],
                        'rbi': [80, 100, 12]})
#         name pos  year
# 0   john doe  1B  2000
# 1   al smith   C  2004
# 2  sam black   P  2008
# 3   john doe  2B  2003

mlb_merged = pd.merge(mlb_df1, mlb_df2)
#        name pos  year  rbi
# 0  john doe  1B  2000   80
# 1  al smith   C  2004  100</code></pre>

    <h3 class="card-title">Indexing</h3>

<pre><code class="python">df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4],
                   'c3': [5, 6]}, index=['r1', 'r2'])

col1 = df['c1']
# r1    1
# r2    2
# Name: c1, dtype: int64</code></pre>

<pre><code class="python">df = pd.DataFrame({'c1': [1, 2, 3], 'c2': [4, 5, 6],
                   'c3': [7, 8, 9]}, index=['r1', 'r2', 'r3'])

# First two rows.
df[0:2]
#     c1  c2  c3
# r1   1   4   7
# r2   2   5   8
# r3   3   6   9

# Last two rows.
df['r2':'r3']
#     c1  c2  c3
# r1   1   4   7
# r2   2   5   8

df.iloc[1]
# c1    2
# c2    5
# c3    8
# Name: r2, dtype: int64

df.iloc[[0, 2]]
#     c1  c2  c3
# r1   1   4   7
# r3   3   6   9

df.loc['r2']
# c1    2
# c2    5
# c3    8
# Name: r2, dtype: int64</code></pre>

    <h3 class="card-title">CSV</h3>

<pre><code class="python">df = pd.read_csv('data.csv')
#         name pos  HR
# 0  joe smith  2B  17
# 1  alan west   C  28
# 2   john doe   P  19

df = pd.read_csv('data.csv', index_col=0)
#           pos  HR
# name
# joe smith  2B  17
# alan west   C  28
# john doe    P  19

df = pd.read_csv('data.csv', index_col=1)
#           name  HR
# pos
# 2B   joe smith  17
# C    alan west  28
# P     john doe  19

# Write to csv.
df.to_csv('data.csv')</code></pre>

    <h3 class="card-title">JSON</h3>

<pre><code class="python">data
# {'tom june': {'pos': 'P', 'HR': 31}, 'jack doe': {'pos': '1B', 'HR': 4}}

df = pd.read_json('data.json')
#     tom june jack doe
# pos        P       1B
# HR        31        4

df = pd.read_json('data.json', orient='index')
#          pos  HR
# tom june   P  31
# jack doe  1B   4

# Write to json.
df.to_json('data.json')</code></pre>

    <h3 class="card-title">Grouping</h3>

<pre><code class="python">df
#    yearID teamID     H    R
# 0    2017    CLE  1449  818
# 1    2015    CLE  1395  669
# 2    2016    BOS  1598  878
# 3    2015    DET  1515  689
# 4    2016    DET  1476  750
# 5    2016    CLE  1435  777
# 6    2015    BOS  1495  748
# 7    2017    BOS  1461  785
# 8    2017    DET  1435  735

groups = df.groupby('yearID')
groups.get_group(2016))
#    yearID teamID     H    R
# 2    2016    BOS  1598  878
# 4    2016    DET  1476  750
# 5    2016    CLE  1435  777

groups.sum()
#            H     R
# yearID
# 2015    4405  2106
# 2016    4509  2405
# 2017    4345  2338

groups.mean()
#                  H           R
# yearID
# 2015    1468.333333  702.000000
# 2016    1503.000000  801.666667
# 2017    1448.333333  779.333333

groups.filter(lambda x: x.name > 2015)
#    yearID teamID     H    R
# 0    2017    CLE  1449  818
# 2    2016    BOS  1598  878
# 4    2016    DET  1476  750
# 5    2016    CLE  1435  777
# 7    2017    BOS  1461  785
# 8    2017    DET  1435  735</code></pre>

<pre><code class="python">groups = player_df.groupby(['yearID', 'teamID'])

groups.sum()
#                  H
# yearID teamID
# 2016   BOS     607
#        HOU     374
# 2017   BOS     441
#        HOU     337</code></pre>

    <h3 class="card-title">Feature</h3>

<pre><code class="python">df = pd.DataFrame({
  'T1': [0.1, 150.],
  'T2': [0.25, 240.],
  'T3': [0.16, 100.]})

df_ms = df.multiply([1000, 1], axis=0)
#       T1     T2     T3
# 0  100.0  250.0  160.0
# 1  150.0  240.0  100.0

df_w = df_ms.multiply([1,0.5,1])
#       T1     T2     T3
# 0  100.0  125.0  160.0
# 1  150.0  120.0  100.0

df_w.sum(axis=1))
# 0    385.0
# 1    370.0
# dtype: float64</code></pre>

    <h3 class="card-title">Filter</h3>

<pre><code class="python">df = pd.DataFrame({
  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],
  'yearID': [2016, 2016, 2016, 2016, 2017],
  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],
  'HR': [31, 39, 43, 38, 39]})

df['playerID'] == 'cruzne02'
#     playerID  yearID teamID  HR
# 0  bettsmo01    2016    BOS  31
# 1   canoro01    2016    SEA  39
# 2   cruzne02    2016    SEA  43
# 3  ortizda01    2016    BOS  38
# 4   cruzne02    2017    SEA  39

df['HR'] > 40
# 0    False
# 1    False
# 2     True
# 3    False
# 4     True
# Name: playerID, dtype: bool

df[df['HR'] > 40]
#    playerID  yearID teamID  HR
# 2  cruzne02    2016    SEA  43

df['playerID'].str.startswith('c')
#     playerID  yearID teamID  HR
# 0  bettsmo01    2016    BOS  31
# 1   canoro01    2016    SEA  39
# 2   cruzne02    2016    SEA  43
# 3  ortizda01    2016    BOS  38
# 4   cruzne02    2017    SEA  39

df['playerID'].isin(['cruzne02','ortizda01'])
# 0    False
# 1    False
# 2     True
# 3     True
# 4     True
# Name: playerID, dtype: bool

df['teamID'].isna()
# 0    False
# 1    False
# 2     True
# Name: teamID, dtype: bool</code></pre>

    <h3 class="card-title">Sort</h3>

<pre><code class="python">sort2 = df.sort_values(['yearID', 'HR'],
                       ascending=[True, False])</code></pre>

    <h3 class="card-title">Metric</h3>

<pre><code class="python">df.describe()
#             yearID         HR         RBI
# count     6.000000   6.000000    6.000000
# mean   2016.333333  24.833333   79.000000
# std       0.816497  15.341664   28.312541
# min    2015.000000   7.000000   42.000000
# 25%    2016.000000  12.750000   64.500000
# 50%    2016.500000  24.000000   73.000000
# 75%    2017.000000  37.500000   97.250000
# max    2017.000000  43.000000  119.000000

df['playerID'].value_counts(normalize=True)
# pedrodu01    0.500000
# cruzne02     0.333333
# troutmi01    0.166667
# Name: playerID, dtype: float64

df['playerID'].unique()
# array(['cruzne02', 'pedrodu01', 'troutmi01'], dtype=object)</code></pre>

    <h3 class="card-title">Plot</h3>

<pre><code class="python">df.plot(kind='line',x='yearID',y='HR')
plt.title('HR vs. Year')
plt.xlabel('Year')
plt.ylabel('HR Count')
plt.show()

df.plot(kind='bar',y='HR')
plt.ylabel('Frequency')
plt.show()

df.plot(kind='box',y='HR')
plt.show()

ax = plt.gca()  # Get current axis.
df.plot(kind='line',x='yearID',y='H',ax=ax)
df.plot(kind='line',x='yearID',y='BB', color='red', ax=ax)
plt.show()</code></pre>

  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pandas-2">
  <div class="card-body">
    <h2 class="card-title">Exploratory data analysis</h2>

<pre><code class="python">import pandas as pd
import seaborn as sns

df = pd.read_csv('listings.csv')

print(df.head())
print(df.head(10))
print(df.tail())
print(df.iloc[99])
print(df.shape)
print(df.columns)
print(df.describe())
print(df.describe(include='all'))

sns.pairplot(df,vars=['price','number_of_reviews','availability_365'])

df_corr = df.corr()
sns.heatmap(df_corr,annot=True,cmap='coolwarm')</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/machine-learning-with-python-libraries">Machine Learning with Python Libraries</a>
  </div>
</div>

<div class="card mb-4" id="pandas-3">
  <div class="card-body">
    <h2 class="card-title">Data scrubbing</h2>
    <ul>
      <li>Removing variables</li>
      <li>One-hot encoding</li>
      <li>Drop missing values</li>
      <ul>
        <li>Missing completely at random (MCAR)</li>
        <li>Missing at random (MAR)</li>
        <li>Nonignorable</li>
      </ul>
      <li>Dimension reduction</li>
    </ul>

<pre><code class="python"># Removing variables.
del df['latitude']
del df['longitude']

# One-hot encoding.
df = pd.get_dummies(df, columns = ['neighbourhood_group', 'neighbourhood'] , drop_first = True)

# Drop missing values.
df.isnull().sum()

# Fill with average value.
df['reviews_per_month'].fillna((df['reviews_per_month'].mean()),inplace=True)

# Fill with the most common value.
df['reviews_per_month'].fillna(df['reviews_per_month'].mode(),inplace=True)

# Fill with customized value. (For example, 0)
df['reviews_per_month'].fillna(0)

# Remove rows that contain missing values.
df.dropna(axis = 0, how = 'any', thresh = None, subset = None, inplace = True)</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/machine-learning-with-python-libraries">Machine Learning with Python Libraries</a>
  </div>
</div>

<div class="card mb-4" id="pandas-4">
  <div class="card-body">
    <h2 class="card-title">Pre-model algorithm</h2>

    <h3 class="card-title">PCA</h3>

<pre><code class="python"># Import libraries.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Import dataset.
df = pd.read_csv('advertising.csv')
print(df.head())

# Remove non-numerical features.
del df['Ad Topic Line']
del df['City']
del df['Country']
del df['Timestamp']
del df['Male']

# Standardize data.
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(df)
scaled_data = scaler.transform(df)

# Run PCA.
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(scaled_data)
scaled_pca = pca.transform(scaled_data)
print(scaled_data.shape)
print(scaled_pca.shape)

# Visualize the output.
plt.figure(figsize=(10,8))
legend = df['Clicked on Ad']

#Add indigo and yellow RGB colors
colors = {0: '#4B0082', 1: '#FFFF00'}
labels = {0: 'Clicked', 1: 'Did not click'}

#Use a for-loop to set color for each data point
for t in np.unique(legend):
    ix = np.where(legend == t)
    plt.scatter(scaled_pca[ix,0], scaled_pca[ix,1], c=colors[t], label=labels[t])

plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.legend()
plt.show()</code></pre>

    <h3 class="card-title">K-means clustering</h3>

<pre><code class="python"># Import libraries.
import numpy as np
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Create blobs
X, y = make_blobs(n_samples=300, n_features=2, centers=4, cluster_std=4, random_state=10)
plt.figure(figsize=(7,5))
plt.scatter(X[:, 0], X[:, 1])

# Run k-means clustering.
model = KMeans(n_clusters=4)
model.fit(X)

# Predict.
model_predict = model.predict(X)
centroids = model.cluster_centers_
print(model.cluster_centers_)

# Visualize the output.
plt.figure(figsize=(7,5))
plt.scatter(X[:, 0], X[:, 1], c=model_predict, s=50, cmap='rainbow')
plt.scatter(centroids[:, 0], centroids[:, 1], c='black', s=200, alpha=1)

# Scree plot.
distortions = []
K = range(1,10)
for k in K:
    model = KMeans(n_clusters=k)
    model.fit(X, y)
    distortions.append(model.inertia_)

#Generate plot with k on the x-axis and distortions on the y_axis using matplotlib
plt.figure(figsize=(16,8))
plt.plot(K, distortions)
plt.xlabel('k')
plt.ylabel('Distortion')
plt.show()</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/machine-learning-with-python-libraries">Machine Learning with Python Libraries</a>
  </div>
</div>

<div class="card mb-4" id="pandas-5">
  <div class="card-body">
    <h2 class="card-title">Split validation</h2>

<pre><code class="python">from sklearn.model_selection import train_test_split

import pandas as pd
df = pd.read_csv('advertising.csv')
X = df[['Daily Time Spent on Site', 'Age', 'Area Income', 'Daily Internet Usage', 'Ad Topic Line', 'Country']]
y = df['Clicked on Ad']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, shuffle=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)

X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/machine-learning-with-python-libraries">Machine Learning with Python Libraries</a>
  </div>
</div>

<div class="card mb-4" id="pandas-6">
  <div class="card-body">
    <h2 class="card-title">Data analysis</h2>

<pre><code class="python">import pandas as pd

# Read the CSV data files into DataFrames
def read_dataframes():
    train_df = pd.read_csv('weekly_sales.csv')
    features_df = pd.read_csv('features.csv')
    stores_df = pd.read_csv('stores.csv')
    return train_df, features_df, stores_df</code></pre>

    <h3 class="card-title">Merge feature</h3>

<pre><code class="python">general_features = features_df.columns
print('General Features: {}\n'.format(general_features.tolist()))

store_features = stores_df.columns
print('Store Features: {}'.format(store_features.tolist()))

merged_features = features_df.merge(stores_df, on='Store')
print(merged_features)</code></pre>

    <h3 class="card-title">Missing data</h3>
    <ul>
      <li>Pandas represents missing values with an <code>NA</code> in the DataFrame.</li>
      <li>Count the number of <code>True</code> for each feature column in the boolean DataFrame.</li>
    </ul>

<pre><code class="python">na_values = pd.isna(merged_features)  # Boolean DataFrame.
na_features = na_values.any()  # Boolean Series.
print(na_features)

print(len(na_values))
print(sum(na_values['MarkDown1']))
print(sum(na_values['CPI']))

# Drop unusable features.
markdowns = [
    'MarkDown1',
    'MarkDown2',
    'MarkDown3',
    'MarkDown4',
    'MarkDown5'
]
merged_features = merged_features.drop(columns=markdowns)
print(merged_features.columns.tolist())</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- Pandas END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>