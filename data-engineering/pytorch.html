<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.bundle.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script type="text/javascript" src="/js/include_html.js"></script>
<script type="text/javascript" src="/js/site.js"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Data Engineering</h1>

<!-- PyTorch BEGIN -->
<div class="card mb-4" id="pytorch">
  <div class="card-body">
    <h2 class="card-title">PyTorch</h2>
    <p class="card-text"></p>
    <ul class="list-unstyled mb-0">
      <li><a href="#pytorch-1">Tensorflow</a></li>
      <li><a href="#pytorch-2">Tensorflow for image</a></li>
      <li><a href="#pytorch-3">Tensorflow for CNN</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="pytorch-1">
  <div class="card-body">
    <h2 class="card-title">PyTorch basic</h2>

    <h3 class="card-title">PyTorch tensor</h3>

<pre><code class="python">import torch
# simple pytorch tensor
x = torch.tensor(3.5)

# simple arithmetic with tensors
y = x + 3</code></pre>

    <h3 class="card-title">PyTorch gradient</h3>

<pre><code class="python">import torch
# pytorch tensor
x = torch.tensor(3.5, requires_grad=True)

# y is defined as a function of x
y = (x-1) * (x-2) * (x-3)

# work out gradients
y.backward()

# what is gradient at x = 3.5
print("Numerical value of gradient:", x.grad)</code></pre>

    <h3 class="card-title">Computation graph</h3>

<pre><code class="python">import torch

# set up simple graph relating x, y and z
x = torch.tensor(3.5, requires_grad=True)
y = x*x
z = 2*y + 3

# work out gradients
z.backward()

# what is gradient at x = 3.5
print("Gradient at x = 3.5: ", x.grad)</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pytorch-2">
  <div class="card-body">
    <h2 class="card-title">Tensorflow for image</h2>
    <ul>
      <li><code>tf.io.decode_image</code> is used to load pixel values of input image.</li>
      <ul>
        <li><code>channels=1</code> means grey scale.</li>
        <li><code>channels=3</code> means RGB.</li>
        <li><code>channels=4</code> means RGBA where A indicates opacity.</li>
      </ul>
      <li><code>tf.image.resize</code> compresses or expands the image.</li>
      <li><code>map</code> rather than using a <code>for</code> loop to do image decoding in parallel across the files.</li>
    </ul>

<pre><code class="python">import tensorflow as tf

# Decode image data from a file in Tensorflow
def decode_image(filename, image_type, resize_shape, channels=0):
    value = tf.io.read_file(filename)
    if image_type == "png":
        decoded_image = tf.io.decode_png(value, channels=channels)
    elif image_type == "jpeg":
        decoded_image = tf.io.decode_jpeg(value, channels=channels)
    else:
        decoded_image = tf.io.decode_image(value, channels=channels)

    if resize_shape is not None \
        and (image_type == "png" or image_type == "jpeg"):
        decoded_image = tf.image.resize(decoded_image, resize_shape)

    return decoded_image</code></pre>

<pre><code class="python"># Return a dataset created from the image file paths
def get_dataset(image_paths, image_type, resize_shape, channels):
    filename_tensor = tf.constant(image_paths)
    dataset = tf.data.Dataset.from_tensor_slices(filename_tensor)

    def _map_fn(filename):
        return decode_image(filename, image_type,resize_shape,channels=channels)

    return dataset.map(_map_fn)

# Get the decoded image data from the input image file paths
def get_image_data(image_paths, image_type=None, resize_shape=None, channels=0):
    dataset = get_dataset(image_paths, image_type, resize_shape, channels)
    iterator =tf.compat.v1.data.make_one_shot_iterator(dataset)
    next_image = iterator.get_next()

    image_data_list = []
    with tf.compat.v1.Session() as sess:
        for i in range(len(image_paths)):
            image_data = sess.run(next_image)
            image_data_list.append(image_data)

        return image_data_list

    return image_data_list</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>

<div class="card mb-4" id="pytorch-3">
  <div class="card-body">
    <h2 class="card-title">Tensorflow for CNN</h2>

    <h3 class="card-title">MNIST</h3>
    <ul>
      <li>MNIST contains 60,000 training and 10,000 testing examples.</li>
      <li>Dataset is normalized to values between 0.0 and 1.0. (0.0 means grayscale pixel value 255 and 1.0 means grayscale pixel value 0)</li>
      <li>Each image has dimensions 28x28, so that there are 784 pixels.</li>
      <li>The label for an image is a one-hot tensor with 10 classes.</li>
    </ul>

    <h3 class="card-title">NHWC format</h3>
    <ul>
      <li>Number of image data samples (batch size)</li>
      <li>Height of each image.</li>
      <li>Width of each image.</li>
      <li>Channels per image.</li>
    </ul>

<pre><code class="python">import tensorflow as tf

class MNISTModel(object):
    # Model Initialization
    def __init__(self, input_dim, output_size):
        self.input_dim = input_dim
        self.output_size = output_size

    # CNN Layers
    def model_layers(self, inputs, is_training):
        reshaped_inputs = tf.reshape(
            inputs, [-1, self.input_dim, self.input_dim, 1])

        # Convolutional layer #1
        conv1 = tf.keras.layers.Conv2D(
            filters=32,
            kernel_size=[5, 5],
            padding='same',
            activation='relu',
            name='conv1')(reshaped_inputs)

        # Pooling layer #1
        pool1 = tf.keras.layers.MaxPool2D(
            pool_size=[2, 2],
            strides=2,
            name='pool1')(conv1)

        # Convolutional layer #2
        conv2 = tf.keras.layers.Conv2D(
            filters=64,
            kernel_size=[5, 5],
            padding='same',
            activation='relu',
            name='conv2')(pool1)

        # Pooling layer #2
        pool2 = tf.keras.layers.MaxPool2D(
            pool_size=[2, 2],
            strides=2,
            name='pool2')(conv2)

        # Fully connected layer
        hwc = pool2.shape.as_list()[1:]
        flattened_size = 0
        flattened_size = hwc[0] * hwc[1] * hwc[2]
        pool2_flat = tf.reshape(pool2, [-1, flattened_size])
        dense = tf.keras.layers.Dense(1024, activation='relu', name='dense')(pool2_flat)

        # Dropout (Applied to fully connected layer)
        dropout = tf.keras.layers.Dropout(rate=0.4)(dense, training=is_training)

        logits = tf.keras.layers.Dense(self.output_size, name='logits')(dropout)

        return logits</code></pre>
  </div>
  <div class="card-footer text-muted">
    Reference: <a href="https://www.educative.io/path/become-a-machine-learning-engineer">Become a Machine Learning Engineer</a>
  </div>
</div>
<!-- PyTorch END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>