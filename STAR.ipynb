{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f946625-5bb6-4d3f-a8c6-339f271102d3",
   "metadata": {},
   "source": [
    "# STAR\n",
    "\n",
    "- Situation\n",
    "- Task\n",
    "- Action\n",
    "- Result\n",
    "\n",
    "Shorten the sentence.\n",
    "- Ex. due to the fact that -> because\n",
    "\n",
    "Turn into numbers.\n",
    "- Ex. most, many, frequent -> 30%, 85%\n",
    "\n",
    "Explain acronym in the beginnnig.\n",
    "\n",
    "Question\n",
    "- Why do you want to work here and what are you looking for in the next role?\n",
    "- Had to prioritize between many projects?\n",
    "- Had to manage multiple responsiblities?\n",
    "- Needed information from someone who was not responsive?\n",
    "- Had to manage unexpected changes in deadlines?\n",
    "- https://www.techinterviewhandbook.org/behavioral-interview-questions/\n",
    "\n",
    "## Achievements\n",
    "\n",
    "ML infrastructure deployment automation\n",
    "- MLOps team was manually constructing five hundred yaml files to provision infrastructure for machine learnig use cases. 95% of information we provided were duplicate. \n",
    "- I wanted to automate this manul work.\n",
    "- I came up with using one config file where we supply the minimum five percent information. Then I wrote 9 scripts in python to automatically generate all those yaml files based on that one config file. \n",
    "- Use case infra provisioning, which used to take 4-6 weeks were reduced to less than 2 weeks.\n",
    "\n",
    "Enterprise DevOps pipeline feature enhancement\n",
    "- When users made mistakes in pipeline configurations, they had to go back to the beginning to raise a new Pull Request. There was no way update deployment configuration for inflight releases. This caused delays between three days to 2 weeks in deployments.\n",
    "- I wanted to allow users to update pipeline variables w/o going back to the beginning.\n",
    "- I could not allowed users to update variables in the tool itself because audit claimed that the source of truth must comes from GIT. I came up with a way to allow users to invoke a separate release which targeted the original release to update its deployment variables. This design passed the audit because that separate release will be triggered based on GIT, which we treat as source of truth.\n",
    "- User feedback was their deployment time got reduced by three to five times on average because they didn't have to go back to the beginning after releazing the mistakes in the middle of the releases.\n",
    "\n",
    "## Made current system better\n",
    "\n",
    "K8s cluster \n",
    "- The kubernetes cluster we use for model build/training/inference was not robust because it lacked monitoring and security.\n",
    "- I wanted monitoring and security integrated with K8s clusters.\n",
    "- I used helm charts to deploy datadog and kube-state-metric for monitoring and collecting metrics, and Kubernetes Reboot Daemon to automatically reboot Kubernetes nodes after the cloud provider applied the patches on the virtual machines.\n",
    "- The time to notice CPU and memory outage was cut by one day on average and we were able to solve problems before users can even notice. The time and effort to reboot Kubernetes nodes manually by checking the condition inside the machines have been eliminated.\n",
    "\n",
    "## Caculated risk and take\n",
    "\n",
    "Security Master deployment\n",
    "- We were deploying new infrastructure for a project whose load-testing was failing in non-production. We had different infrastructure t-shirt sizes between non-production and production. \n",
    "- I wanted to complete the production deployment within the given timeline.\n",
    "- I suggested that we do production deployment knowing that it is an internal application, user size is limited to the number of IT employees in the bank, which was eight thousand. The production t-shirt size was twice bigger in CPU and memory.\n",
    "-  We reviewed that we had to increase the t-shrit size in non-production so that it exactly matches the production despite the cost, in order to closely reflect what would happen in reality during non-production testing. \n",
    "\n",
    "## Build something from scratch / Most complex project\n",
    "\n",
    "Multibranch pipeline\n",
    "- Team had created jobs manually in Jenkins where scripts were embedded within the jobs. Each job was different, making it hard to manage Continuous Integration for the whole line of business.\n",
    "- I wanted systematic approach to setup the pipeline for all projects.\n",
    "- I wrote multibranch pipeline using groovy language from scratch so that every project would use the same codebase for continuous integration. And the codebase is stored in one place and updated in one place rather than each job being managed differently.\n",
    "- Each project in line of businss significatly reduced time to onboard to CI. From two weeks to one day because we established a streamlined way to configure the hooks from code repo to Jenkins and how to configure pipeline for each project in a very systemtic way.\n",
    "\n",
    "EDP local development environment\n",
    "\n",
    "## Disaggreement with team member\n",
    "\n",
    "Helm chart for API based model\n",
    "- I updated helm chart for deploying resources in Kubernetes for the real time machine learning usecases. My team member claimed that I should update all usecases that used that helm chart immediately.\n",
    "- I wanted to come up with a conclusion which we could agree upon.\n",
    "- I reasoned that there wouldn't be any difference between updating the chart version now or the next time we do the deployment. My team member still didn't agree. So, I explained the time and effort for doing the deployment, and the benefits of use cases having the lastest updated chart wouldn't exceeds the cost of doing it.\n",
    "- He came to an agreement and we ended up saving time for doing that deployment, which would be 2 days for three usecaes. \n",
    "\n",
    "## Had to pursuade the team\n",
    "\n",
    "Inner-sourcing Enterprise DevOps pipeline\n",
    "- The whole DevOps team were the users of the pipeline. Because we didn't know the internal mechanics of the pipeline,  we had to rely on support whenever we hit any issues. And the supports were very limited due to short staffing in cloud engineering. \n",
    "- I wanted the team to innersource to pipeline development.\n",
    "- I asked the team to select several individuals to inner-source to cloud engineering to work as pipeline developers. This would raise the knowledge of the team as a whole and we would be much better enabled to resolve any pipeline issues by ourselves. \n",
    "- I was selected as one of the developers to inner-source to the pipeline. I gained lot of knowledge working as a developer. When we were facing any pipeline issues, it usually took a week to resolve it. But, that now I knew the internal mechanics, each issue was resolved within one day.\n",
    "\n",
    "## Had to go beyond my responsibility\n",
    "\n",
    "Supporting Enterprise DevOps pipeline\n",
    "- I was inner-sourcing in cloud engineering, working as a developer for the enterprise pipeline. There were individuals hired to support the users of the pipeline. This support was done through an internal forum where users would ask questions and support team would answer questions. Because support engineers were not too knowledgable about the pipeline, users were complaining about the quality of support.\n",
    "- I wanted to provide much better support for the users.\n",
    "- I voluntarily started answering the question on the forum whenever I found time after finishing my development work. The forum was used by everyone in the enterprise, although the alignment was that support engineer working for a line of business would only support users in that LOB. But I supported all users of the pipeline regardless where they come from.\n",
    "- I did that to build trust, because in an enterprise settings, we often need things from each others although helping other LOBs requires time commitment. \n",
    "\n",
    "## Most challenging experience / Navigate through a difficult situation / Solve a difficult problem \n",
    "\n",
    "First ML usecase onboarding\n",
    "- In the first week of joining Layer6 AI, I was tasked to on-board infrastructure for a new use case. This is one major task for this team. I was given two weeks, which is the same time given to all other very experienced members.\n",
    "- I wanted to provision all necessary infrastrucutre for the new use case.\n",
    "- I studied the on-boarding document very carefully. Many places in the document did not make sense, so I reached out to team members asking questions and corrected the document. I noted down places for improvement, especially what we could automate. The pipeline to provision the infrastructure was failing in many different places, and rather than waiting for support engineers to fix, I investigated the codebase myself to resolve issues.\n",
    "- It tooks two weeks and two days to finish the infrasturcture on-boarding. Team said well down for it was first time for me to do it and they starting showing me trust.\n",
    " \n",
    "VMC pipeline\n",
    "- I was given a very tight deadline (2 weeks) to develop and deploy pipeline for automating the provisioning of infrastructure on private cloud. The release date was already communicated to the users in the Enterpise and cloud engineering could not find the right candidate until they gave it to me. \n",
    "- I wanted to build and release VMC provisioning feature in the pipeline in two weeks.\n",
    "- I gathered all the requirements from the stakeholders. There were lots. I realized it is impractical to target all of them and I suggested the team to deliver the requirements in phases. First of all, I would finish the infra provisioning for various middlewares (jboss, springboot, nodejs) including the core configuration of those infrastructure because those were most critical. Then, I would target allowing users to provide their own custom configuration for the infrastructure in the second phase. Then, the ability to cleanup any unused infrasture or deployment would come in third phase.\n",
    "- R: The team was still able to deliver their initial promise to end users. The end users got what they expected. And before they realized they were missing something, we filled those gaps in the next phases. \n",
    "\n",
    "# Made tradeoffs in your projects / Made short-term sacrifice for long term gain \n",
    "\n",
    "Log4J layer6 AI\n",
    "- Log4j issue hit Layer6 AI hard affecting most containers running in production in December 2021. The issue came during the weekend, so we had limited responses from the users. If we kept the containers running, we would have serious security risks of RCE (Remote Code Execution). If we just shutdown the containers, it could impact businesses.  \n",
    "- I wanted to remediate log4j situation as soon as possible.\n",
    "- I tried to reach out to all users. But seeing people didn't respond for it was a weekend, I took an intiative to tell my team that we should shutdown all the containers. It was because I determined the risk of RCE far outweighted the loss of business outputs in the next several days.\n",
    "- R: I took 3 days (including the weekend) to patch the containers and re-stood them up. Although that caused some business impacts, I still feel it was the right decision to make since Layer6 AI was not exploited by the vulnerability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b23537-9439-4ec0-9ffb-01443824d94d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9a769-d060-44f1-b6bf-942d0bd19db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
