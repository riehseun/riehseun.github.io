{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f946625-5bb6-4d3f-a8c6-339f271102d3",
   "metadata": {},
   "source": [
    "# STAR\n",
    "\n",
    "- Situation\n",
    "- Task\n",
    "- Action\n",
    "- Result\n",
    "\n",
    "Shorten the sentence.\n",
    "- Ex. due to the fact that -> because\n",
    "\n",
    "Turn into numbers.\n",
    "- Ex. most, many, frequent -> 30%, 85%\n",
    "\n",
    "Explain acronym in the beginnnig.\n",
    "\n",
    "Question\n",
    "- Had to prioritize between many projects?\n",
    "- Had to manage multiple responsiblities?\n",
    "- Had to manage unexpected changes in deadlines?\n",
    "- https://www.techinterviewhandbook.org/behavioral-interview-questions/\n",
    "\n",
    "Some answers should include\n",
    "- What business told me was rarely what they actually wanted. Requirements were never written in a way that delivered context. I realized I needed interpret the requirements correctly by contiune asking questions.\n",
    "- Mixing up with agile and waterfall was a mistake because we had fixed set of deliverables by certain date while allow new items to come into the sprint. And we end up infinite amount of work. If items come in, then new items need to come out.\n",
    "- Manual testing and deployment hit the limit quickly as the application became more complex. We insisted \"due deligence\" of human effort but we quickly realized that everyone makes mistakes. Automation is not only recommened, it is necessary.\n",
    "- When we were estimating the work effort, giving a range of time only made business assume the shortest time. I learned to consider the worst case scenario to always make promise that I can deliver, and also apply that principle when doing VSM.\n",
    "\n",
    "## Why do you want to work here and what are you looking for in the next role?\n",
    "\n",
    "- I want experience on state of art tools and technology.\n",
    "- I want intellectually challenging experience rather than repetitive work.\n",
    "- I want to work in a culture where people show ownership.\n",
    "\n",
    "## Most challenging experience / Achievements\n",
    "\n",
    "ML infrastructure deployment automation (Layer6 AI)\n",
    "- MLOps team was manually constructing 500 yaml files to provision infrastructure for machine learnig use cases. 95% of information we provided were duplicate. \n",
    "- I wanted to automate this manul work.\n",
    "- I came up with using one config file where we supply the minimum 5 percent information. Then I wrote 9 Python scripts to automatically generate all those yaml files based on that 1 config file. \n",
    "- Use case infra provisioning, which used to take 4-6 weeks were reduced to less than 2 weeks.\n",
    "\n",
    "Enterprise DevOps pipeline feature enhancement (Wealth SDDE)\n",
    "- When users made mistakes in the pipeline configurations, they had to go back to the beginning to raise a new Pull Request. There was no way update deployment configuration for inflight releases. This caused delays between 3 days to 2 weeks in deployments.\n",
    "- I wanted to allow users to update pipeline variables w/o going back to the beginning.\n",
    "- I could not allow users to update variables in the tool itself because audit claimed that the source of truth must comes from GIT. So, I came up with a way to allow users to invoke a separate release which targeted the original release to update its deployment variables. This design passed the audit because that separate release will be triggered based on GIT, which we treat as source of truth.\n",
    "- User feedback was their deployment time got reduced by 3 to 5 times on average because they didn't have to go back to the beginning after releazing the mistakes in the middle of the releases.\n",
    "\n",
    "## Made current system better\n",
    "\n",
    "K8s cluster (Layer6 AI)\n",
    "- The K8s cluster we use for model building/training/inference was not robust because it lacked monitoring and security.\n",
    "- I wanted monitoring and security integrated with K8s clusters.\n",
    "- I used helm charts to deploy datadog and kube-state-metric for monitoring and collecting metrics, and K8s Reboot Daemon to automatically reboot K8s nodes after the cloud provider applied the patches on the virtual machines.\n",
    "- The time to notice CPU and memory outage was cut by 1 day on average and we were able to solve problems before users can even notice. The time and effort to reboot K8s nodes manually by checking the condition inside the machines have been eliminated.\n",
    "\n",
    "## Caculated risk and take\n",
    "\n",
    "Security Master deployment (Wealth SDDE)\n",
    "- We were deploying new infrastructure for a project whose load-testing was failing in non-production. We had different infrastructure t-shirt sizes between non-production and production. \n",
    "- I wanted to complete the production deployment within the given timeline.\n",
    "- I suggested that we do production deployment knowing that it is an internal application, user size is limited to the number of IT employees in the bank, which was 8000. The production t-shirt size was twice bigger in CPU and memory.\n",
    "- The deployment worked. But, I reviewed that we had to increase the t-shrit size in non-production so that it exactly matches the production despite the cost, in order to closely reflect what would happen in reality during non-production testing. \n",
    "\n",
    "## Build something from scratch / Most complex project\n",
    "\n",
    "Multibranch pipeline (RESL & HOJ)\n",
    "- Team had created jobs manually in Jenkins where scripts were embedded within the jobs. Each job was different, making it hard to manage continuous integration for the whole line of business.\n",
    "- I wanted systematic approach to setup the pipeline for all projects.\n",
    "- I wrote multibranch pipeline using Groovy from scratch so that every project would use the same codebase for continuous integration. And the codebase is stored in one place and updated in one place rather than each job being managed differently.\n",
    "- Each project in the line of businss reduced time to onboard to continuous integration from 1 week to 1 day. Because we established a streamlined way to configure the hooks from code repo to Jenkins and how to configure pipeline for each project in a standardized way.\n",
    "\n",
    "EDP local development environment (Wealth SDDE)\n",
    "- The entire dev team had manually set up their local development environment. It took between 2-3 months for a new develop to fully setup the complex pipeline environment in his/her local machine. Also, there were some differences between each developer's local environment, which caused code bugs. \n",
    "- I wanted to overcome this hurdle.\n",
    "- I took an initiave to write bash scripts and docker-compose file to automatically provision and configure all pipeline tools locally. I wrote docker-compose file to deploy all Docker files for tools that we were using such as BitBucket, Jenkins, XL Release, XL Deploy. I wrote bash scripts to configure all these tools in fully automated fashion such that everyone in the team would have the exact same local development environment.\n",
    "- New users who took 2-3 months to onboard to project started taking only 2-3 weeks for they did not have to go through configuring all the details of local development environment.\n",
    "\n",
    "## Disaggreement with team member\n",
    "\n",
    "Helm chart for API based model (Layer6 AI)\n",
    "- I updated helm chart for deploying resources in K8s for the real time machine learning usecases. My team member claimed that I should update all usecases that used that helm chart immediately.\n",
    "- I wanted to come up with a conclusion which we could agree upon.\n",
    "- I reasoned that there wouldn't be any difference between updating the chart version now or the next time we do the deployment. My team member still didn't agree. So, I explained the time and effort for doing the deployment, and the benefits of use cases having the lastest updated chart wouldn't exceeds the cost of doing it.\n",
    "- He came to an agreement and we ended up saving time for doing that deployment, which would be 2 days for 3 usecaes combined. \n",
    "\n",
    "## Had to pursuade the team\n",
    "\n",
    "Inner-sourcing Enterprise DevOps pipeline (Wealth SDDE)\n",
    "- The whole DevOps team were the users of the pipeline. Because we didn't know the internal mechanics of the pipeline, we had to rely on support whenever we hit any issues. And the supports were very limited due to short staffing in cloud engineering. \n",
    "- I wanted the team to innersource to pipeline development.\n",
    "- I asked the team to select several individuals to inner-source to cloud engineering to work as pipeline developers. This would raise the knowledge of the team as a whole and we would be much better enabled to resolve any pipeline issues by ourselves. \n",
    "- I was selected as one of the developers to inner-source to the pipeline. I gained lot of knowledge working as a developer. When we were facing any pipeline issues, it usually took 1 week to resolve it. But, now I knew the internal mechanics, each issue was resolved within 1 day.\n",
    "\n",
    "## Had to go beyond my responsibility\n",
    "\n",
    "Supporting Enterprise DevOps pipeline (Wealth SDDE)\n",
    "- I was inner-sourcing in cloud engineering, working as a developer for the enterprise pipeline. There were individuals hired to support the users of the pipeline. This support was done through an internal forum where users would ask questions and support team would answer questions. Because support engineers were not too knowledgable about the pipeline, users were not happy about the quality of support.\n",
    "- I wanted to provide much better support for the users.\n",
    "- I voluntarily started answering the question on the forum whenever I found time after finishing my development work. The forum was used by everyone in the enterprise, although the alignment was that support engineer working for a line of business would only support users from that LOB. But I supported all users of the pipeline regardless where they come from.\n",
    "- I did that to build trust, because in an enterprise settings, we often need things from each other. \n",
    "\n",
    "## Navigate through a difficult situation / Solve a difficult problem \n",
    "\n",
    "First ML usecase onboarding (Layer6 AI)\n",
    "- In the first week of joining Layer6 AI, I was tasked to on-board infrastructure for a new use case. This is a major task for this team. I was given 2 weeks, which was the same amount of time given to all other experienced members.\n",
    "- I wanted to provision all necessary infrastrucutre for the new use case.\n",
    "- I studied the on-boarding document very carefully. Many places in the document did not make sense, so I reached out to team members asking questions and corrected the document. I noted down places for improvement, especially what we could automate. The pipeline to provision the infrastructure was failing in many different places, but I rather than waiting for support engineers to fix, I investigated the codebase myself to resolve issues.\n",
    "- It took until the very last day of 2 weeks to finish infrasturcture on-boarding. Team said well down for it was first time for me to do it and they starting showing me trust.\n",
    " \n",
    "VMC pipeline (Wealth SDDE)\n",
    "- I was given a very tight deadline, which was 2 weeks, to develop and deploy pipeline for automating the provisioning of infrastructure on private cloud. The release date was already communicated to the users in the Enterpise and cloud engineering could not find the right candidate until they gave it to me. \n",
    "- I wanted to build and release VMC provisioning feature in the pipeline in 2 weeks.\n",
    "- I gathered all the requirements from the stakeholders. There were lots. I realized it was impractical to target all of them. I suggested the team to deliver the requirements in phases. First of all, I would finish the infra provisioning for various middlewares (jboss, springboot, nodejs) including the core configuration of those infrastructure because those were most critical. Then, I would target allowing users to provide their own custom configuration for the infrastructure in the second phase. Then, the ability to cleanup any unused infrasture or deployment would come in third phase.\n",
    "- R: The team was able to deliver their initial promise to end users. The end users got what they expected. And before they realized they were missing something, we filled those gaps in the subsequence release from our phase approach. \n",
    "\n",
    "## Made tradeoffs in your projects / Made short-term sacrifice for long term gain \n",
    "\n",
    "Log4J (Layer6 AI)\n",
    "- Log4j issue hit Layer6 AI hard affecting most containers running in production in December 2021. The issue came during the weekend, so we had limited responses from the users. If we kept the containers running, we would have serious security risks of RCE (Remote Code Execution). But if we just shutdown the containers, it could impact businesses.  \n",
    "- I wanted to remediate log4j situation as soon as possible.\n",
    "- I tried to reach out to all users. But seeing people didn't respond, I took an intiative to tell my team that we should shutdown all the containers. It was because I determined the risk of RCE far outweighted the loss of business outputs in the next several days.\n",
    "- R: I took 3 days (including the weekend) to patch the containers and re-stood them up. Although that caused some business impacts, I still feel it was the right decision to make since Layer6 AI was not exploited by this vulnerability.\n",
    "\n",
    "## Needed information from someone who was not responsive?\n",
    "\n",
    "Azure DataFactory pipeline (Layer6 AI)\n",
    "- I was deploying Azure DataFactory using pipeline but the pipeline lacked functionality to grant right permissions to Azure groups. Thus, users could not access the tool that I provisioned.\n",
    "- I did not have access to make changes in Azure myself. But, I still had to solve this issue.\n",
    "- I reached out to individuals in Identity and Access Management team in chat and email, but I did not get any resposne. Then, I reached out to their manager, but still no response. After sending out chats several times, I finally got responese from them. And they handed over quite complex process to have them do the change I wanted.\n",
    "- I was able to grant users access to Azure DataFactory by following their process, which involved raising a Pull Request to their repository and running a build in the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b23537-9439-4ec0-9ffb-01443824d94d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9a769-d060-44f1-b6bf-942d0bd19db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
