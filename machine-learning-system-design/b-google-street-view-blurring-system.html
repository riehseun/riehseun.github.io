<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Google Street View Blurring System BEGIN -->
<div class="card mb-4" id="google-street-view-blurring-system">
  <div class="card-body">
    <h2 class="card-title">Google Street View Blurring System</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#google-street-view-blurring-system-1">Clarifying Requirements</a></li>
      <li><a href="#google-street-view-blurring-system-2">Frame the Problem as an ML Task</a></li>
      <li><a href="#google-street-view-blurring-system-3">Data Preparation</a></li>
      <li><a href="#google-street-view-blurring-system-4">Model Development</a></li>
      <li><a href="#google-street-view-blurring-system-5">Evaluation</a></li>
      <li><a href="#google-street-view-blurring-system-6">Serving</a></li>
      <li><a href="#google-street-view-blurring-system-7">Follow Up</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-1">
  <div class="card-body">
    <h2 class="card-title">Clarifying Requirements</h2>
    <ul>
      <li>What is the the purpose of the system? Blurring parts of images that are inappropriate</li>
      <li>Should the detect human faces and license plates? Yes</li>
      <li>Can users report images that are not correctly blurred? Yes</li>
      <li>Do we have training data available? There are 1M images with human faces and license plates manually annotated</li>
      <li>Should the system handle bias w.r.t. race, gender, age, etc? No</li>
      <li>Can the inference be batch or does it need to be online? Images can be processed offline</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-2">
  <div class="card-body">
    <h2 class="card-title">Frame the Problem as an ML Task</h2>
    <ul>
      <li>Define ML objective</li>
      <ul>
        <li></li>
      </ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - images with zero or more objects in it</li>
        <li>Output - location of objects of interest</li>
      </ul>
      <li>Choose right ML category</li>
      <ul>
        <li>Predict location of object - regression problem</li>
        <li>Predict class of object - multi-class classification</li>
        <li>1. one stage network</li>
        <ul>
          <li>Bounding boxes and object classes are generated simultaneously</li>
          <li>Ex. YOLO, SDD</li>
        </ul>
        <li>2. two stages networks</li>
        <ul>
          <li>Region proposal network (RPN) - proposes candidate regions that are likely objects</li>
          <li>Classifier - classifies each proposed region into an object class</li>
          <li>Usually slower but accurate</li>
          <li>Ex. R-CNN, Fast R-CNN, Faster R-CNN</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-3">
  <div class="card-body">
    <h2 class="card-title">Data Preparation</h2>
    <ul>
      <li>Data engineering</li>
      <ul>
        <li>Annotated dataset</li>
        <ul>
          <li>image_path</li>
          <li>objects - human face, license plate</li>
          <li>bounding_boxes - x coordinate, y coordinate, width, height</li>
        </ul>
        <li>Street view images</li>
        <ul>
          <li>image_path</li>
          <li>location - latitude, longitude</li>
          <li>pitch_yaw_roll</li>
          <li>timestamp</li>
        </ul>
      </ul>
      <li>Feature engineering</li>
      <ul>
        <li>Resize</li>
        <li>Scale</li>
        <li>Normalize</li>
        <li>Color mode</li>
        <li>Data augmentation</li>
        <ul>
          <li>Ex. random crop, random saturation, vertical/horizontal flip, rotation/translation, affline transformations, changing brightness/saturation/contrast</li>
          <li>When rotating/flipping images, the ground truth bounding boxes must also be transformed</li>
          <li>Option 1. offline</li>
          <ul>
            <li>Augment image before training</li>
            <li>Training is faster but requires additional storage</li>
          </ul>
          <li>Option 2. online</li>
          <ul>
            <li>Augment image on the fly during training</li>
            <li>Training is slower but requires no additional storage</li>
          </ul>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-4">
  <div class="card-body">
    <h2 class="card-title">Model Development</h2>
    <ul>
      <li>Model selection</li>
      <ul>
        <li>Two stages network</li>
        <ul>
          <li>Convolutional layers</li>
          <ul>
            <li>Takes input image and produces feature map</li>
          </ul>
          <li>Region proposal network (RPN)</li>
          <ul>
            <li>Regression task to detect objects</li>
            <li>Based on neural network</li>
            <li>Takes feature map and produces candidate regions in the image</li>
          </ul>
          <li>Classifier</li>
          <ul>
            <li>Classification task to assign objects to classes</li>
            <li>Based on neural network</li>
            <li>Takes feature map and candidate regions, and assigns an object class to each region</li>
          </ul>
        </ul>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Constructing dataset</li>
        <ul>
          <li>We are given annotated dataset</li>
        </ul>
        <li>Choosing loss function</li>
        <ul>
          <li>Regression loss</li>
          <ul>
            <li>Measures how aligned the predicted bounding boxes are with the ground truth bounding boxes</li>
            <li>Use mean squared error (MSE)</li>
            <li>\( L_{reg} = \dfrac{1}{M}\displaystyle\sum_{i=1}^{M} \left[ (x_{i}-\hat{x}_{i})^{2} + (y_{i}-\hat{y}_{i})^{2} + (w_{i}-\hat{w}_{i})^{2} + (h_{i}-\hat{h}_{i})^{2} \right] \)</li>
            <ul>
              <li>\( M \) - total number of predictions</li>
              <li>\( x_{i} \) - ground truth top left \( x \) coordinate</li>
              <li>\( \hat{x}_{i} \) - predicted top left \( x \) coordinate</li>
              <li>\( y_{i} \) - ground truth top left \( y \) coordinate</li>
              <li>\( \hat{y}_{i} \) - predicted top left \( y \) coordinate</li>
              <li>\( w_{i} \) - ground truth width</li>
              <li>\( \hat{w}_{i} \) - predicted width</li>
              <li>\( h_{i} \) - ground truth height</li>
              <li>\( \hat{h}_{i} \) - predicted height</li>
            </ul>
          </ul>
          <li>Classification loss</li>
          <ul>
            <li>Measures how accurate the predicted probabilities are for each detected object</li>
            <li>Use log loss (cross-entropy)</li>
            <li>\( L_{cls} = -\dfrac{1}{M} \displaystyle\sum_{i=1}^{M} \displaystyle\sum_{c=1}^{C} y_{c}log\hat{y}_{c} \)</li>
            <ul>
              <li>\( M \) - total number of detected bounding boxes</li>
              <li>\( C \) - total number of classes</li>
              <li>\( y_{i} \) - ground truth label for detection \( i \)</li>
              <li>\( \hat{y}_{i} \) - predicted class label for detection \( i \)</li>
            </ul>
          </ul>
          <li>Total loss</li>
          <ul>
            <li>\( L = L_{reg} + \lambda L_{cls} \)</li>
            <li>\( \lambda \) - balancing parameter</li>
          </ul>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>
    <ul>
      <li>Offline</li>
      <ul>
        <li>1. Precision</li>
        <ul>
          <li>\( P(n) = \dfrac{\text{Correct detections}}{\text{total detections}} \)</li>
          <li>Need to pick an IoU threshold</li>
          <ul>
            <li>Intersection over union (IoU) - measures overlap between detected and ground truth bounding boxes</li>
          </ul>
        </ul>
        <li>2. Average precision (AP)</li>
        <ul>
          <li>Calculate precision at different IoU threshold and compute the average</li>
          <li>If there are \( 11 \) IOU values, \( AP = \dfrac{1}{11} \displaystyle\sum_{n=10}^{n=0} P(n) \)</li>
        </ul>
        <li>3. Mean average precision (mAP)</li>
        <ul>
          <li>Average of average precision across all object classes</li>
          <li>\( mAP = \dfrac{1}{C} \displaystyle\sum_{c=1}^{C} AP_{c} \)</li>
        </ul>
      </ul>
      <li>Online</li>
      <ul>
        <li>Number of user reports and complaints</li>
        <li>Human annotators to spot check the percentage of incorrectly blurred images</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-6">
  <div class="card-body">
    <h2 class="card-title">Serving</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning-system-design/image/ref-mlsd-1/google-street-view-blurring-system-1.png" alt="Card image cap">

    <ul>
      <li>Data pipeline</li>
      <ul>
        <li>Hard negative mining</li>
        <ul>
          <li>Negative examples created from incorrectly predicted examples</li>
          <li>Model should perform better when trained with this dataset</li>
        </ul>
        <li>Preprocessing</li>
        <ul>
          <li>Resize, scale, normalize</li>
        </ul>
      </ul>
      <li>Batch inference pipeline</li>
      <ul>
        <li>Non-max suppression (NMS)</li>
        <ul>
          <li>Keep one bounding box out of many overlapping bounding boxes</li>
        </ul>
        <li>Preprocessing</li>
        <ul>
          <li>CPU intensive task</li>
          <li>Seperated from blurring service</li>
          <ul>
            <li>CPU and GPU intensive tasks can be scaled independently</li>
            <li>Better utilization of CPU and GPU</li>
          </ul>
        </ul>
        <li>Blurring service</li>
        <ul>
          <li>GPU intensive task</li>
          <li>Identify all objects in the image</li>
          <li>Resolve overlapping bounding boxes using NMS</li>
          <li>Blur objects of interest</li>
          <li>Store blurred images in object storage</li>
        </ul>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>

<div class="card mb-4" id="google-street-view-blurring-system-7">
  <div class="card-body">
    <h2 class="card-title">Follow Up</h2>
    <ul>
      <li>Explain how transformer based object detection differs from one-stage or two-stage models</li>
      <li>Explain distributed training techniques to improve object detection at larger dataset</li>
      <li>Explain the impact of generate data protection regulation (GDPR) on the design</li>
      <li>Explain how to handle bias in face detection system</li>
      <li>Explain how to continuously fine-tune the model</li>
      <li>Explain how to use active learning or human-in-the-loop ML to select data points for training</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Machine Learning System Design Interview, Ali Aminian & Alex Xu
  </div>
</div>
<!-- Google Street View Blurring System END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>