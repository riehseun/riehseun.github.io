<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Generative AI System Design BEGIN -->
<div class="card mb-4" id="generative-ai-system-design">
  <div class="card-body">
    <h2 class="card-title">Generative AI System Design</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#generative-ai-system-design-1">Introduction and Overview</a></li>
      <li><a href="#generative-ai-system-design-2">Gmail Smart Compose</a></li>
      <li><a href="#generative-ai-system-design-3">Google Translate</a></li>
      <li><a href="#generative-ai-system-design-4">ChatGPT</a></li>
      <li><a href="#generative-ai-system-design-5">Image Captioning</a></li>
      <li><a href="#generative-ai-system-design-6">RAG</a></li>
      <li><a href="#generative-ai-system-design-7">Realistic Face Generation</a></li>
      <li><a href="#generative-ai-system-design-8">High-Resolution Image Synthesis</a></li>
      <li><a href="#generative-ai-system-design-9">Text-to-Image Generation</a></li>
      <li><a href="#generative-ai-system-design-10">Personalized Headshot Generation</a></li>
      <li><a href="#generative-ai-system-design-11">Text-to-Video Generation</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-1">
  <div class="card-body">
    <h2 class="card-title">Introduction and Overview</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>Business objective</li>
      <ul>
        <li>What is primary goal of the system?</li>
      </ul>
      <li>System features</li>
      <ul>
        <li>What features should the system support that might influence the ML design?</li>
      </ul>
      <li>Data</li>
      <ul>
        <li>What is data source?</li>
        <li>How large is dataset?</li>
        <li>Is data labeled?</li>
      </ul>
      <li>Constraints</li>
      <ul>
        <li>How much computing power is available?</li>
        <li>Should model be deployed to cloud or mobile devices?</li>
      </ul>
      <li>Scale</li>
      <ul>
        <li>How many total users? How many daily active users?</li>
        <li>How many items?</li>
        <li>What is rate of growth?</li>
      </ul>
      <li>Performance</li>
      <ul>
        <li>How fast should generation be?</li>
        <li>Is real-time generation required??</li>
        <li>Is content quality or generation speed more important?</li>
      </ul>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Discriminative vs generative</li>
        <li>Identify task type</li>
        <ul>
          <li>Text, image, audio, video generation</li>
        </ul>
        <li>Choose suitable algorithm</li>
        <ul>
          <li>Text - RNN (GRU, LSTM), Transformers</li>
          <li>Image - VAE, GANs, Diffusion, Autoregressive</li>
          <li>Audio - VAE, Autoregressive</li>
          <li>Video - Diffusion, Autoregressive</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Data collection</li>
      <li>Data cleaning</li>
      <li>Data efficiency</li>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Model architecture</li>
      <li>Model training</li>
      <ul>
        <li>Training methodology</li>
        <li>Training data</li>
        <li>ML objective and loss function</li>
        <li>Task-specific challenges and mitigations</li>
        <ul>
          <li>Gradient checkpointing</li>
          <li>Mixed precision training</li>
          <li>Distributed training</li>
          <ul>
            <li>Data parallelism</li>
            <li>Model parallelism</li>
            <li>Hybrid parallelism</li>
          </ul>
        </ul>
      </ul>
      <li>Model sampling</li>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <ul>
        <li>Text generation</li>
        <ul>
          <li>Perplexity</li>
          <li>BLUE</li>
          <li>METEOR</li>
          <li>ROUGE</li>
          <li>CIDEr</li>
        </ul>
        <li>Image generation</li>
        <ul>
          <li>FID</li>
          <li>IS</li>
          <li>KID</li>
          <li>SWD</li>
          <li>PPL</li>
          <li>LPIPS</li>
        </ul>
        <li>Text-to-video</li>
        <ul>
          <li>FVD</li>
          <li>ClipScore</li>
          <li>FID</li>
          <li>LPIPS</li>
          <li>KID</li>
        </ul>
      </ul>
      <li>Online</li>
      <ul>
        <li>Click-through rate (CRT)</li>
        <li>Conversion rate</li>
        <li>Latency (inference time)</li>
        <li>Engagement rate</li>
        <li>Revenue per user</li>
        <li>Churn rate</li>
        <li>User satisfaction</li>
        <li>User retiontion</li>
        <li>Completion rate</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-2">
  <div class="card-body">
    <h2 class="card-title">Gmail Smart Compose</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>Should suggestions be personalized? No</li>
      <li>Should suggestions be made only when the model is confident in prediction? Yes</li>
      <li>How large is dataset? 1B email messages</li>
      <li>Should the model use just email body or other apsects of email? Email body only</li>
      <li>What language should the model support? English only</li>
      <li>Should the model handle bias in its prediction? Yes</li>
      <li>How many users are there? 1.8B users</li>
      <li>How many emails can a user send? Up to 500 emails per day</li>
      <li>How fast should the suggestions be? Under 100ms</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - words typed by user</li>
        <li>Output - words that user will likely type next</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Transformer</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Training data</li>
      <ul>
        <li>General data like books, websites, social media</li>
        <li>Email data</li>
        <ul>
          <li>email_id</li>
          <li>sender</li>
          <li>receiver</li>
          <li>subject</li>
          <li>body</li>
        </ul>
      </ul>
      <li>Text cleaning</li>
      <ul>
        <li>Remove non-english</li>
        <li>Remove confidential info by masking them</li>
        <li>Remove irrelevant chars or symbols</li>
        <li>Remove duplicate data</li>
      </ul>
      <li>Text normalization</li>
      <ul>
        <li>Convert texts to consistent format</li>
      </ul>
      <li>Text tokenization</li>
      <ul>
        <li>Char-level</li>
        <ul>
          <li>Simple to implement</li>
          <li>Difficult for model to understand meaning of each token</li>
        </ul>
        <li>Word level</li>
        <ul>
          <li>Easier for model to understand meaning of each token</li>
          <li>Very large vocabulary size</li>
        </ul>
        <li>Subword-level</li>
        <ul>
          <li>Break uncommon words into known subwords, resulting in medium vocab size</li>
          <li>Algorithm can be complex (Ex. Byte-Pair Encoding (BPE), SentencePiece)</li>
        </ul>
      </ul>
      <li>Token indexing</li>
      <ul>
        <li>Convert texts to numbers</li>
      </ul>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Architecture</li>
      <ul>
        <li>Encoder-only</li>
        <ul>
          <li>Process input sequences and makes a prediction about it</li>
          <li>Ex. sentiment analysis</li>
          <li>Ex. Google's BERT, Meta's RoBERTa</li>
        </ul>
        <li>Decoder-only</li>
        <ul>
          <li>Process input sequences and generates a new sequence</li>
          <li>Ex. text generation</li>
          <li>Ex. OpenAI's GPT, Google's Gemini, Meta's LLaMA, xAI's Grok, Anthropic's Claude</li>
        </ul>
        <li>Encoder-decoder</li>
        <ul>
          <li>Useful where output is transformation of input</li>
          <li>Ex. language transation</li>
          <li>Ex. Google's T5, Meta's BART</li>
        </ul>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Architecture</li>
        <ul>
          <li>Text embedding</li>
          <ul>
            <li>Convert token ID to embedding vector</li>
            <li>Representing tokens by ID via one-hot encoding results in very sparse vector</li>
            <li>IDs do not capture any semantic relationships between words</li>
          </ul>
          <li>Positional encoding</li>
          <ul>
            <li>Without this, model treats input sequence as bag of words</li>
            <li>Fixed encoding</li>
            <ul>
              <li>Pros</li>
              <ul>
                <li>No extra parameters</li>
                <li>Supports very long sequence</li>
              </ul>
              <li>Cons</li>
              <ul>
                <li>Requires a pre-defined limit and training data longer than the limit is typically discarded</li>
                <li>Lower performance</li>
              </ul>
            </ul>
            <li>Learned encoding</li>
            <ul>
              <li>Pros</li>
              <ul>
                <li>Higher performance</li>
              </ul>
              <li>Cons</li>
              <ul>
                <li>Additional parameters are needed</li>
                <li>May overfit specific sequence length</li>
              </ul>
            </ul>
          </ul>
          <li>Transformer</li>
          <ul>
            <li>Multi-head attention</li>
            <ul>
              <li>Also known as self-attention</li>
            </ul>
            <li>Feed forward</li>
            <ul>
              <li>Two linear transformations with ReLu activations in between</li>
            </ul>
          </ul>
          <li>Prediction head</li>
          <ul>
            <li>Convert model output into probabilities of each word</li>
          </ul>
        </ul>
        <li>Training</li>
        <ul>
          <li>Direct training</li>
          <ul>
            <li>Lack of large training data</li>
            <li>Risk of overfitting</li>
          </ul>
          <li>Pre-training</li>
          <ul>
            <li>Train on general data</li>
            <li>Objective is to predict the next token</li>
            <li>Cross-entropy loss to measure difference between predicted vs actual next token</li>
          </ul>
          <li>Fine-tuning</li>  
          <ul>
            <li>Very similar to pre-training but loss is calculated based on email data</li>
          </ul>
        </ul>
        <li>Sampling</li>
        <ul>
          <li>Deterministic</li>
          <ul>
            <li>Generated result is always the same for the same input</li>
            <li>Pros</li>
            <ul>
              <li>Predictable output</li>
            </ul>
            <li>Cons</li>
            <ul>
              <li>Lack of diversity</li>
            </ul>
            <li>Greedy search</li>
            <ul>
              <li>Select token with highest probability</li>
            </ul>
            <li>Beam search</li>
            <ul>
              <li>Initialization - select top k most probable tokens</li>
              <li>Expansion - obtain probabilities of next token</li>
              <li>Pruning - select top k sequences based on their cumulative probabilities</li>
            </ul>
          </ul>
          <li>Stochastic</li>
          <ul>
            <li>Samples result from distribution based on probability assigned to each token</li>
            <li>Pros</li>
            <ul>
              <li>Diversity and novelty</li>
            </ul>
            <li>Cons</li>
            <ul>
              <li>Inconsistency and unexpected output</li>
            </ul>
          </ul>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <ul>
        <li>Option 1. perplexity</li>
        <ul>
          <li>Given input sequence, Evaluate if model can accurately predict next words in text data</li>
          <li>\( \text{Perplexity}(X) = \text{exp}\left(-\dfrac{1}{N}\displaystyle\sum_{i=1}^{N}\text{log}P(x_{i}|x_{1:i-1})\right) \)</li>
          <ul>
            <li>\( X \) - tokenized sequence \( x_{1} \dots x_{N} \) in text data</li>
            <li>\( N \) - number of tokens in sequence</li>
            <li>\( P(x_{i}|x_{1:i-1}) \) - conditional probability of ith token given preceeding tokens</li>
          </ul>
        </ul>
        <li>Option 2. ExactMatch@N</li>
        <ul>
          <li>Evaluate if predicted words and ground truth words exactly match up to N words</li>
        </ul>
      </ul>
      <li>Online</li>
      <ul>
        <li>User engagement</li>
        <ul>
          <li>Acceptance rate - rate of suggestions that are accepted by users</li>
          <li>Usage rate - rate of emails that are used by users</li>
        </ul>
        <li>Effectiveness</li>
        <ul>
          <li>Average completion time - average time taken by users to compose emails</li>
        </ul>
        <li>Latency</li>
        <ul>
          <li>System response time - time for suggestions to appear after user begins typing</li>
        </ul>
        <li>Quality</li>
        <ul>
          <li>Feedback rate</li>
          <li>Human evaludation</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Serving</h3>

    <img class="img-fluid" class="card-img-top" src="/machine-learning-system-design/image/mlsd-c/gmail-smart-compose-1.png" alt="Card image cap">

    <ul>
      <li>Triggering service</li>
      <ul>
        <li>When users start typing, based on number of chars that user typed, the service triggers next words generation</li>
      </ul>
      <li>Phase generator</li>
      <ul>
        <li>Calls the model to receive words that are likely to be next words</li>
        <li>Remove long suggestions</li>
        <li>Remove low-confidence suggestions</li>
      </ul>
      <li>Post-processing service</li>
      <ul>
        <li>Filter out gender-sensitive, racial-sensitive, nudity, violence words</li>
      </ul>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to support multiple languages</li>
      <li>Explain how to personalize suggestions</li>
      <li>Explain how to incorporate additional context for better predictions</li>
      <li>Explain how to choose between BPE, SentencePiece, WordPiece</li>
      <li>Explain masked lanaguage modeling (MLM)</li>
      <li>Explain multi-token prediction</li>
      <li>Explain how to balance inference quality and latency</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-3">
  <div class="card-body">
    <h2 class="card-title">Google Translate</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>Which languages should the system support? English, Spanish, Korean, French</li>
      <li>How large is dataset? 300M pairs of source and target languages</li>
      <li>Do we have training data available? Yes, terabytes of general text data is available</li>
      <li>Should the system detect input language automatically? Yes</li>
      <li>What should be the input length limit? 1000 words</li>
      <li>Should the model be deployed to mobile devices? No</li>
      <li>How fast should the suggestions be? Translation can be done offline</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - source language</li>
        <li>Output - target language</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Transformer with encoder-decoder architecture</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Text preprocessing</li>
      <ul>
        <li>Remove missing data</li>
        <li>Remove noisy data</li>
        <li>Remove duplicate data</li>
        <li>Handle entity names</li>
        <ul>
          <li>Replace entities with placeholder in order not to confuse the model with uncommon terms</li>
        </ul>
        <li>These preprocessing are not needed in LLM</li>
        <ul>
          <li>Lowercasing</li>
          <li>Removing stop words </li>
          <ul>
            <li>Ex. the, and, in</li>
          </ul>
          <li>Stemming and lemmatization</li>
          <li>Removing punctuations</li>
        </ul>
      </ul>
      <li>Text tokenization</li>
      <ul>
        <li>Byte-Pair Encoding (BPE)</li>
        <ul>
          <li>For all words in data set, append&lt;/w&gt; to mark the end of word</li>
          <li>For all words in data set, split into chars and create frequency table for each char</li>
          <li>Starting from chars with highest frequency, iteratively merge chars to create subwords and count frequency of those subwords</li>
          <li>Iteration continues to merge subwords into bigger subwords until reaching pre-defined size</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Model architecture</li>
      <ul>
        <li>Encoder</li>
        <ul>
          <li>Text embedding</li>
          <li>Positional encoding</li>
          <li>Transformer</li>
        </ul>
        <li>Decoder</li>
        <ul>
          <li>Text embedding</li>
          <li>Positional encoding</li>
          <li>Transformer</li>
          <ul>
            <li>Cross attention integrates information from encoder</li>
            <li>All word/token attends to only the word/token that comes before (future tokens are masked)</li>
            <li>Model should only use previous tokens to generate next tokens</li>
          </ul>
          <li>Prediction head</li>
          <ul>
            <li>Prediction head contains linear layer followed by softmax layer</li>
          </ul>
        </ul>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Unsupervised pre-training</li>
        <ul>
          <li>Train on general data that has source and target languages</li>
          <li>Objective is to predict masked tokens (Masked Language Modeling)</li>
          <ul>
            <li>Randomly mask subset of input tokens by replacing them with [MASK]</li>
            <li>Feed masked sequence to encoder</li>
            <li>Encoder outputs a sequence of new embeddings for each token</li>
            <li>Feed the same masked sequence to decoder but without masking and shifting one position to right by inserting start token &lt;BOS&gt;</li>
            <li>Decoder predicts next token for each position in sequence</li>
            <li>Calculate cross-entropy loss over predicted probabilities and ground truth for masked tokens only</li>
          </ul>
          <li>Existing models (T5, BART) can be used instead</li>
        </ul>
        <li>Supervised Fine-tuning</li>  
        <ul>
          <li>Train on pairs of source and target sentences</li>
          <ul>
            <li>Option 1. bilingual</li>
            <ul>
              <li>Higher accuracy</li>
              <li>Hard to handle multiple languages in terms of trainning, deployment, monitoring</li>
            </ul>
            <li>Option 2. multilingual</li>
            <ul>
              <li>Lower accuracy</li>
              <li>Simple</li>
            </ul>
          </ul>
          <li>Objective is to predict next token</li>
          <li>Cross-entropy loss to measure difference between predicted vs actual next token</li>
        </ul>
        <li>Sampling</li>
        <ul>
          <li>Beam search for accuracy and consistency of translation</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <ul>
        <li>Option 1. BiLingual Evaludation Understudy (BLUE)</li>
        <ul>
          <li>Precision based which compares n-gram of candidate translation against n-gram of reference translations</li>
          <li>\( \text{BLEU} = \text{BP}\cdot\text{exp} \left( \displaystyle\sum_{n=1}^{N}w_{n}\text{log}p_{n}\right) \)</li>
          <ul>
            <li>\( N \) - maximum n-gram length considered for evaluation</li>
            <li>\( \text{BP}  =  1 \) if \( c \gt r \), \( \text{BP}  =  0\)  if \( c \le r \) </li>
            <ul>
              <li>\( c \) - candidate translation length</li>
              <li>\( r \) - reference translation length<</li>
            </ul>
            <li>\( p_{n} \) - precision that measures how many n-grams in candidate translation are present in reference translation</li>
            <li>\( w_{n} \) - weights corresponding to precision of each n-gram size</li>
          </ul>
          <li>May unfairly penalize good translations that has just different ordering of words</li>
        </ul>
        <li>Option 2. Recall Oriented Understudy for Gisting Evaluation (ROUGE)</li>
        <ul>
          <li>Recall based which computes ratio of matching n-gram in candidate translation over total number of n-grams in reference translations</li>
          <li>Similar to BLUE (focus on recall rather than precision) and has same drawbacks</li>
        </ul>
        <li>Option 3. Metric for Evaluation of Translation with Explicit ORdering (METEOR)</li>
        <ul>
          <li>Matches synonyms rather than exact words</li>
          <li>Relies on linguistic resources such as synonym dictionaries and stemming algorithms</li>
        </ul>
      </ul>
      <li>Online</li>
      <ul>
        <li>User feedback</li>
        <li>User engagement</li>
      </ul>
    </ul>

    <h3 class="card-title">Serving</h3>

    <img class="img-fluid" class="card-img-top" src="/machine-learning-system-design/image/mlsd-c/google-translate-1.png" alt="Card image cap">

    <ul>
      <li>Language detector service</li>
      <ul>
        <li>Use encoder-only model to detect language given input sentence</li>
        <ul>
          <li>Option 1. average pooling - pass transformer output to average pooling layer, then to prediction head</li>
          <li>Option 2. last token representation - pass last token representation from transformer output directly to prediction head</li>
        </ul>
      </ul>
      <li>Translation service</li>
      <ul>
        <li>Calls the model to receive translation of detected sentence</li>
      </ul>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to deal with limited data via transfer learning</li>
      <li>Explain how to build translation with decoder-only model</li>
      <li>Explain how to improve translation using user feedback</li>
      <li>Explain how to achieve efficient inference for models deployed on device</li>
      <li>Explain how to develop a single multilingual model</li>
      <li>Explain WER</li>
      <li>Explain how to build a language detection model</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-4">
  <div class="card-body">
    <h2 class="card-title">ChatGPT</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>Which languages should the system support? English only</li>
      <li>Should the system moderate contents? Yes</li>
      <li>Should the system support images and videos as input and output? No, text only</li>
      <li>Should the system support follow up questions? Yes, context window should be at least 4096</li>
      <li>Should the system browser website, call APIs? No</li>
      <li>Should the system be personalized to each user? No</li>
      <li>Do we have training data available? Yes, 80k examples of questions and answers</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - user prompt</li>
        <li>Output - response</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Transformer with decoder architecture</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>General data from web</li>
      <ul>
        <li>Content extraction and parsing</li>
        <li>URL and domain filtering</li>
        <li>Language identification</li>
        <li>Content quality filtering</li>
      </ul>
      <li>General data from web, books, articles, social media</li>
      <ul>
        <li>Remove inappropriate content</li>
        <li>Mask sensitive information</li>
        <ul>
          <li>Ex. PII</li>
        </ul>
        <li>Remove low-quality data</li>
        <li>Remove duplicate data</li>
        <li>Remove irrelevant data</li>
        <ul>
          <li>Ex. non-standard characters</li>
        </ul>
        <li>Tokenized text</li>
      </ul>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Model architecture</li>
      <ul>
        <li>Positional encoding</li>
        <ul>
          <li>Option 1. absolute</li>
          <ul>
            <li>Ex. sinusoidal, learnable</li>
            <li>Hard to generalize for sequences with different length</li>
          </ul>
          <li>Option 2. relative</li>
          <ul>
            <li>Encodes difference in the positions of two tokens</li>
          </ul>
          <li>Option 3. rotary (RoPE)</li>
          <ul>
            <li>Apply rotation matrix to token embedding</li>
          </ul>
        </ul>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Pre-training</li>
        <ul>
          <li>Train on general data that has English</li>
          <ul>
            <li>Example datasets - Common Crawl, C4, Github, Books, Wikipedia, ArXiv, Stack Exchange</li>
          </ul>
          <li>Objective is to predict next token</li>
          <li>Cross-entropy loss</li>
        </ul>
        <li>Fine-tuning</li>  
        <ul>
          <li>Train on pairs of prompt-response</li>
          <ul>
            <li>Example datasets - InstructGPT, Alpaca, Dolly-15K, FLAN 2022</li>
          </ul>
          <li>Objective is to predict next token</li>
          <li>Cross-entropy loss</li>
        </ul>
        <li>Reinforcement learning from human feedback (RLHF)</li>  
        <ul>
          <li>Make model generate responses preferred by human</li>
          <li>Train reward model</li>
          <ul>
            <li>Input - pair of prompt and response</li>
            <li>Output - score representing helpfulness of response for the prompt</li>
            <li>Copy model from fine-tuning and add a prediction head</li>
            <li>Training data</li>
            <ul>
              <li>Manually create a list of prompts</li>
              <li>Generate multiple responses for each prompt</li>
              <li>Rank responses</li>
              <li>Create preference pairs - (prompt, winning response, losing response)</li>
            </ul>
          </ul>
          <li>Optimize</li>
          <ul>
            <li>Proximal policy optimization (PPO)</li>
            <ul>
              <li>Update model weights to maximize score from reward model</li>
            </ul>
          </ul>
        </ul>
        <li>Sampling</li>
        <ul>
          <li>Stochastic</li>
          <ul>
            <li>Multinomial</li>
            <ul>
              <li>Token is chosen based on probabilities of each token</li>
              <li>Randomness is too big, especially when probabilty distribution is flat</li>
            </ul>
            <li>Top k</li>
            <ul>
              <li>Sample from k most likely tokens rathen than from entire distribution</li>
              <li>If sharp distribution, model might miss the best choice resulting in non-sensical outputs</li>
              <li>If flat distribution, model may not consider enough word options</li>
            </ul>
            <li>Top p</li>
            <ul>
              <li>Adjust number of tokens to be considered based on their combined probabilities</li>
              <li>Consider smallest possible number of tokens whose cumulative probabily exceeds p</li>
            </ul>
          </ul>
        </ul>
        <li>Temperature</li>
        <ul>
          <li>Adjusted softmax with temperature - \( p_{i} = \dfrac{\text{exp}(\dfrac{x_{i}}{T})}{\displaystyle\sum_{j}^{n}\text{exp}(\dfrac{x_{i}}{T})} \)</li>
          <li>When T > 1, model generates more uniform probability distribution, making predictions more random</li>
          <li>When T < 1, predictions become more determinstic</li>
          <li>When T = 0, sampling becomes deterministic (always same output)</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <ul>
        <li>Task specific</li>
        <ul>
          <li>Common-sense reasoning</li>
          <ul>
            <li>Ex. PIQA (Physical Interation QA), SIQA, HellaSwag, WinoGrande, OpenBookQA, CommonsenseQA</li>
          </ul>
          <li>World knowledge</li>
          <ul>
            <li>Ex. TriviaQA, NQ (Natural Questions), SQuAD (Stanford Question Answering Dataset)</li>
          </ul>
          <li>Reading comprehension</li>
          <ul>
            <li>Ex. SQuAD, QuAC, BoolQ</li>
          </ul>
          <li>Mathematical reasoning</li>
          <ul>
            <li>Ex. MATH, GSM8K (Grade School Math 8K)</li>
          </ul>
          <li>Code generation</li>
          <ul>
            <li>Ex. HumanEval, MBPP (MultiPL-E Benchmarks for Programming Problems)</li>
          </ul>
          <li>Composite benchmark</li>
          <ul>
            <li>Ex. MMLU (Massive Multitask Language Understanding), MMMU (Massive Multilingual Multitask Understanding), AGIEval, Meta Llama 3 human evaluation</li>
          </ul>
        </ul>
        <li>Safety</li>
        <ul>
          <li>Toxicity and Harmful content</li>
          <ul>
            <li>Ex. RealToxicityPrompts, ToxiGen, HateCheck</li>
          </ul>
          <li>Bias and fairness</li>
          <ul>
            <li>Ex. CrowS-Pairs, BBQ, BOLD</li>
          </ul>
          <li>Truthfulness</li>
          <ul>
            <li>Ex. TruthfulQA</li>
          </ul>
          <li>User privacy and data leakage</li>
          <ul>
            <li>Ex. PrivacyQA</li>
          </ul>
          <li>Adversarial robustness</li>
          <ul>
            <li>Ex. AdvGLUE, TextFooler, AdvBench</li>
          </ul>
        </ul>
      </ul>
      <li>Online</li>
      <ul>
        <li>User engagement</li>
        <li>Conversion rate</li>
        <li>Online leaderboards</li>
      </ul>
    </ul>

    <h3 class="card-title">Serving</h3>

    <img class="img-fluid" class="card-img-top" src="/machine-learning-system-design/image/mlsd-c/chatgpt-1.png" alt="Card image cap">

    <ul>
      <li>Safety filtering</li>
      <ul>
        <li>Detect harmful, inappropriate, unsafe quries</li>
      </ul>
      <li>Prompt enhancer</li>
      <ul>
        <li>Expand acrynyms, correct spelling mistakes, add additional context</li>
      </ul>
      <li>Response generator</li>
      <ul>
        <li>Uses top-p sampling to generate response</li>
      </ul>
      <li>Response safety evaluator</li>
      <li>Rejection response generator</li>
      <li>Session management</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to manage dialogue and transfer contexts</li>
      <li>Explain how to do multi-token prediction</li>
      <li>Explain how to handle very long sequence length</li>
      <li>Explain how to develop multimodal LLM</li>
      <li>Explain how to use distillation for faster text generation</li>
      <li>Explain how to fine-tune LLM for specific task without forgetting previous knowledge</li>
      <li>Explain how to address privacy and security concerns in LLM</li>
      <li>Explain PPO, DPO, rejection sampling</li>
      <li>Explain how to reduce harmfulness in LLM</li>
      <li>Explain in-context learning</li>
      <li>Explain grouped query attention</li>
      <li>Explain how to implement KV cache</li>
      <li>Explain how to produce clear and verifiable justification for model ouputs</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-5">
  <div class="card-body">
    <h2 class="card-title">Image Captioning</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What type of images should the system support? General images</li>
      <li>How long should the caption be? It should be short and clear</li>
      <li>Should the system support multiple languages? No, English only</li>
      <li>Do we have training data available? Yes, 400M image-caption pairs</li>
      <li>Should the system generate captioning in real-time? Yes</li>
      <li>Should the system skip captioning if image is ambiguous? Yes</li>
      <li>Should the system handle bias and fairness in captioning? Yes</li>
      <li>What are dimensions of images? 256 by 256</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - image</li>
        <li>Output - text describing the input image</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Transformer with encoder-decoder architecture</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Caption</li>
      <ul>
        <li>Remove data points that are not English</li>
        <li>Remove duplicate image-caption data</li>
        <li>Summarize long captions</li>
        <li>Tokenize captions</li>
      </ul>
      <li>Image</li>
      <ul>
        <li>Remove low-resolution images that are less than 256 by 256</li>
        <li>Normalize images by scaling pixel values between 0 and 1</li>
        <li>Remove low quality images</li>
      </ul>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Model architecture</li>
      <ul>
        <li>Encoder</li>
        <ul>
          <li>Patchfy</li>
          <ul>
            <li>Divide the image into fixed-sized patches (Ex. 64 by 64)</li>
            <li>Flatten each patch</li>
            <li>Linearly project each path</li>
          </ul>
          <li>Positional encoding</li>
          <ul>
            <li>Assign position information to each patch</li>
          </ul>
        </ul>
        <li>Decoder</li>
        <ul>
          <li>Generate token by token, constructing captions</li>
        </ul>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Unsupervised pre-training</li>
        <ul>
          <li>Train encoder on general image data and decoder on general text data</li>
          <li>Alternatively, use an existing pre-trained model for encoder (Ex. Clip) and for decoder (Ex. Llama)</li>
        </ul>
        <li>Supervised fine-tuning</li>  
        <ul>
          <li>Train on pairs of image-caption</li>
          <li>Objective is to predict next token</li>
          <li>Cross-entropy loss</li>
        </ul>
        <li>Sampling</li>
        <ul>
          <li>Beam search for accuracy and consistency of caption</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <ul>
        <li>CIDEr</li>
        <ul>
          <li>Represent both generated and reference captions using TF-IDF</li>
          <li>Calculate similarities between the generated and each reference caption</li>
          <li>Aggregate and average the similarity scores, which represents overall simialrity between the generated and reference captions</li>
          <li>Final CIDEr is computed by average similarity scores for all generated captions in validation set</li>
          <li>Pros</li>
          <ul>
            <li>Robust to different caption variations</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Computationally expensive</li>
            <li>Sensitive to quality of reference captions</li>
            <li>May penalize creative phrases that are not in validation dataset</li>
            <li>Does not capture semantic similarity</li>
          </ul>
        </ul>
      </ul>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Preprocess images</li>
      <li>Generate caption</li>
      <li>Filtering</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to expand the model to perform visual question answering</li>
      <li>Explain how to generate caption in multiple languages using multilingual dataset and cross-linqual transfer learning</li>
      <li>Explain how to generate multiple captions and rank them</li>
      <li>Explain BLIP-2, BLIP-3</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-6">
  <div class="card-body">
    <h2 class="card-title">RAG</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What does knowledge base look like? Company's wiki pages and question-answer forum</li>
      <li>Does knowledge base contain texts, images, and other modalities? Yes, the documents are PDFs and they includes text, images, tables, diagrams</li>
      <li>Do documents have certain structure? No, they vary in structure</li>
      <li>How many pages of documents are there? 5M pages</li>
      <li>Should the system return citations of documents? Yes</li>
      <li>Should the system respond in real-time? Yes, but few seconds of delay is fine</li>
      <li>Should the system support multiple languages? No, English only</li>
      <li>Should the system support follow-up questions? Yes</li>
      <li>What is rate of growth of the documents? 20% per year</li>
      <li>Should the system handle safety, bias, fairness, etc? Yes</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - user prompt</li>
        <li>Output - answer</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Fine-tuning</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>Higher accuracy</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Computationally expensive</li>
            <li>Frequent retraining</li>
            <li>Hard to provide references for the answers</li>
          </ul>
        </ul>
        <li>Prompt engineering</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>No computation needed</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Highly dependant of quality of prompt</li>
            <li>Prompty often exceeds LLM's context window</li>
          </ul>
        </ul>
        <li>Retrieval augmented generation (RAG)</li>
        <ul>
          <li>Pros</li>
          <ul>
            <li>Access to most current information</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Highly dependant of quality of retriever</li>
          </ul>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Document parsing</li>
      <ul>
        <li>Convert texts, images, tables, diagrams into structured format that model can understand</li>
        <li>Ex. Dedoc, Layout-Parser, Google Cloud Document AI, PDF.co</li>
      </ul>
      <li>Document chunking</li>
      <ul>
        <li>Length-based chunking (Ex. LangChain's CharacterTextSplitter, RecursiveCharacterTextSplitter)</li>
        <li>Regular expression-based chunking</li>
        <li>HTML, markdown, code splitters (Ex. LangChain's MarkdownHeaderTextSplitter, HTMLHeaderTextSplitter, PythonCodeTextSplitter)</li>
      </ul>
      <li>Indexing</li>
      <ul>
        <li>Keyword-based</li>
        <ul>
          <li>Match exact query terms</li>
          <li>Struggle with synonyms and semantic search</li>
        </ul>
        <li>Full-text search</li>
        <ul>
          <li>Searches entire documents performs partial matches and phrase searches (Ex. Elasticsearch)</li>
          <li>Computationally expensives</li>
          <li>Struggle with semantic search</li>
        </ul>
        <li>Knowledge graph-based</li>
        <ul>
          <li>Uses relationship between entities (Ex. people, places)</li>
          <li>Building graph is lots of work</li>
        </ul>
        <li>Vector-based</li>
        <ul>
          <li>Match based on similarity of embeddings of query and chunks</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Model architecture</li>
      <ul>
        <li>Ingestion</li>
        <ul>
          <li>Text encoder</li>
          <li>Image encoder</li>
        </ul>
        <li>Generation</li>
      </ul>
      <li>Model training</li>
      <ul>
        <li>Retrieval augmented fine-tuning (RAFT)</li>
        <ul>
          <li>Label retrieved documents are relevant and irrelevant</li>
          <li>Fine-tune LLM with loss function that penalizes irrelevant document</li>
        </ul>
        <li>Sampling</li>
        <ul>
          <li>Compute query embedding</li>
          <li>Approximate nearest neighbor (ANN)</li>
          <ul>
            <li>Tree-based</li>
            <li>Locality-sensitive hashing (LSH)</li>
            <li>Clustering-based</li>
            <li>Graph-based (Ex. HNSW)</li>
          </ul>
          <li>Prompt engineering</li>
          <ul>
            <li>Chain-of-thought prompting</li>
            <ul>
              <li>Used when model needs to combine information from multiple documents</li>
            </ul>
            <li>Few-shot prompting</li>
            <ul>
              <li>Provide few examples of input-output pairs before the actual query</li>
            </ul>
            <li>Role-specific prompting</li>
            <ul>
              <li>Tell the model to assume a specific role</li>
            </ul>
            <li>User-context prompting</li>
            <ul>
              <li>Tell the model user profile to personalize the response</li>
            </ul>
          </ul>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <ul>
        <li>Context relevance</li>
        <ul>
          <li>Hit rate</li>
          <li>Mean reciprocal rank (MRR)</li>
          <li>Normalized discounted cumulative gain (NDCG)</li>
          <li>Precision@k</li>
        </ul>
        <li>Faithfulness</li>
        <ul>
          <li>Hunam evaluation</li>
          <li>Automated fact-checking tool</li>
          <li>Consistency checks</li>
        </ul>
        <li>Answer relevance</li>
        <li>Answer correctness</li>
      </ul>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Ingestion</li>
      <li>Filtering</li>
      <li>Query expansion</li>
      <li>Retrieval</li>
      <li>Generation</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to detect tables during document parsing</li>
      <li>Explain details of various ANN algorithms</li>
      <li>Explain how to support user-uploaded documents</li>
      <li>Explain dynamic retrieval strategy</li>
      <li>Explain query rewriting and expansion</li>
      <li>Explain inference time CoT and test-time scaling</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-7">
  <div class="card-body">
    <h2 class="card-title">Realistic Face Generation</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What is purpose of the system? Generate faces</li>
      <li>Should the system also generate body? No</li>
      <li>Should the system generate face that covers all ethnicity? Yes</li>
      <li>Should the system all users to provide face attributes? No</li>
      <li>Do we have training data available? Yes, 70k face images</li>
      <li>What is the resolution of generate image? 1024 by 1024</li>
      <li>Should the system generate faces in real-time? Yes, within a second</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - there is no input</li>
        <li>Output - face image</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Variational autoencoder</li>
        <ul>
          <li>Encoder converts input image into vector</li>
          <li>Decoer converts vector into image</li>
          <li>Pros</li>
          <ul>
            <li>Simple architecture</li>
            <li>Fast generation</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Lower quality (blurriness)</li>
          </ul>
        </ul>
        <li>Generative adversarial network</li>
        <ul>
          <li>Generator learns to make more realistic images</li>
          <li>Discriminator learns to distinguish real images from generated images</li>
          <li>Pros</li>
          <ul>
            <li>High quality generation</li>
            <li>Fast generation</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Hard to generate various images</li>
            <li>Hard to generate images based on certain attributes</li>
          </ul>
        </ul>
        <li>Autoregressive model</li>
        <ul>
          <li>Each part of image is generated sequentially</li>
          <li>Pros</li>
          <ul>
            <li>Can generate various images</li>
            <li>Can generate images based on certain attributes</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Slow generation</li>
          </ul>
        </ul>
        <li>Diffusion model</li>
        <ul>
          <li>During training, noisy is added to images</li>
          <li>Then, neural network is trained to predict the noise</li>
          <li>During inference, image is inially consisted of random noises</li>
          <li>Then, neural network interatively denoise the image</li>
          <li>Pros</li>
          <ul>
            <li>High quality</li>
            <li>Can generate various images</li>
            <li>Can generate images based on certain attributes</li>
          </ul>
          <li>Cons</li>
          <ul>
            <li>Slow generation</li>
          </ul>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Remove low-quality or low-resolution images</li>
      <li>Augment images - flip, rotate, color adjustment</li>
      <li>Resize and normalize images</li>
      <li>Address data imbalance in terms of race, gender, age</li>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Model architecture</li>
      <ul>
        <li>GAN</li>
      </ul>
      <li>Model training</li>
      <li>Sampling</li>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Face generator</li>
      <li>Training serivce</li>
      <li>Evaluation service</li>
      <li>Deployment servce</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain various GAN architecture like DCGAN, WGAN, StyleGAN</li>
      <li>Explain techniques for stabilizing GAN such as Wasserstein loss, gradient penality</li>
      <li>Explain how to use conditional GAN (cGAN) to generate faces based on certain conditions</li>
      <li>Explain evaluation metrics of condition consistency</li>
      <li>Explain style-mixing in face generation</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-8">
  <div class="card-body">
    <h2 class="card-title">High-Resolution Image Synthesis</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What is kind of images should the system support? Natural scenes and urban landscapes</li>
      <li>Do we have training data available? Yes, 5M images</li>
      <li>Should the system support input text describing desired images? Yes</li>
      <li>What is resolution of images? 1024 by 1024 or 2048 by 2048</li>
      <li>Should the system generate faces in real-time? Yes, within five seconds</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - there is no input</li>
        <li>Output - high-resolution image</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Variational autoencoder</li>
        <ul>
          <li>Hard to generate high-resolution image</li>
          <li>Decoder needs to be powerful to meet high-resolution requirement</li>
          <li>But, decoder then ignores latent variables reducing diversity of images</li>
        </ul>
        <li>Generative adversarial network</li>
        <ul>
          <li>Same limitation as VAE</li>
        </ul>
        <li>Autoregressive model</li>
        <ul>
          <li>Image tokenizer</li>
          <li>Image generator</li>
        </ul>
        <li>Diffusion model</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Image cleaning and normalization</li>
      <li>Image tokenization</li>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Architecture</li>
      <ul>
        <li>Image tokenizer</li>
        <li>Image generator</li>
      </ul>
      <li>Training</li>
      <li>Sampling</li>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Image generator</li>
      <li>Decoding serivce</li>
      <li>Super-resolution service</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to expand autoregressive models to support text-based generation</li>
      <li>Explain how to support applications such as image completion and image super-resolution</li>
      <li>Explain how to balance diversity and fidelity in sampling</li>
      <li>Explain how to enhance stability with adversarial training, gradient clipping, learning rate scheduling</li>
      <li>Explain how to use progressive growing and multi-scale architecture to improve image quality and detail</li>
      <li>Explain how to create interactive systems for users to refine and customize generated images</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-9">
  <div class="card-body">
    <h2 class="card-title">Text-to-Image Generation</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What is the resolution of image to generate? 1024 by 1024</li>
      <li>Should the system support multiple languages as input? No, English only</li>
      <li>Do we have training data available? Yes, 500M images with captions</li>
      <li>Is the a limit on the length of text input? Yes, 128 words</li>
      <li>Should the system generate faces in real-time? Yes, within 10 seconds</li>
      <li>What type of images should the system support? All types</li>
      <li>Should the system handle safety, bias, fairness? Yes</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - text</li>
        <li>Output - image that corresponds to input text</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Autoregressive model</li>
        <ul>
          <li>Simpler to implement</li>
        </ul>
        <li>Diffusion model</li>
        <ul>
          <li>Higher image quality</li>
          <li>Flexible for tuning sampling speed vs image quality</li>
        </ul>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Image preparation</li>
      <li>Caption preparation</li>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Architecture</li>
      <li>Training</li>
      <li>Sampling</li>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Data pipeline</li>
      <li>Training pipeline</li>
      <li>Evaluation pipeline</li>
      <li>Model optimization pipeline</li>
      <li>Inference pipeline</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to use consistency models for faster image generation</li>
      <li>Explain how to employ RLHF for quality improvement</li>
      <li>Explain how to extend text-to-image model to support inpainting and outpainting applications</li>
      <li>Explain how to personalize text-to-image model</li>
      <li>Explain details on different scheduling techniques</li>
      <li>Explain DDPM and DDIM</li>
      <li>Explain how to support multiple aspect rations and resolutions</li>
      <li>Explain how to develop a re-captioning model</li>
      <li>Explain how to improve diversity-fidelity trade-off with guidance</li>
      <li>Explain ControlNet</li>
      <li>Explain how to control the style of generated images</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-10">
  <div class="card-body">
    <h2 class="card-title">Personalized Headshot Generation</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What is purpose of the system? Generate headshot image for business profile</li>
      <li>How many images does user upload? 10-20 images</li>
      <li>Should the system ask users to upload new images if images are bad? Yes</li>
      <li>Should the system allow users to input desired attributes? No</li>
      <li>What is the resolution of image? 1024 by 1024</li>
      <li>Can the system use a pre-trained model? Yes</li>
      <li>Should the system allow users to input texts describing desired image? No</li>
      <li>How many images should the system generate? 50 images</li>
      <li>Should the system generate faces in real-time? No, generation should be less than an hour</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - images that users provide</li>
        <li>Output - professional headshot image</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Tuning-based</li>
        <ul>
          <li>Textual inversion</li>
          <li>DreamBooth</li>
          <li>Low-rank adaption (LoRA)</li>
        </ul>
        <li>Tuning-free</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Image resizing</li>
      <li>Image augmentation</li>
      <li>Generic face data addition</li>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Architecture</li>
      <li>Training</li>
      <li>Sampling</li>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Data pipeline</li>
      <li>Training pipeline</li>
      <li>Inference pipeline</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to prevent catastrophic forgetting during fine-tuning</li>
      <li>Explain details of choosing a rare token for new subject, and its importance</li>
      <li>Explain details of class-specific prior preservation loss</li>
      <li>Explain how to address the issue of reduced output diversity after fine-tuning</li>
      <li>Explain how to support multiple sizes and aspect ratios in generated images</li>
      <li>Explain details of tuning-free methods such as Meta's Imagine Yourself</li>
      <li>Explain how to mitigate the risk and ethical concerns around deepfake generation and detection</li>
      <li>Explain ML techniques to handle personally identifiable information (PII) securely while ensuring data privacy</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="generative-ai-system-design-11">
  <div class="card-body">
    <h2 class="card-title">Text-to-Video Generation</h2>

    <h3 class="card-title">Clarifying Requirements</h3>
    <ul>
      <li>What is the length of video? 5 seconds</li>
      <li>What is the resolution of video? 720p</li>
      <li>What is FPS of video? 24</li>
      <li>What is expected latency? few minutes</li>
      <li>Should the system generate all types of videos? Yes</li>
      <li>Should the system support multiple languages as input? No, English only</li>
      <li>Should the system also generate audio? No</li>
      <li>Do we have training data available? Yes, 100M videos with captions</li>
      <li>Can the system use a pre-trained model? Yes</li>
      <li>What is compute budget? 6000 H100 GPUs</li>
      <li>Should the system handle safety, bias, fairness? Yes</li>
    </ul>

    <h3 class="card-title">Frame the Problem as an ML Task</h3>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - text</li>
        <li>Output - video that corresponds to input text</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Latent diffusion model</li>
      </ul>
    </ul>

    <h3 class="card-title">Data Preparation</h3>
    <ul>
      <li>Video preparation</li>
      <ul>
        <li>Remove low-quality or low-resolution images</li>
        <li>Remove inappropriate videos</li>
        <li>Remove duplicate videos</li>
        <li>Adjust video length to be 5 seconds</li>
        <li>Standardize frame rate by re-encoding videos with higher frames to 24FPS</li>
        <li>Resize and crop videos to a standard size</li>
      </ul>
      <li>Caption preparation</li>
      <ul>
        <li>Handle missing or non-English captions</li>
        <li>Re-captioning </li>
        <li>Pre-compute caption embeddings</li>
      </ul>
    </ul>

    <h3 class="card-title">Model Development</h3>
    <ul>
      <li>Architecture</li>
      <li>Training</li>
      <li>Sampling</li>
    </ul>

    <h3 class="card-title">Evaluation</h3>
    <ul>
      <li>Offline</li>
      <li>Online</li>
    </ul>

    <h3 class="card-title">Serving</h3>
    <ul>
      <li>Data pipeline</li>
      <li>Training pipeline</li>
      <li>Inference pipeline</li>
    </ul>

    <h3 class="card-title">Follow Up</h3>
    <ul>
      <li>Explain how to ensure sampling flexibility for variable durations, resolutions, and aspect ratios</li>
      <li>Explain how to extend text-to-video model to inpainting, outpainting, video-to-video stylization, frame interpolation, super-resolution, animating images</li>
      <li>Explain how to support controlling the generated videos such as level of desired motion and type of motion</li>
      <li>Explain how to use progressive distillation techniques to reduce the computational demands of training</li>
      <li>Explain details of spatial and temporal super-resolution models</li>
      <li>Explain details of re-captioning model</li>
      <li>Explain different noise schedulers</li>
      <li>Explain noise conditioning augmentation techniques</li>
      <li>Explain how to personlize a text-to-video model to a particular subject</li>
      <li>Explain ControlNet for text-to-video model</li>
      <li>Explain details of stable cascade method</li>
      <li>Explain details of visual compression method</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>
<!-- Generative AI System Design END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>