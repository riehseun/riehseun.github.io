<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Text-to-Video Generation BEGIN -->
<div class="card mb-4" id="text-to-video-generation">
  <div class="card-body">
    <h2 class="card-title">Text-to-Video Generation</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#text-to-video-generation-1">Clarifying Requirements</a></li>
      <li><a href="#text-to-video-generation-2">Frame the Problem as an ML Task</a></li>
      <li><a href="#text-to-video-generation-3">Data Preparation</a></li>
      <li><a href="#text-to-video-generation-4">Model Development</a></li>
      <li><a href="#text-to-video-generation-5">Evaluation</a></li>
      <li><a href="#text-to-video-generation-6">Serving</a></li>
      <li><a href="#text-to-video-generation-7">Follow Up</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation1">
  <div class="card-body">
    <h2 class="card-title">Clarifying Requirements</h2>
    <ul>
      <li>What is the length of video? 5 seconds</li>
      <li>What is the resolution of video? 720p</li>
      <li>What is FPS of video? 24</li>
      <li>What is expected latency? few minutes</li>
      <li>Should the system generate all types of videos? Yes</li>
      <li>Should the system support multiple languages as input? No, English only</li>
      <li>Should the system also generate audio? No</li>
      <li>Do we have training data available? Yes, 100M videos with captions</li>
      <li>Can the system use a pre-trained model? Yes</li>
      <li>What is compute budget? 6000 H100 GPUs</li>
      <li>Should the system handle safety, bias, fairness? Yes</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation2">
  <div class="card-body">
    <h2 class="card-title">Frame the Problem as an ML Task</h2>
    <ul>
      <li>Specify system input and output</li>
      <ul>
        <li>Input - text</li>
        <li>Output - video that corresponds to input text</li>
      </ul>
      <li>Choose suitable ML approach</li>
      <ul>
        <li>Latent diffusion model</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation3">
  <div class="card-body">
    <h2 class="card-title">Data Preparation</h2>
    <ul>
      <li>Video preparation</li>
      <ul>
        <li>Remove low-quality or low-resolution images</li>
        <li>Remove inappropriate videos</li>
        <li>Remove duplicate videos</li>
        <li>Adjust video length to be 5 seconds</li>
        <li>Standardize frame rate by re-encoding videos with higher frames to 24FPS</li>
        <li>Resize and crop videos to a standard size</li>
      </ul>
      <li>Caption preparation</li>
      <ul>
        <li>Handle missing or non-English captions</li>
        <li>Re-captioning </li>
        <li>Pre-compute caption embeddings</li>
      </ul>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation4">
  <div class="card-body">
    <h2 class="card-title">Model Development</h2>
    <ul>
      <li>Architecture</li>
      <li>Training</li>
      <li>Sampling</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation5">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>
    <ul>
      <li>Offline</li>
      <li>Online</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation6">
  <div class="card-body">
    <h2 class="card-title">Serving</h2>

    <img class="img-fluid" class="card-img-top" src="/machine-learning/image/machine-learning-system-design-1/text-to-image-generation1.png" alt="Card image cap">

    <ul>
      <li>Data pipeline</li>
      <li>Training pipeline</li>
      <li>Inference pipeline</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>

<div class="card mb-4" id="text-to-image-generation7">
  <div class="card-body">
    <h2 class="card-title">Follow Up</h2>
    <ul>
      <li>Explain how to ensure sampling flexibility for variable durations, resolutions, and aspect ratios</li>
      <li>Explain how to extend text-to-video model to inpainting, outpainting, video-to-video stylization, frame interpolation, super-resolution, animating images</li>
      <li>Explain how to support controlling the generated videos such as level of desired motion and type of motion</li>
      <li>Explain how to use progressive distillation techniques to reduce the computational demands of training</li>
      <li>Explain details of spatial and temporal super-resolution models</li>
      <li>Explain details of re-captioning model</li>
      <li>Explain different noise schedulers</li>
      <li>Explain noise conditioning augmentation techniques</li>
      <li>Explain how to personlize a text-to-video model to a particular subject</li>
      <li>Explain ControlNet for text-to-video model</li>
      <li>Explain details of stable cascade method</li>
      <li>Explain details of visual compression method</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: Generative AI System Design Interview, Ali Aminian & Hao Sheng
  </div>
</div>
<!-- Text-to-Video Generation END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>