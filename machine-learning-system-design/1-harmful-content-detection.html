<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Machine Learning</h1>

<!-- Harmful content detection BEGIN -->
<div class="card mb-4" id="harmful-content-detection">
  <div class="card-body">
    <h2 class="card-title">Harmful content detection</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#harmful-content-detection-">Harmful content detection</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="product-search-">
  <div class="card-body">
    <h2 class="card-title">Product search</h2>

    <pre><code class="markdown">
Requirement and problem

Business
  What is purpose of the system?
  Where do potentially harmful content exist?
  How do harmful content get created?
  Should the system remove harmful content in the existing feed? yes - #1
  What does feed consist of?
  Should the system support multiple languages?
  What is defintion of harmful content? Violence, nude, hate, etc - #2
Data
  Is labeled dataset available? No
  Should the system use user reports on harmful content? yes - #2
Constraint
  Should the model be deployed to mobile device?
  Should the model be continuously trained? yes - #3 (if time)
  How fast should the inference be? under 200ms - #4 (if time)
Problem
Input
Output

High-level design

Data and feature engineering

Data
  User
  Feed
  Image
  Video
Feature
  User - history of posting harmful contents, number of reports received
  Text - hate speech, promoting violence, inappropriate words
  Image - inappropriate visuals
  Video - inappropriate visuals
Engineering
  Numerical - standarize (scale and normalize)
  Text - BERT
  Image - CLIP
  Video - CLIP

Model development

Baseline
  Logistic regression - binary classification to determine whether a post in harmful or not
Model
  Ensemble - cannot handle text, image, video well
  Neural network - blackbox, lots of dataprep, but best choice
    Loss - cross-entropy (binary classification)
Training data
  Human label - expensive but accurate
  User reports - inexpensive but noisy
Data spilt
  Splitting by time makes sence because languages associated with violence, hate changes with time
  56% - training set
  24% - dev set
  20% - test set
Imbalanced dataset
  Most examples will be negative, thus undersample

Inference and evaluation

Sampling
  N/A
Offline metrics
  Recall - how many actual harmful content can the model retrieve?
  Precision - how accurate are the identified harmful contents
  PR curve - precision vs recall
Online metric
  Number of user reports
</code></pre>

    <img class="img-fluid" class="card-img-top" src="/machine-learning-system-design/image/mlsd1/harmful-content-detection-1.png" alt="Card image cap">

    <img class="img-fluid" class="card-img-top" src="/machine-learning-system-design/image/mlsd1/harmful-content-detection-2.png" alt="Card image cap">
  </div>
  <div class="card-footer text-muted">
    Reference: 
  </div>
</div>
<!-- Harmful content detection END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>