<!DOCTYPE html>

<html lang="en">

<head>

<!-- Metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="">
<meta name="author" content="Seungmoon Rieh">
<meta name="keywords" content="">

<!-- Title and image -->
<title>Seungmoon Rieh</title>
<link href="/img/seungmoonrieh.jpg" rel="icon">

<!-- CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/monokai-sublime.css" rel="stylesheet">
<link href="/css/site.css" rel="stylesheet">

<!-- JavaScript -->
<script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/bootstrap.bundle.min.js" type="text/javascript"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script src="/js/include_html.js" type="text/javascript"></script>
<script src="/js/mathjax/tex-chtml.js" type="text/javascript"></script>
<script src="/js/site.js" type="text/javascript"></script>

</head>

<body>

<include src="/header.html"></include>

<div class="container">
<div class="row">
<div class="col-md-12">
<h1 class="my-4">Software Engineering</h1>

<!-- Web crawler BEGIN -->
<div class="card mb-4" id="web-crawler">
  <div class="card-body">
    <h2 class="card-title">Web crawler</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#web-crawler-1">Requirement</a></li>
      <li><a href="#web-crawler-2">Estimation</a></li>
      <!-- <li><a href="#web-crawler-3">Storage schema</a></li> -->
      <li><a href="#web-crawler-4">High level design</a></li>
      <!-- <li><a href="#web-crawler-5">API</a></li> -->
      <li><a href="#web-crawler-6">Detailed design</a></li>
      <li><a href="#web-crawler-7">Evaluation</a></li>
      <li><a href="#web-crawler-8">Distinct component</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="web-crawler-1">
  <div class="card-body">
    <h2 class="card-title">Requirement</h2>

    <h3 class="card-title">Functional</h3>
    <ul>
      <li>What does web crawler need to do? Search engine indexing</li>
      <li>How many web pages to crawl? 1B pages</li>
      <li>What content types are in scpe? HTML only</li>
      <li>Do we need to store HTML page? Yes for 5 yearss</li>
      <li>What about duplicate content? Duplicate content should be ignored</li>
    </ul>

    <h3 class="card-title">Non-functional</h3>
    <ul>
      <li>Availability</li>
      <li>Reliability</li>
      <li>Scalability</li>
      <li>Performance</li>
      <li>Consistency</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: System Design Interview, Alex Xu
  </div>
</div>

<div class="card mb-4" id="web-crawler-2">
  <div class="card-body">
    <h2 class="card-title">Estimation</h2>

    <h3 class="card-title">Server</h3>
    <ul>
      <li>Assume</li>
      <ul>
        <li>100ms to traverse one page</li>
        <li>1B HTML pages</li>
      </ul>
      <li>100ms * 1B = 100Ms = 1157 days</li>
      <li>To crawl the web in one day, we need 1157 servers</li>
    </ul>

    <h3 class="card-title">Storage</h3>
    <ul>
      <li>Assume</li>
      <ul>
        <li>1B HTML pages per month</li>
        <li>Page size including metadata is 100KB on average</li>
      </ul>
      <li>1B * 100KB = 100TB</li>
      <li>100TB per month = 6PM for 5 years</li>
    </ul>

    <h3 class="card-title">Bandwidth</h3>
    <ul>
      <li>Incoming - 100TB * 8 / (86400 * 30) = 3Gbps</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: System Design Interview, Alex Xu
  </div>
</div>

<div class="card mb-4" id="web-crawler-4">
  <div class="card-body">
    <h2 class="card-title">High level design</h2>

    <h3 class="card-title">High level design</h3>
    <ul>
      <li>Worker gets a URL to work on.</li>
      <li>DNS is resolved to provide the IP address.</li>
      <li>Download the document.</li>
      <li>Parse document contents to look for new URLs.</li>
      <li>Add new URLs to unvisited URL list.</li>
      <li>Process downloaded document.</li>
    </ul>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/web-crawler1.png" alt="Card image cap">

    <h4 class="card-title">URL frontier (priority queue)</h4>
    <ul>
      <li>Contains all the remaining URLs to download.</li>
      <li>Prioritize which URLs should be downloaded first.</li>
      <li>Use BFS implemented by a queue.</li>
      <li>Distributed into multiple servers.</li>
      <ul>
        <li>Each server maintains many queues such that each thread gets a queue.</li>
        <li>Hash table maps carnonical hostname to thread number that run the queue.</li>
      </ul>
      <li>Due to huge size of URLs, need to store URLs into a disk.</li>
      <ul>
        <li>Enqueue buffer, once filled, is dumped into disk.</li>
        <li>Dequeue buffer keeps cache of URLs to be visited. It periodically reads from disk to fill the buffer.</li>
      </ul>
    </ul>

    <h4 class="card-title">Relational DB</h4>
    <ul>
      <li>Stores all the URLs with two associated parameters "priority" and "update frequency".</li>
    </ul>

    <h4 class="card-title">DNS resolver</h4>
    <ul>
      <li>Custom DNS resolver is needed because DNS lookup is time consuming process.</li>
      <li>Cache frequently used IP addresses within their TTL.</li>
    </ul>

    <h4 class="card-title">HTML fetcher</h4>
    <ul>
      <li>Downloads documents corresponding to given URL using protocol like HTTP.</li>
    </ul>

    <h4 class="card-title">Service host</h4>
    <ul>
      <li>Each worker dequeues URL from the URL frontier.</li>
      <li>Each worker uses DNS resolver to acquire web page's IP address.</li>
    </ul>

    <h4 class="card-title">Document input stream</h4>
    <ul>
      <li>Cache used to store the extracted document.</li>
      <li>Prevents downloading the same document again.</li>
      <li>Redis can be used to implement this.</li>
    </ul>

    <h4 class="card-title">Duplicate eliminator</h4>
    <ul>
      <li>Checks if document is duplicate.</li>
      <li>Calculates 64-bit checksum of every processed document using MD5 or SHA and store it in DB.</li>
    </ul>

    <h4 class="card-title">Blob store</h4>
    <ul>
      <li>Stores fetched content and metadata.</li>
    </ul>

    <!-- <h4 class="card-title">URL filter</h4>
    <ul>
      <li>Blocks some websites so that crawler can ignore them.</li>
    </ul>

    <h4 class="card-title">URL de-dup</h4>
    <ul>
      <li>Check if URL is duplicates. (Multiple URL linking to the same document)</li>
      <li>Store checksum of URLs in carnonical forms into DB.</li>
    </ul> -->

  </div>
  <div class="card-footer text-muted">
    Reference: System Design Interview, Alex Xu
  </div>
</div>

<div class="card mb-4" id="web-crawler-6">
  <div class="card-body">
    <h2 class="card-title">Detailed design</h2>

    <img class="img-fluid" class="card-img-top" src="/img/system-design/web-crawler2.png" alt="Card image cap">

    <h3 class="card-title">Block servers</h3>
    <ul>
      <li>A file is split into smaller blocks</li>
      <li>Each block is compressed to reduce size</li>
      <li>Each block is encrypted to ensure security</li>
      <li>Each block is uploaded to cloud storage</li>
      <ul>
        <li>Delta sync - only the modified blocks are trasferred to cloud stroage</li>
      </ul>
    </ul>

    <h3 class="card-title">Client uploads a file</h3>
    <ul>
      <li>File metadata</li>
      <ul>
        <li>Cilent 1 sends a request to add metadata of new file</li>
        <li>New file metadata is added to metadata DB</li>
        <li>Notification service notifies client 2 that the new file is being uploaded</li>
      </ul>
      <li>File upload</li>
      <ul>
        <li>Client 1 uploads file to block servers</li>
        <li>Block servers process the file and upload blocks to cloud storage</li>
        <li>Cloud storage calls API servers</li>
        <li>API servers change file status to "uploaded" in metadata DB</li>
        <li>Notification service notifies client 2 that the new file has been uploaded</li>
      </ul>
    </ul>

    <h3 class="card-title">File is added or edited elsewhere</h3>
    <ul>
      <li>Client 2 sends requests to API servers to fetch metadata</li>
      <li>Client 2 sends requests to block servers to download blocks</li>
      <li>Block servers retrieve blocks from cloud storage</li>
      <li>Client 2 downloads all blocks to reconstruct the file</li>
    </ul>

    <h3 class="card-title">Notification service</h3>
    <ul>
      <li>WebSocket</li>
      <ul>
        <li>Persistent connection between client and server</li>
        <li>Communication is bi-directional</li>
        <li>Suited for real-time communication like chat app</li>
      </ul>
      <li>Long polling (choose this over WebSocket)</li>
      <ul>
        <li>Communication for notificaiton service is not bi-directional</li>
        <li>Notifications are sent infrequently</li>
      </ul>
    </ul>

    <h3 class="card-title">Save storage space</h3>
    <ul>
      <li>De-duplicate data blocks that have the same hash value</li>
      <li>Set limits on number of versions to store</li>
      <li>Move infrequently used data to cold storage</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: System Design Interview, Alex Xu
  </div>
</div>

<div class="card mb-4" id="web-crawler-7">
  <div class="card-body">
    <h2 class="card-title">Evaluation</h2>

    <h3 class="card-title">Availability</h3>
    <ul>
      <li>Replication</li>
      <ul>
        <li>Replicate each server and DB</li>
        <li>Replicate entire components to different zone or geographical region</li>
      </ul>
      <li>Fail over</li>
      <ul>
        <li>Load balancer - active-passive, when heartbeat fails, the secondary takes the IP</li>
        <li>Block servers - other block servers pick up the job</li>
        <li>Cloud storage - S3 is replicated is multiple regions. Blocks can be fetched from different region if one region fails</li>
        <li>API servers - traffic is redirected to other API servers via load balancer</li>
        <li>Metadata cache - other cache servers serve the cache</li>
        <li>Metadata DB</li>
        <ul>
          <li>Master - promote one slave to master</li>
          <li>Slave - use anotehr slave for read operation</li>
        </ul>
        <li>Notification service - all clients reconnect to different server (This can be slow)</li>
        <li>Offline backup queue - other queue can be subscribed by consumers</li>
      </ul>
    </ul>

    <h4 class="card-title">Reliability</h4>
    <ul>
      <li>Data loss - regional backup of database using S3</li>
    </ul>

    <h3 class="card-title">Scalability</h3>
    <ul>
      <li>Horizontal scaling</li>
      <li>Data replication</li>
    </ul>

    <h4 class="card-title">Performance</h4>
    <ul>
      <li>Use of metadata cache</li>
      <li>Spliting files into blocks and delta update</li>
    </ul>

    <h3 class="card-title">Consistency</h3>
    <ul>
      <li>RDBMS is chosen to achieve strong consistency</li>
      <li>Strong consistency is needed for all users to see the same file information</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: System Design Interview, Alex Xu
  </div>
</div>

<div class="card mb-4" id="web-crawler-8">
  <div class="card-body">
    <h2 class="card-title">Distinct component</h2>

    <h3 class="card-title">Sync conflict</h3>
    <ul>
      <li>When two users are trying to update the same file, conflict can happen</li>
      <li>First user's update goes through while second user gets conflict</li>
      <li>Second user is presented both copies of files (local copy and server copy) and user can either merge or override the file</li>
    </ul>
  </div>
  <div class="card-footer text-muted">
    Reference: System Design Interview, Alex Xu
  </div>
</div>
<!-- Web crawler END -->

<!-- Web crawler BEGIN -->
<div class="card mb-4" id="web-crawler">
  <div class="card-body">
    <h2 class="card-title">Web crawler</h2>
    <ul class="list-unstyled mb-0">
      <li><a href="#web-crawler-1">Web crawler</a></li>
    </ul>
  </div>
</div>

<div class="card mb-4" id="web-crawler-1">
  <div class="card-body">
    <h2 class="card-title">Web crawler</h2>


    <h3 class="card-title">Evaluation</h3>

    <h4 class="card-title">Availability</h4>

    <h4 class="card-title">Reliability</h4>

    <h4 class="card-title">Scalability</h4>
    <ul>
      <li>Data partitioning</li>
      <ul>
        <li>Distribute based on hostname which contains URLs to visit, URL checksum, document checksum.</li>
      </ul>
    </ul>

    <h4 class="card-title">Performance</h4>
  </div>
  <div class="card-footer text-muted">
    <a href="https://www.educative.io/path/deep-dive-into-system-design-interview">Deep Dive into System Design Interview</a>
  </div>
</div>
<!-- Web crawler END -->

</div> <!-- /.col-md-12 -->
</div> <!-- /.row -->
</div> <!-- /.container -->

<include src="/footer.html"></include>

</body>

</html>